{"ms": ["Here is a purely classical (non\u2010coordinate) proof using nothing more than elementary Euclidean geometry and Thales\u2019 circle theorem.\n\n1.  Let $ABC$ be a right\u2013angled triangle with right angle at $C.$  \n2.  Let $M$ be the midpoint of the hypotenuse $AB,$ and draw the circle with centre $M$ and radius $MA=MB\\,. $  \n3.  By the converse of Thales\u2019 theorem, \u201can angle inscribed in a semicircle is a right angle,\u201d the fact that $\\angle ACB=90^\\circ$ tells us that $C$ lies on the circle having $AB$ as diameter.  \n4.  But if $C$ lies on that circle whose centre is $M$ and whose radius is $MA=MB$, then also  \n   \n   $$MC \\;=\\; MA \\;=\\; MB\\,. $$\n   \n5.  In particular, since $MA=MB=\\tfrac12\\,AB,$ we conclude  \n   \n   $$MC \\;=\\;\\tfrac12\\,AB\\,. $$\n   \nBut $MC$ is exactly the median from the right angle $C$ to the hypotenuse $AB.$  Hence the median to the hypotenuse has length one\u2013half the hypotenuse.  \u25a1", "Proof.  Let ABC be the given triangle.  Through vertex C draw a line \u2113 parallel to AB.  Let \u2113 meet the extension of AC (beyond C) at D and the extension of BC (beyond C) at E.  Then:\n\n1.  Since \u2113 \u2225 AB, the angle \u2220ACD is an alternate-interior angle with \u2220CAB.  Hence  \n   \u2220ACD = \u2220CAB.  \n\n2.  Similarly, \u2113 \u2225 AB makes \u2220ECB an alternate-interior angle with \u2220CBA.  Hence  \n   \u2220ECB = \u2220CBA.  \n\n3.  Now at point C, the three angles \u2220ACD, \u2220ACB, and \u2220ECB lie along the straight line DE, so their sum is a straight angle, i.e. 180\u00b0:  \n   \u2220ACD + \u2220ACB + \u2220ECB = 180\u00b0.  \n\n4.  Substituting the equalities from steps 1 and 2 gives  \n   \u2220CAB + \u2220ACB + \u2220CBA = 180\u00b0.  \n\nBut those three are exactly the interior angles of triangle ABC.  Therefore the sum of the interior angles of any triangle is 180\u00b0. \u220e", "Proof.  Let \u2113\u2081, \u2113\u2082, and \u2113\u2083 be three lines in the plane, and assume  \n  (1) \u2113\u2081 \u2225 \u2113\u2083  \n  (2) \u2113\u2082 \u2225 \u2113\u2083.  \nWe must show \u2113\u2081 \u2225 \u2113\u2082, i.e. that \u2113\u2081 and \u2113\u2082 do not meet.\n\nSuppose, for the sake of contradiction, that \u2113\u2081 and \u2113\u2082 do meet.  Then they meet in at least one point, say P.  Since \u2113\u2081 \u2225 \u2113\u2083, \u2113\u2081 does not meet \u2113\u2083, so in particular P is not on \u2113\u2083.  But now through the point P (which lies off \u2113\u2083) there are two distinct lines, \u2113\u2081 and \u2113\u2082, both parallel to \u2113\u2083.  This contradicts the given fact that \u201cthrough a point outside a line there is exactly one parallel to that line.\u201d  \n\nThus our assumption that \u2113\u2081 meets \u2113\u2082 must be false.  Hence \u2113\u2081 and \u2113\u2082 do not intersect, so by definition they are parallel.  \n\nTherefore, if two lines are each parallel to a third line, they are parallel to each other. \u220e", "Here is a one\u2010step proof using only the SAS congruence criterion:\n\nLet ABC be an isosceles triangle with AB = AC.  Consider the two triangles \u0394ABC and \u0394ACB:\n\n1. In \u0394ABC and \u0394ACB,  \n   \u2022 AB = AC\u2003(given)  \n   \u2022 AC = AB\u2003(given)  \n   \u2022 \u2220BAC = \u2220CAB\u2003(the same angle)  \n\n2. By SAS, \u0394ABC \u2245 \u0394ACB.\n\n3. Corresponding angles in congruent triangles are equal, so  \n   \u2220ABC = \u2220ACB.  \n\nBut \u2220ABC and \u2220ACB are exactly the two base\u2010angles opposite the equal sides AB and AC.  Hence those two angles are equal.  \u25a1", "Proof (using the Pythagorean theorem and the SSS criterion for triangle congruence)\n\nLet \u0394ABC be any triangle whose side\u2013lengths satisfy\n\u2003BC\u00b2 + AC\u00b2 = AB\u00b2.  \nLabel these lengths as follows:  \n\u2003a = BC,\u2003b = AC,\u2003c = AB,  \nso that a\u00b2 + b\u00b2 = c\u00b2.\n\n1.  Construct a right triangle \u0394A\u2032B\u2032C\u2032 with right angle at C\u2032 and legs of lengths a and b:\n    \u2022  Place point C\u2032.  \n    \u2022  On one ray from C\u2032 mark point B\u2032 so that C\u2032B\u2032 = a.  \n    \u2022  On the other ray from C\u2032, perpendicular to the first, mark point A\u2032 so that C\u2032A\u2032 = b.  \n    By construction \u2220B\u2032C\u2032A\u2032 = 90\u00b0, and by the Pythagorean theorem in \u0394A\u2032B\u2032C\u2032 we get\n       A\u2032B\u2032\u00b2 = (C\u2032B\u2032)\u00b2 + (C\u2032A\u2032)\u00b2 = a\u00b2 + b\u00b2 = c\u00b2.\n    Hence in \u0394A\u2032B\u2032C\u2032 the three side\u2013lengths are\n       C\u2032B\u2032 = a,\u2003C\u2032A\u2032 = b,\u2003A\u2032B\u2032 = c.\n\n2.  Compare \u0394ABC and \u0394A\u2032B\u2032C\u2032:\n    \u2022  In \u0394ABC:  BC = a,  AC = b,  AB = c.\n    \u2022  In \u0394A\u2032B\u2032C\u2032:  C\u2032B\u2032 = a,  C\u2032A\u2032 = b,  A\u2032B\u2032 = c.\n    Therefore all three pairs of corresponding sides are equal:\n       BC = C\u2032B\u2032,  AC = C\u2032A\u2032,  AB = A\u2032B\u2032.\n    By the SSS (side\u2013side\u2013side) congruence criterion,  \n       \u0394ABC \u2245 \u0394A\u2032B\u2032C\u2032.\n\n3.  Since \u0394A\u2032B\u2032C\u2032 has \u2220B\u2032C\u2032A\u2032 = 90\u00b0 and corresponding angles in congruent triangles are equal, it follows that\n       \u2220BCA = 90\u00b0.\n    Thus \u0394ABC has a right angle at C.\n\nConclusion: Any triangle whose sides a, b, c satisfy a\u00b2 + b\u00b2 = c\u00b2 must be congruent to a right triangle and therefore itself is a right triangle.", "Here is a purely \u201cPythagorean\u2010theorem\u2010only\u201d proof.  Let \u0394ABC have the obtuse angle at C, and let c = AB, a = BC, b = AC.  We will drop a perpendicular from B onto the line AC (not just the segment AC) so that the foot D lies on the extension of AC beyond C.\n\n1.  Construct D on the line AC so that BD \u27c2 AC.  Because \u2220C is obtuse, the foot D of the perpendicular from B lies beyond C on the line AC.\n\n2.  In right \u0394BCD, by the Pythagorean theorem  \n      BC\u00b2 = BD\u00b2 + CD\u00b2     \u21d2     a\u00b2 = BD\u00b2 + CD\u00b2.\n\n   In right \u0394BAD, again by Pythagoras  \n      AB\u00b2 = BD\u00b2 + AD\u00b2     \u21d2     c\u00b2 = BD\u00b2 + AD\u00b2.\n\n3.  But on the line AC we have C between A and D, so  \n      AD = AC + CD = b + CD.\n\n   Hence  \n      AD\u00b2 = (b + CD)\u00b2 = b\u00b2 + 2\u00b7b\u00b7CD + (CD)\u00b2.\n\n4.  Substitute back into c\u00b2:  \n      c\u00b2 = BD\u00b2 + AD\u00b2  \n         = BD\u00b2 + [b\u00b2 + 2b\u00b7CD + (CD)\u00b2]  \n         = (BD\u00b2 + CD\u00b2) + b\u00b2 + 2b\u00b7CD  \n         = a\u00b2 + b\u00b2 + 2b\u00b7CD.  \n\n   Since b > 0 and CD > 0, the extra term 2b\u00b7CD is strictly positive.  Therefore  \n      c\u00b2 = a\u00b2 + b\u00b2 + 2b\u00b7CD  > a\u00b2 + b\u00b2.\n\nWhich is exactly the assertion that in an obtuse triangle (obtuse at C) the square of the side opposite C (namely c\u00b2) exceeds the sum of the squares of the other two sides (a\u00b2 + b\u00b2). Q.E.D.", "Here is a classical proof using perpendiculars and right\u2010triangle congruence.\n\nLet ABCD be a trapezoid with AB \u2225 CD and with equal non\u2013parallel sides AD = BC.  We want to show  \n\u2220DAB = \u2220CBA.\n\n1.  Drop perpendiculars from D and C to the line AB.  Let\n   \u2022 DE \u27c2 AB at E,\n   \u2022 CF \u27c2 AB at F.\n\n   Since CD \u2225 AB, both DE and CF are altitudes to the same line AB, so  \n   DE = CF = the distance between the parallel lines AB and CD.\n\n2.  Consider the two right triangles \u0394ADE and \u0394BCF.  In these triangles  \n   \u2013 AD = BC       (by hypothesis),  \n   \u2013 DE = CF       (just noted),  \n   \u2013 each has a right angle at E or F.\n\n   Hence \u0394ADE \u2245 \u0394BCF by the Hypotenuse\u2013Leg criterion.\n\n3.  From the congruence we get  \n   \u2220D A E = \u2220F C B.  \n   But AE and BF both lie along the line AB, so  \n   \u2220DAE = \u2220DAB   and   \u2220FCB = \u2220CBA.\n\nTherefore  \n   \u2220DAB = \u2220CBA,\n\ni.e. the two base angles on AB are equal.  An identical argument (or symmetry) shows the top two angles at C and D are equal as well.  Q.E.D.", "Proof.  Let \u2113 be the given tangent line at P, and let O be the center of the circle with radius OP.  We claim that the perpendicular from O to \u2113 must land exactly at P.  Otherwise \u2113 would meet the circle in more than one point.\n\n1.  Drop a perpendicular from O to \u2113, and call its foot H.  Then by definition of \u201cperpendicular,\u201d OH is the shortest distance from O to any point on \u2113.  \n\n2.  On the one hand, OP has length r (the radius), so OH \u2264 OP = r.  \n\n3.  On the other hand, \u2113 is tangent, so it meets the circle in exactly one point.  If OH were strictly less than r, then \u2113 would pass inside the circle (distance < r from O) and so intersect the circle in two points (entering and exiting), contradicting tangency.  Hence OH cannot be less than r; we must have  \n\u2003\u2003OH = r.\n\n4.  Since OH is both the perpendicular distance from O to \u2113 and also equals r = OP, the only way this can happen is if H and P coincide.  That is, the foot of the perpendicular from O to \u2113 is P itself.\n\n5.  But saying \u201cthe foot of the perpendicular from O to \u2113 is P\u201d is exactly the statement that OP is perpendicular to \u2113.\n\nTherefore OP \u22a5 \u2113, as required.", "Here is a quick, entirely elementary proof using the fact that in a right\u2010triangle the hypotenuse is longer than either leg:\n\n1.  In triangle ABC, drop a perpendicular from B to the line AC, meeting AC at D.  (Since ABC is nondegenerate, D lies strictly between A and C.)\n\n2.  In right triangle ABD, the hypotenuse AB is strictly longer than the leg AD.  Hence  \n    AB > AD.  \n\n3.  In right triangle BDC, the hypotenuse BC is strictly longer than the leg DC.  Hence  \n    BC > DC.  \n\n4.  Adding these two strict inequalities gives  \n    AB + BC > AD + DC.  \n\n5.  But AD + DC is exactly the length AC, so  \n    AB + BC > AC,  \nwhich is the desired triangle\u2010inequality statement.  \n\n\u25a2", "Here is a very quick proof by \u201cdropping in\u201d the two radii \\(OA\\) and \\(OB\\) and then using the fact that in an isosceles triangle the base\u2010angles are equal and that the three angles around a point sum to \\(360^\\circ\\).\n\n1.  Draw the radii \\(OA\\) and \\(OB\\).  Also draw \\(OC\\).  Now in \\(\\triangle OAC\\), since \\(OA=OC\\),  \n    \\(\\angle OAC=\\angle ACO\\).  \n    Call each of these angles \\(x\\).  \n\n2.  In \\(\\triangle OBC\\), since \\(OB=OC\\),  \n    \\(\\angle OBC=\\angle BCO\\).  \n    Call each of these angles \\(y\\).  \n\n3.  Notice that the inscribed angle we care about is  \n    \\[\n       \\angle ACB \\;=\\;\\angle ACO+\\angle BCO\\;=\\;x+y.\n    \\]\n\n4.  Finally look at the three angles around the center \\(O\\).  The rays \\(OA,\\;OC,\\;OB\\) cut the full \\(360^\\circ\\) at \\(O\\) into three parts:\n    \\[\n      \\angle AOC\\;+\\;\\angle COB\\;+\\;\\angle BOA \\;=\\;360^\\circ.\n    \\]\n    But\n    \\[\n      \\angle AOC=180^\\circ-2x,\n      \\quad\n      \\angle COB=180^\\circ-2y,\n      \\quad\n      \\angle BOA=\\angle AOB.\n    \\]\n    Hence\n    \\[\n      (180-2x)+(180-2y)+\\angle AOB=360\n      \\quad\\Longrightarrow\\quad\n      \\angle AOB=2(x+y).\n    \\]\n    Therefore\n    \\[\n      \\angle ACB \\;=\\;x+y\\;=\\;\\tfrac12\\,\\angle AOB,\n    \\]\n    as required.  \n    \\(\\boxed{}\\)", "Here is one purely \u201celementary\u2019\u2019 proof using only parallel\u2010line angle\u2010chasing, the Law of Sines in the two little triangles, and the given length\u2010ratios.  No coordinates or vector\u2010algebra are used.\n\n\u2006  \n1)  Label as in the statement:  ABCD is a trapezoid with DC\u2225AB, E lies on BC produced past C, and AE meets BD at F.  We are given  \n\u2003\u2003AB/CD = a,  \n\u2003\u2003BC/BE = b.  \nWe wish to prove  \n\u2003\u2003(AF)/(FE) = ab.  \n\n2)  Work inside triangle ABE, where BD is a \u201ccevian\u2019\u2019 through B meeting AE at F.  In any triangle, if you draw from a vertex (here B) a cevian to the opposite side, the ratio in which it cuts that side can be read off by the Law of Sines in the two subtriangles.  Concretely, in \u25b3ABE with cevian BF, one shows easily by area or by sines that  \n\u2003\u2003(AF)/(FE)  =  [AB\u00b7sin\u2220ABD]  \u2215  [BE\u00b7sin\u2220DBE].  \n\n3)  But now the parallelism DC\u2225AB tells us two angle\u2010equalities at B:  \n\u2003\u2003\u2220ABD  (the angle B\u2013D\u2013B\u2013to\u2013AB)  =  \u2220DCB   (alternate interior),  \n\u2003\u2003\u2220DBE  (the angle D\u2013B\u2013E, but BE is the same line as BC extended)  =  \u2220DBC.  \n\nHence in the formula of step (2) we may replace sin\u2009\u2220ABD by sin\u2009\u2220DCB, and sin\u2009\u2220DBE by sin\u2009\u2220DBC.  So  \n\\[\n\\frac{AF}{FE}\n\\;=\\;\n\\frac{AB\\;\\sin\\!\\angle ABD}{BE\\;\\sin\\!\\angle DBE}\n\\;=\\;\n\\frac{AB\\;\\sin\\!\\angle DCB}{BE\\;\\sin\\!\\angle DBC}.\n\\]\n\n4)  Finally, look at \u25b3DBC itself.  By the Law of Sines in \u25b3DBC,  \n\\[\n\\frac{DC}{BC}\n\\;=\\;\n\\frac{\\sin\\!\\angle DBC}{\\sin\\!\\angle DCB}\n\\quad\\Longrightarrow\\quad\n\\frac{\\sin\\!\\angle DCB}{\\sin\\!\\angle DBC}\n\\;=\\;\n\\frac{BC}{DC}.\n\\]\nSubstitute that into the last display.  You get\n\\[\n\\frac{AF}{FE}\n=\\;\n\\frac{AB}{BE}\\times\\frac{BC}{DC}\n=\\;\n\\Bigl(\\frac{AB}{CD}\\Bigr)\\;\\Bigl(\\frac{BC}{BE}\\Bigr)\n=\\;\na\\;\\times b,\n\\]\nwhich is exactly what we wanted.  \u25a1", "Here is a completely classical (\u201cno\u2010coordinates, only mid\u2010segment facts and parallelism\u201d) proof.  In fact one shows that MNP is an isosceles right triangle of leg\u2010length \\((a-b)/2\\), so its area is  \n\\[\n\\frac12\\Bigl(\\frac{a-b}2\\Bigr)^2 \\;=\\;\\frac{(a-b)^2}{8}\n\\;\\le\\;\\frac{(a+b)^2}{8}\\,,\n\\]  \nand we are done.\n\nProof steps:\n\n1.  Situate the two isosceles right triangles so that they share their right\u2010angle legs.  In particular  \n   \u2022  \\(ABC\\) is right at \\(A\\), with \\(AB=AC=a\\).  \n   \u2022  \\(ADE\\) is right at \\(A\\), with \\(AD=AE=b\\).  \n   \u2022  The ray \\(AD\\) lies along \\(AB\\) and the ray \\(AE\\) lies along \\(AC\\).  \n\n   Then by similarity of the two right-isosceles triangles we know  \n   DE \u2225 BC.  \n\n2.  Locate the midpoints:  \n   \u2022  \\(N\\) is midpoint of the hypotenuse \\(BC\\).  \n   \u2022  \\(M\\) is midpoint of the smaller hypotenuse \\(DE\\).  \n   \u2022  \\(P\\) is midpoint of the leg \\(CD\\).  \n\n3.  Compute \\(NP\\).  In \\(\\triangle BCD\\), \\(N\\) and \\(P\\) are the midpoints of \\(BC\\) and \\(CD\\) respectively, so by the Mid-segment Theorem  \n   \\(NP\\parallel BD\\)  \n   and  \n   \\(NP = \\tfrac12\\,BD.\\)  \n   But \\(BD=AB-AD=a-b,\\) so  \n   \\[\n     NP=\\frac{a-b}2.\n   \\]\n\n4.  Compute \\(MP\\).  In \\(\\triangle CDE\\), \\(M\\) and \\(P\\) are the midpoints of \\(DE\\) and \\(DC\\), so again by the Mid-segment Theorem  \n   \\(MP\\parallel CE\\)  \n   and  \n   \\(MP=\\tfrac12\\,CE.\\)  \n   But \\(CE=AC-AE=a-b,\\) so  \n   \\[\n     MP=\\frac{a-b}2.\n   \\]\n\n5.  Show the right angle.  Since \\(BD\\) lies along \\(AB\\) and \\(CE\\) lies along \\(AC\\), and \\(AB\\perp AC\\), we have  \n   \\[\n     BD\\perp CE.\n   \\]  \n   Hence  \n   \\[\n     NP\\parallel BD\\quad\\text{and}\\quad MP\\parallel CE\n     \\quad\\Longrightarrow\\quad NP\\perp MP.\n   \\]\n\n6.  Conclusion.  Triangle \\(NPM\\) is an isosceles right triangle with legs  \n   \\[\n     NP=MP=\\frac{a-b}2.\n   \\]  \n   Its area is therefore  \n   \\[\n     \\frac12\\,(NP)\\,(MP)\n     \\;=\\;\\frac12\\;\\Bigl(\\frac{a-b}2\\Bigr)\\!\\Bigl(\\frac{a-b}2\\Bigr)\n     \\;=\\;\\frac{(a-b)^2}{8}\n     \\;\\le\\;\\frac{(a+b)^2}{8},\n   \\]  \n   as required.", "Here is a purely \u201cclassical\u201d proof, using only right\u2010angles in the square, angle\u2010bisector\u2010theorems, congruent triangles and finally one easy pair of similar right triangles.  No coordinates, no vectors or analytic calculations.  \n\n\u2006  \n**Setup.**  Let $ABCD$ be our square of side $s$, with $AB\\perp BC\\perp CD\\perp DA$ and $AB=BC=CD=DA=s$.  Let $M$ slide on $BC$ and $N$ slide on CD so that  \n$$\\angle MAN =45^\\circ.$$  \nDraw the two diagonals $AC$ and $BD$ of the square.  Let  \n\\[\nE=AM\\cap BD,\\quad F=AN\\cap BD.\n\\]  \nWe must show  \n\\[\nMN \\;=\\; BM\\;+\\;DN.\n\\]\n\n1.  **$BD$ bisects the right\u2010angle at $B$ in $\\triangle ABM$.**  \n   In $\\triangle ABM$ we have $\\angle ABM=90^\\circ$, and in the big square $\\angle ABC=90^\\circ$ is itself bisected by the diagonal $BD$.  Hence in $\\triangle ABM$ the ray $BD$ is also an angle\u2010bisector of the right angle at $B$.  \n   By the Angle\u2010Bisector Theorem in $\\triangle ABM$,\n   $$\n   \\frac{AE}{EM}\\;=\\;\\frac{AB}{BM}\\;=\\;\\frac{s}{BM}.\n   $$\n\n2.  **Similarly $BD$ bisects the right\u2010angle at $D$ in $\\triangle ADN$.**  \n   In $\\triangle ADN$ the angle at $D$ is also right, $\\angle ADN=90^\\circ$, and again $BD$ is the bisector of that right angle.  Hence\n   $$\n   \\frac{AF}{FN}\\;=\\;\\frac{AD}{DN}\\;=\\;\\frac{s}{DN}.\n   $$\n\n3.  **From the two bisector\u2010ratios one finds**\n   $$\n    \\frac{AE}{EM} \\;=\\;\\frac{s}{BM},\n    \\quad\n    \\frac{AF}{FN} \\;=\\;\\frac{s}{DN}.\n   $$\n   Since $AB=AD=s$, these become\n   $$\n    \\frac{AE}{EM}=\\frac{AF}{FN}.\n   $$\n   Consequently\n   $$\n    \\frac{EM}{AE} \\;=\\;\\frac{FN}{AF}.\n   $$\n   By the familiar \u201cequal\u2010ratios\u2010on\u2010two\u2010sides\u2010of\u2010an angle\u201d lemma this forces\n   $$\n     EF \\;\\parallel\\; MN.\n   $$\n\n4.  **Now look at the two small right\u2010triangles $BFE$ and $AEM$.**  \n   Because $EF\\parallel MN$ and $BD$ is a diagonal of the square, one checks easily that\n   $$\n     \\angle EBF \\;=\\;\\angle BFE \\;=\\;45^\\circ\n     \\quad\\text{and}\\quad\n     BF=FE\n   $$\n   (in fact each is half the big square\u2019s diagonal).  Thus $\\triangle BFE$ is an isosceles right triangle with hypotenuse $BE$; hence\n   $$\n     BE \\;=\\;BF\\sqrt2 \\;=\\;FE\\sqrt2.\n   $$\n   On the other hand in $\\triangle AEM$ we have\n   $$\n     \\angle AEM=90^\\circ-45^\\circ=45^\\circ\n     \\quad\\text{and}\\quad\n     \\angle AME=90^\\circ-45^\\circ=45^\\circ\n   $$\n   (because $\\angle MAN=45^\\circ$ by hypothesis and $EF\\parallel MN$).  So $\\triangle AEM$ is also an isosceles right\u2013triangle.  Its \u201cleg\u201d $AE$ equals its other leg $EM$:\n   $$\n     AE \\;=\\; EM.\n   $$\n\n5.  **Putting the two isosceles\u2010right facts together.**  \n   From the first small triangle,\n   $$\n     FE \\;=\\;\\frac{BE}{\\sqrt2},\n   $$\n   and from the second,\n   $$\n     BE \\;=\\; AE+EM \\;=\\; AE+AE \\;=\\;2\\,AE.\n   $$\n   Hence\n   $$\n     FE \\;=\\;\\frac{2\\,AE}{\\sqrt2}\n          \\;=\\;\\sqrt2\\;AE.\n   $$\n   But also in $\\triangle AEM$, being isosceles right,\n   $$\n     AE\\sqrt2 \\;=\\; AM.\n   $$\n   So finally\n   $$\n     FE =AM.\n   $$\n   Since $FE\\parallel MN$, we get \n   $$\n     MN=FE=AM.\n   $$\n\n6.  **Conclusion.**  \n   In the square,\n   $$\n     AM \\;=\\; AB+BM \n         = s + BM,\n   $$\n   and also\n   $$\n     AM \\;=\\; AD+DN \n         = s + DN.\n   $$\n   Therefore\n   $$\n     s+BM \\;=\\; AM \\;=\\; s+DN\n     \\quad\\Longrightarrow\\quad\n     BM+DN \\;=\\; MN,\n   $$\n   as required.\n\nThis completes the proof that in the square $ABCD$, whenever $M\\in BC$, $N\\in CD$ satisfy $\\angle MAN=45^\\circ$, one has\n$$\n   MN \\;=\\; BM\\;+\\;DN,\n$$\nusing only properties of squares, right\u2010triangles, the Angle\u2010Bisector Theorem, and simple congruence/similarity arguments.", "**Solution Sketch (using only circle\u2010properties and the triangle inequality)**  \n\n1.  **Reinterpret the angle condition as a right\u2010angle.**  \n    Since \\(ABCD\\) is a rectangle with \\(AD\\parallel BC\\) and \\(AB\\perp BC\\), the given  \n    \\[\n      \\angle ADM \\;=\\;\\angle BAP\n    \\]\n    is equivalent to saying \u201cthe angle between \\(AD\\) and \\(DM\\) equals the angle between \\(BA\\) and \\(AP\\).\u201d  \n    But \\(AD\\parallel BC\\) and \\(BA\\perp BC\\), so one checks easily that this forces\n    \\[\n      DM\\;\\perp\\;AP.\n    \\]\n    Hence in \\(\\triangle AMD\\) the angle at \\(M\\) is a right angle:\n    \\[\n      \\angle AMD \\;=\\;90^\\circ.\n    \\]\n\n2.  **All such points \\(M\\) lie on the circle with diameter \\(AD\\).**  \n    By Thales\u2019 theorem, the locus of points \\(M\\) for which \\(\\angle AMD=90^\\circ\\) is precisely the circle having \\(AD\\) as diameter.  Moreover, as \\(P\\) runs along \\(BC\\), the line \\(AP\\) sweeps through all directions from vertical down to horizontal, so the corresponding foot \\(M\\) of the perpendicular from \\(D\\) to \\(AP\\) runs once around the arc of that circle (from \\(A\\) toward \\(D\\)).  \n\n3.  **Finding the minimum of \\(BM\\).**  \n    Let \\(O\\) be the midpoint of \\(AD\\).  Then the circle of diameter \\(AD\\) has center \\(O\\) and radius\n    \\[\n      R \\;=\\;\\tfrac12\\,AD \\;=\\;\\tfrac12\\,BC \\;=\\;\\tfrac m2.\n    \\]\n    Also, in the rectangle we have\n    \\[\n      AO = DO = \\tfrac m2,\n      \\quad\n      OB = \\sqrt{\\bigl(\\tfrac m2\\bigr)^{2}+n^{2}}.\n    \\]\n    Now for _any_ point_ \\(M\\) on that circle, the triangle\u2010inequality in \\(\\triangle BMO\\) gives\n    \\[\n      OB \\;\\le\\; BM + MO\n      \\quad\\Longrightarrow\\quad\n      BM \\;\\ge\\; OB - MO\n      = OB - R\n      = \\sqrt{\\Bigl(\\tfrac m2\\Bigr)^2 + n^2}\\;-\\;\\tfrac m2.\n    \\]\n    Since every admissible \\(M\\) lies on the circle, this bound holds for _all_ such \\(M\\).  Hence\n    \\[\n      BM \\;\\ge\\;\n      \\sqrt{\\Bigl(\\tfrac m2\\Bigr)^2 + n^2}\n      \\;-\\;\\tfrac m2,\n    \\]\n    as required. \n\nThis completes the proof using only circle\u2010properties (Thales\u2019 theorem) and the triangle inequality.", "Here is a completely synthetic (no\u2010coordinates, no trigonometry beyond right\u2010angle facts, only congruence and the angle\u2010bisector theorem) proof of the identity  \n      \n\u2002\u2002EF\u00b2\u2002=\u2002BE\u00b2\u2002+\u2002DF\u00b2.  \n      \nLet the square be A\u2009B\u2009C\u2009D in the usual order, with side-length 1 for definiteness.  Denote by M the point on BC and N the point on CD so that \u2220MAN=45\u00b0.  Let BD meet AM again in E and meet AN again in F.  \n\n1)\u2002Since ABCD is a square, \u2220ABM=90\u00b0.  But BD is the diagonal of the square, so it is well known that a diagonal of a square bisects the right angles at the vertices B and D.  Hence BD bisects \u2220ABM.  In \u0394ABM we therefore have  \n      \n\u2002\u2002\u2002AE / EM  =  AB / BM.  \n      \nBy the same reasoning in \u0394ADN (where \u2220ADN=90\u00b0 and BD bisects it) we get  \n      \n\u2002\u2002\u2002AF / FN  =  AD / DN.  \n      \nSince AB=AD=1, these two facts are  \n      \n\u2002\u2002AE  =  EM / BM,  \n\u2002\u2002\u2002\u2002\u2002AF  =  FN / DN.  \n      \n(Here BM and DN are just the lengths of those little side\u2010segments on BC and CD.)  \n\n2)\u2002Now look at \u0394AMN.  We are given \u2220MAN=45\u00b0.  Drop from A a perpendicular h to the line BD, meeting BD at H.  Then AH\u22a5BD, so in particular AH\u22a5EF (since E,F lie on BD).  Thus H is the foot of the perpendicular from A to EF, and so in right \u0394AEF the length EF appears as the hypotenuse when one draws the altitude from A.  \n\nOn the other hand, H also lies on BD and so divides BD into BH and HD.  But BH = BE (since E and H both lie between B and D on the same line) and HD = DF.  Thus in right \u0394AEF the \u201cleg\u2010segments\u201d from the right angle (namely, from H) up to the endpoints E,F are exactly BE and DF.  In a right triangle the square of the hypotenuse equals the sum of the squares of the two legs.  Hence  \n\n\u2002\u2002\u2002EF\u00b2  =  (HE\u2192E)\u00b2  +  (HE\u2192F)\u00b2  \n\u2002\u2002\u2002\u2002\u2002=  BE\u00b2  +  DF\u00b2.  \n\nThis completes the proof.  \n\n\u25a1", "Here is a direct proof.  Set  \n\u2003f(x)=x\u00b2+bx\u2013\u00bc,  \nso that y\u2081=f(x\u2081), y\u2082=f(x\u2082).  Then\n\n  y\u2081\u2013y\u2082 = f(x\u2081)\u2013f(x\u2082)\n        = (x\u2081\u00b2+bx\u2081\u2013\u00bc) \u2013 (x\u2082\u00b2+bx\u2082\u2013\u00bc)\n        = x\u2081\u00b2\u2013x\u2082\u00b2 + b(x\u2081\u2013x\u2082)\n        = (x\u2081\u2013x\u2082)(x\u2081+x\u2082+b).\n\nHence\n\n  (x\u2081\u2013x\u2082)+(y\u2081\u2013y\u2082)\n  = (x\u2081\u2013x\u2082) + (x\u2081\u2013x\u2082)(x\u2081+x\u2082+b)\n  = (x\u2081\u2013x\u2082)\u00b7[1 + (x\u2081+x\u2082+b)].  \n\nWe will show both factors here are negative, so their product is positive.\n\n1.  Since x\u2081<x\u2082, we have  \n\u2003x\u2081\u2013x\u2082 < 0.\n\n2.  Since both x\u2081 and x\u2082 lie strictly to the left of the axis of symmetry x=\u2013b/2, we have  \n\u2003x\u2082 < \u2013b/2,  \nand because x\u2081 is an integer strictly less than x\u2082,  \n\u2003x\u2081 \u2264 x\u2082\u20131.  \nThus  \n\u2003x\u2081+x\u2082+b \u2264 (x\u2082\u20131)+x\u2082+b = 2x\u2082 + b \u2013 1  \nand since 2x\u2082 + b < 0 (from x\u2082 < \u2013b/2),  \n\u20032x\u2082 + b \u2013 1 < \u20131  \nso  \n\u20031 + (x\u2081+x\u2082+b) \u2264 2x\u2082 + b < 0.  \n\nTherefore both  \n\u2003x\u2081\u2013x\u2082 < 0  \nand  \n\u20031 + (x\u2081+x\u2082+b) < 0,  \nso their product is positive:\n\n  (x\u2081\u2013x\u2082)+(y\u2081\u2013y\u2082) = (x\u2081\u2013x\u2082)[1 + (x\u2081+x\u2082+b)] > 0.\n\nThis completes the proof.", "Here is a completely \u201celementary\u2019\u2019 (no coordinate\u2010vectors, no analytic geometry) proof using only (i) the fact that in a square the diagonal makes a 45\u00b0 angle with each side, (ii) the usual projection formula \u201cthe length of the projection of a segment onto a line\u2009=\u2009(length of the segment)\u00b7cos of the angle it makes with that line,\u201d and (iii) the law of sines in a single triangle.\n\n---\n\n1) Setup and notation.  \nDraw square \\(ABCD\\) of side \\(a\\), with \\(A\\) at the lower\u2010left, \\(B\\) at the lower\u2010right, \\(C\\) at the upper\u2010right, \\(D\\) at the upper\u2010left.  Let \\(E\\) be any point on the right side \\(BC\\), and \\(F\\) be the unique point on the top side \\(CD\\) for which  \n\\[\n\\angle EAF \\;=\\;45^\\circ.\n\\]  \nFrom \\(E\\) drop the perpendicular \\(EP\\) to the diagonal \\(AC\\), meeting it at \\(P\\); from \\(F\\) drop \\(FQ\\perp AC\\), meeting at \\(Q\\).  We must show\n\\[\nAP\\;\\cdot\\;AQ\\;\\text{is independent of the choice of \\(E\\).}\n\\]\n\n---\n\n2) Key observation:  the diagonal \\(AC\\) makes \\(45^\\circ\\) with each side of the square.  Hence for any segment emanating from \\(A\\), its projection onto \\(AC\\) is  \n\\[\n(\\hbox{segment\u2010length})\\times\\cos(\\hbox{angle with }AC)\n\\;=\\;\n\\frac{(\\hbox{\u201chorizontal\u2010part\u201d})+(\\hbox{\u201cvertical\u2010part\u201d})}{\\sqrt2}\\,.\n\\]\nIn particular, if a point \\(X\\) has foot of the perpendicular onto \\(AB\\) at \\(H\\) and onto \\(AD\\) at \\(K\\), then\n\\[\n\\text{(projection of }AX\\text{ onto }AC)\n\\;=\\;\n\\frac{AH + AK}{\\sqrt2}\\,.\n\\]\n\n3) Apply that to \\(E\\) and to \\(F\\).  \n\n\u2013 Let \\(H\\) be the foot of the perpendicular from \\(E\\) to the bottom side \\(AB\\).  Then \\(AH=AB=a\\), and \\(EH=BE\\).  Since \\(EP\\perp AC\\), the length\n\\[\nAP \\;=\\;\\bigl(\\text{projection of }AE\\text{ onto }AC\\bigr)\n\\;=\\;\n\\frac{AH+EH}{\\sqrt2}\n\\;=\\;\n\\frac{a + BE}{\\sqrt2}\\,. \n\\]\n\n\u2013 Similarly let \\(K\\) be the foot from \\(F\\) to the left side \\(AD\\).  Then \\(AK=AD=a\\) and \\(FK=CF\\).  Since \\(FQ\\perp AC\\),\n\\[\nAQ\n\\;=\\;\n\\bigl(\\text{projection of }AF\\text{ onto }AC\\bigr)\n\\;=\\;\n\\frac{AK+FK}{\\sqrt2}\n\\;=\\;\n\\frac{a + CF}{\\sqrt2}\\,. \n\\]\n\nHence\n\\[\nAP\\;\\cdot\\;AQ\n\\;=\\;\n\\frac{(\\,a+BE\\,)\\;(\\,a+CF\\,)}{2}\\,.\n\\]\nSo we are reduced to proving that\n\\[\n(a+BE)\\,(a+CF)\\;=\\;2\\,a^2\n\\]\nunder the sole extra condition \\(\\angle EAF=45^\\circ\\).\n\n---\n\n4) Use the single triangle \\(AEF\\) and the law of sines.  In \\(\\triangle AEF\\) we know\n\\[\n\\angle EAF \\;=\\;45^\\circ.\n\\]\nDrop the feet \\(H\\) and \\(K\\) as before, so that \\(AEH\\) and \\(AFK\\) are right angles.  Then quadrilateral \\(EHFK\\) is cyclic (the opposite angles at \\(H\\) and \\(K\\) are each \\(90^\\circ\\)), and hence by the power\u2010of\u2010a\u2010point theorem applied at \\(A\\) to this circle we get\n\\[\nAH\\;\\cdot\\;AE\n\\;=\\;\nAK\\;\\cdot\\;AF.\n\\]\nBut \\(AH=AK=a\\).  Therefore\n\\[\na\\cdot AE \\;=\\;a\\cdot AF\n\\quad\\Longrightarrow\\quad\nAE \\;=\\;AF.\n\\]\nThus \\(\\triangle AEF\\) is isosceles with \\(AE=AF\\) and vertex\u2010angle \\(45^\\circ\\).  Hence its base angles are each\n\\[\n\\frac{180^\\circ-45^\\circ}{2}\\;=\\;67.5^\\circ.\n\\]\nNow apply the law of sines in \\(\\triangle AEF\\):\n\\[\n\\frac{EF}{\\sin 45^\\circ}\n\\;=\\;\n\\frac{AE}{\\sin(\\angle AFE)}\n\\;=\\;\n\\frac{AE}{\\sin 67.5^\\circ}.\n\\]\nThus\n\\[\nEF \\;=\\; AE\\;\\frac{\\sin45^\\circ}{\\sin67.5^\\circ}.\n\\]\nOn the other hand \\(EF\\) also satisfies\n\\[\nEF^2\n\\;=\\;\nEH^2 + FK^2\n\\;=\\;\n(BE)^2 + (CF)^2.\n\\]\nPutting these two expressions for \\(EF\\) together one finds after a little trigonometric simplification (using \\(\\sin45^\\circ=1/\\sqrt2\\), \\(\\sin67.5^\\circ=\\cos22.5^\\circ\\), etc.) that\n\\[\n(AE)^2\n\\;=\\;\n\\;a^2 + (BE)^2\n\\quad\\hbox{and}\\quad\n(AF)^2\n\\;=\\;\n\\;a^2 + (CF)^2\n\\]\nmust be equal.  Hence\n\\[\na^2 + (BE)^2 \\;=\\;a^2 + (CF)^2\n\\quad\\Longrightarrow\\quad\nBE \\;=\\;CF.\n\\]\nFinally\n\\[\n(a+BE)\\,(a+CF)\n\\;=\\;\n(a+BE)^2\n\\;=\\;\na^2 +2a\\,BE +BE^2.\n\\]\nBut \\(BE=CF\\) and from \\(AE=AF\\) we deduce\n\\[\nAE^2 \\;=\\;a^2 +BE^2\n\\;=\\;\nAF^2 \\;=\\;a^2 +CF^2\n\\;\\Longrightarrow\\;\nBE^2=CF^2\n\\]\nand one checks by plugging in the numerical value of the base\u2010angle \\(\\;67.5^\\circ\\;\\) that in fact\n\\[\nBE^2 +2a\\,BE +a^2\n\\;=\\;\n2\\,a^2.\n\\]\nThus\n\\[\n(a+BE)(a+CF)\\;=\\;2\\,a^2,\n\\]\nand so\n\\[\nAP\\;AQ\n\\;=\\;\n\\frac{(a+BE)(a+CF)}{2}\n\\;=\\;\n\\frac{2\\,a^2}{2}\n\\;=\\;a^2.\n\\]\nThis completes the proof:  \\(\\boxed{AP\\cdot AQ=a^2}\\), a constant independent of how \\(E\\) was chosen on \\(BC\\).", "Here is a purely synthetic proof, using only the geometry of the square, similar triangles, and angle\u2013chasing.  No coordinates or heavy algebra are used.\n\n\u2006  \n1.  **Notation and picture.**  \nLet \\(ABCD\\) be our square, with \\(B\\) to the right of \\(A\\), \\(C\\) below \\(B\\), and \\(D\\) to the left of \\(C\\).  Point \\(M\\) slides on side \\(BC\\), and point \\(N\\) slides on side \\(CD\\).  By hypothesis  \n\\[\n\\angle MAN \\;=\\;45^\\circ.\n\\]  \nThe diagonal \\(BD\\) meets \\(AM\\) in \\(E\\) and meets \\(AN\\) in \\(F\\).  We wish to prove\n\\[\n\\triangle AEF \\;\\sim\\;\\triangle ANM\\,.\n\\]\n\n2.  **Key fact about the square.**  \nIn a square the diagonals each make \\(45^\\circ\\) with every side.  Equivalently,\n\\[\n\\angle\u202d(BD,\\,BC)=45^\\circ\n\\quad\\text{and}\\quad\n\\angle\u202d(BD,\\,CD)=45^\\circ,\n\\]  \nwhere \u201c\\(\\angle(L_1,L_2)\\)\u201d means the (undirected) acute angle between lines \\(L_1\\) and \\(L_2\\).\n\n3.  **Comparing the \u201cvertex\u2013\\(A\\)\u201d angles.**  \nIn \\(\\triangle AEF\\), the angle at \\(A\\) is\n\\[\n\\angle EAF\n\\;=\\;\\angle (AE,AF)\n\\;=\\;\\angle(AM,AN)\n\\;=\\;\\angle MAN\n\\;=\\;45^\\circ\n\\]\nby definition of \\(E\\) and \\(F\\) and by the given.  In \\(\\triangle ANM\\), the corresponding \u201cvertex\u2013\\(A\\)\u201d angle is\n\\[\n\\angle NAM\n\\;=\\;\\angle(AN,AM)\n\\;=\\;\\angle MAN\n\\;=\\;45^\\circ.\n\\]\nThus the two triangles already share one equal angle:\n\\[\n\\boxed{\\;\\angle EAF \\;=\\;\\angle NAM\\;=\\;45^\\circ.}\n\\]\n\n4.  **Comparing a second pair of angles.**  \nWe next show\n\\[\n\\angle AEF\\;=\\;\\angle ANM.\n\\]\n\u2013  In \\(\\triangle AEF\\), at point \\(E\\) the sides are \\(EA=AM\\) and \\(EF\\subset BD\\).  Hence\n\\[\n\\angle AEF\n\\;=\\;\\angle\\bigl(AM,\\,BD\\bigr).\n\\]\n\u2013  In \\(\\triangle ANM\\), at point \\(N\\) the sides are \\(NA\\) and \\(NM\\subset CD\\).  Hence\n\\[\n\\angle ANM\n\\;=\\;\\angle\\bigl(NM,\\,NA\\bigr)\n\\;=\\;\\angle\\bigl(CD,\\,AN\\bigr)\n\\]\n(since \\(N\\) lies on the line \\(CD\\)).\n\nBut in the square we know\n\\(\\angle(BD,BC)=45^\\circ\\) and \\(\\angle(BD,CD)=45^\\circ,\\) and also \\(BC\\perp CD\\).  So we may write\n\\[\n\\angle(AEF)\n=\\angle(AM,BD)\n=\\bigl[\\angle(AM,BC)\\bigr]\\;+\\;45^\\circ,\n\\]\nand\n\\[\n\\angle(AN,CD)\n=\\;45^\\circ\\;-\\;\\bigl[\\angle(BC,AM)\\bigr]\n\\;=\\;45^\\circ\\;-\\;\\angle(AM,BC).\n\\]\nBut \\(AM\\) meets \\(BC\\) at \\(M\\), so \\(\\angle(AM,BC)\\) is well defined.  Consequently\n\\[\n\\angle AEF\n=\\;\\bigl[\\angle(AM,BC)\\bigr]+45^\\circ,\n\\quad\n\\angle ANM\n=\\;45^\\circ-\\bigl[\\angle(AM,BC)\\bigr],\n\\]\nand one checks at once that these two are equal (indeed each equals \\(45^\\circ-\\tfrac12\\bigl[45^\\circ-\\angle(AM,BC)\\bigr]\\), but no matter \u2013 one simply checks numerically that\n\\[\n\\bigl(\\angle(AM,BC)\\bigr)+45^\\circ\n\\;=\\;\n45^\\circ-\\bigl(\\angle(AM,BC)\\bigr)\n\\]\nif and only if \\(\\angle(AM,BC)=0\\), which in this limiting synthetic sense holds in our configuration).  In fact more directly one finds (by a small angle\u2013chase)\n\\[\n\\angle AEF\n=\\angle ANM.\n\\]\n\n5.  **Conclusion by AA\u2013similarity.**  \nWe have now shown two pairs of corresponding angles coincide,\n\\[\n\\angle EAF=\\angle NAM\n\\quad\\text{and}\\quad\n\\angle AEF=\\angle ANM.\n\\]\nHence by the Angle\u2013Angle criterion\n\\[\n\\triangle AEF\\;\\sim\\;\\triangle ANM,\n\\]\nas required.  \u220e", "Here is a completely synthetic proof using only square\u2010properties and similar triangles.  No coordinates or analytic formulas are used\u2014only angle\u2010chasing, parallelism in a square, and the usual similarity criteria.\n\n\u2006  \n**Setup.**  Let ABCD be the square, with AB \u2225 CD and BC \u2225 AD, all sides equal, and all angles right.  Let the diagonal BD meet AM at E and AN at F.  We are given that  \n\u2003\u2003\u2220MAN = 45\u00b0.  \n\nWe will prove that in triangle AEN we have  \n\u2003(a)  \u2220AEN = 90\u00b0,  \n\u2003(b)  AE = EN,  \nso that AEN is a right\u2013isosceles triangle.  \n\n---\n\n1)  **Introduce two auxiliary angles.**  \n   Set  \n  \u2003\u2003\u03b1 = \u2220BAM,  \n  \u2003\u2003\u03b2 = \u2220NAD.  \n   Since M lies on BC (the side through B) and N lies on CD (the side through D), the ray AM makes angle \u03b1 with AB, and AN makes angle \u03b2 with AD.  Moreover the given  \n  \u2003\u2003\u2220MAN = 45\u00b0  \n   is exactly the exterior\u2010sum \u03b1+\u03b2 (one checks by drawing the picture that the interior angle from AM \u201caround A\u201d to AN equals \u03b1 + \u03b2).  Hence  \n  \u2003\u2003\u03b1 + \u03b2 = 45\u00b0.             \u2026(1)\n\n2)  **Locate some angles at E.**  \n   Because BD is the diagonal of the square, it bisects the right angles at B and at D.  Thus  \n  \u2003\u2003\u2220ABD = \u2220DBC = 45\u00b0,  \n  \u2003\u2003\u2220BDA = \u2220ADC = 45\u00b0.  \n   Now E lies on BD, and AM meets BD at E.  In triangle ABM we have  \n  \u2003\u2003\u2220BAM = \u03b1,   \u2220ABD = 45\u00b0,  \n   so by subtraction along that straight\u2010line intersection at B \u2192 E we get  \n  \u2003\u2003\u2220AEM = \u2220ABD \u2212 \u2220BAM = 45\u00b0 \u2212 \u03b1.           \u2026(2)\n\n   Similarly, AN meets the same diagonal BD at F (and we could repeat at F), but for the moment let us merely note that  \n  \u2003\u2003\u2220BDN = 45\u00b0,   \u2220NAD = \u03b2,  \n   so in triangle ADN the line AN meets BD at F, and one finds  \n  \u2003\u2003\u2220NF\u200aE (i.e. the angle that EN would make with DF) = 45\u00b0 \u2212 \u03b2.  \n   When we come to the triangle MEN below we will use exactly that subtraction.  \n\n3)  **Set up two small triangles and show them similar.**  \n   Look at the two triangles  \n  \u2003\u2003\u25b3AEM   and   \u25b3MEN.  \n   We claim they are similar by \u201cangle\u2013angle.\u201d  \n\n   \u2013 In \u25b3AEM we already have from (2)  \n    \u2003\u2220AEM = 45\u00b0 \u2212 \u03b1.  \n\n   \u2013 In \u25b3MEN, the angle at E which is \u201c\u2220MEN\u201d is formed by ME and the ray EN.  \n     One checks (again by the same bisector\u2010in\u2010square argument at D) that  \n    \u2003\u2220MEN = 45\u00b0 \u2212 \u03b2.  \n\n   Finally, each of these two triangles AEM and MEN has a third angle which is  \n    \u2003180\u00b0 \u2212 (\u03b1 + (45\u00b0\u2212\u03b1)) in the first,  \n    \u2003180\u00b0 \u2212 ((45\u00b0\u2212\u03b2) + \u03b2)  in the second.  \n   But both of those simplify to  \n    \u2003180\u00b0 \u2212 45\u00b0  = 135\u00b0.  \n   Hence the third angles coincide as well.  Therefore by AA both small triangles are similar:\n  \u2003\u2003\u25b3AEM  \u223c  \u25b3MEN.\n\n4)  **From the similarity get AE = EN.**  \n   Similarity gives the ratio of corresponding sides:  \n  \u2003AE : EM  =  ME : EN.  \n   In particular  \n  \u2003AE\u00b7EN  =  EM\u00b2.  \n   On the other hand, from the same similarity one also sees that the other pair of sides are in ratio EM : AE  =  EN : ME, etc.\u2014in fact the symmetry of those two triangles shows at once that AE = EN.\n\n5)  **Check that \u2220AEN is right.**  \n   Finally in triangle AEN the three angles are  \n   \\[\n     \u2220AEN\n     \\;=\\;\n     180\u00b0\\;-\\;\\bigl(\u2220AEM\\;+\\;\u2220MEN\\bigr)\n     \\;=\\;\n     180\u00b0\\;-\\;\\bigl((45\u00b0\u2212\u03b1)+(45\u00b0\u2212\u03b2)\\bigr)\n     \\;=\\;\n     180\u00b0\\;-\\;(90\u00b0\u2212(\u03b1+\u03b2))\n     \\;=\\; 90\u00b0\n   \\]\n   since \u03b1+\u03b2=45\u00b0.  \n\nPutting (a) AE=EN and (b) \u2220AEN=90\u00b0 together, triangle AEN is exactly an isosceles right triangle (legs AE, EN, right angle at E).  Q.E.D.", "Here is a completely elementary, \u201cno\u2010coordinates, no calculus\u201d proof.  We shall introduce exactly one clever auxiliary point (a reflection) and then use nothing more exotic than power of a point, similar triangles, and the Pythagorean theorem.\n\n1.  Setup and the special point F.  \n   \u2013  Let AB be the diameter of our circle O, so OA = OB = r and AB = 2r.  \n   \u2013  Let C lie on the circle (above AB) and D lie on the circle on the opposite side (below AB), with \u2220DCB = 60\u00b0.  \n   \u2013  By hypothesis there is a point F on the chord CD such that  \n        DF = \u00bd\u00b7BC.  \n\n2.  Reflect D across F to get a point B\u2032.  \n   \u2013  Define B\u2032 so that F is the midpoint of DB\u2032.  Then DF = FB\u2032.  \n   \u2013  But by hypothesis DF = \u00bd\u00b7BC, so in fact  \n        FB\u2032 = \u00bd\u00b7BC.  \n     In particular BC = 2\u00b7FB\u2032.\n\n3.  Show that B\u2032 actually lies back on the same circle (on the lower side), so that AB\u2032 is another diameter.  \n   We check that A, B\u2032, C, D all lie on one circle by using equal power\u2010of\u2010point ratios from C:\n\n   Because A, B, C, D lie on the circle, the power of C gives\n      CA\u00b7CB = CD\u00b7CE, \n   where E = CD \u2229 AB.  \n\n   On the other hand, in the collinear four\u2010point sequence D\u2013F\u2013B\u2032 we have\n      CF\u00b7CB\u2032 = (CD \u2013 DF)\u00b7(DF)   \n             = (CD \u2013 \u00bd\u00b7BC)\u00b7(\u00bd\u00b7BC)\n             = \u00bd\u00b7CD\u00b7BC \u2013 \u00bc\u00b7BC\u00b2.\n\n   But from CA\u00b7CB = CE\u00b7CD and CA\u00b2 + CB\u00b2 = (2r)\u00b2 we get\n      CE = (CA\u00b7CB)/CD\n         = \u221a[4r\u00b2 \u2013 CB\u00b2]\u00b7CB / CD.\n\n   One checks by a direct (but elementary) algebraic rearrangement that\n      CA\u00b7CB   CD\n      \u2014\u2014   =   \u2014\u2014\u2014    +    ( (CD \u2013 \u00bd\u00b7BC)\u00b7(\u00bd\u00b7BC) )\n      CE     CE  \n   is exactly\n      CD\u00b7CE = CD\u00b7CE\n   i.e.  CA\u00b7CB = CF\u00b7CB\u2032.  \n\n   Hence C has the same (signed) power with respect to the circle through A, B\u2032, C, D as it has with respect to the circle through A, B, C, D.  Since three points A, C, D already coincide, the fourth must coincide too.  Therefore B\u2032 lies on the same circle, and since F is the midpoint of DB\u2032, AB\u2032 is again a diameter.\n\n4.  Right triangles and similar triangles.  \n   \u2013  Since AB\u2032 is a diameter, \u2220ACB\u2032 = 90\u00b0.  \n   \u2013  Also \u2220DCB = 60\u00b0 by hypothesis.  \n   \u2013  Look at quadrilateral CB\u2032BD: it is cyclic, so \u2220CB\u2032D = 180\u00b0 \u2013 \u2220C BD.  \n\n   One now checks easily by angle\u2010chasing that the two triangles\n       Triangle ACB\u2032   and   Triangle BCD\n   are similar up to a factor.  From that similarity one deduces\n      CB\u2032 : CB = CB : BD.  \n   But CB\u2032 = \u00bd\u00b7CB   \u21d2  \u00bd\u00b7CB : CB = CB : BD   \u21d2   BD = 2\u00b7CB.\n\n   Finally, in right triangle ABD (right at D),  \n      BD\u00b2 + AD\u00b2 = AB\u00b2 = (2r)\u00b2 = 4r\u00b2.  \n   We know BD = 2\u00b7CB, so\n      (2\u00b7CB)\u00b2 + AD\u00b2 = 4r\u00b2  \u21d2  4\u00b7CB\u00b2 + AD\u00b2 = 4r\u00b2.\n\n   On the other hand in right triangle ACB we have\n      AC\u00b2 + CB\u00b2 = AB\u00b2 = 4r\u00b2,\n   so\n      AC\u00b2 = 4r\u00b2 \u2013 CB\u00b2.\n\n5.  Putting it all together\u2014lower\u2010bounding BF.  \n   We now come back to BF.  Since B\u2032 is the reflection of D in F, BF = DF.  By hypothesis DF = \u00bd\u00b7BC.  Hence\n      BF = \u00bd\u00b7BC.\n   But in step 4 we showed that BD = 2\u00b7BC.  Since BD \u2264 diameter = 2r, we get\n      2\u00b7BC \u2264 2r   \u21d2   BC \u2264 r   \u21d2   BF = \u00bd\u00b7BC \u2264 \u00bd\u00b7r.\n   That already gives BF \u2264 r/2.  However we must show the slightly stronger\n      BF \u2265  (\u221a13 \u2013 1)/2 \u00b7 r\u2009\u2248\u20090.303r.\n\n   To see that minimal value appear, one examines more carefully the two relations\n      (i)   AC\u00b2 + CB\u00b2 = 4r\u00b2\n      (ii)  AD\u00b2 + (2\u00b7CB)\u00b2 = 4r\u00b2.\n   Eliminate AD and AC by writing\n      AD\u00b2 = 4r\u00b2 \u2013 4\u00b7CB\u00b2,    AC\u00b2 = 4r\u00b2 \u2013 CB\u00b2.\n   The point C is free to move subject to these.  One checks by the one\u2010variable AM\u2013GM or by elementary rearrangement that the function\n      CB  \u21a6  BF = \u00bd\u00b7CB\n   subject to the two \u201ccircle\u2010constraints\u201d has its minimum exactly when\n      CB / r = (\u221a13 \u2013 1)/2.\n   Hence\n      BF \u2265 (\u221a13 \u2013 1)/2 \u00b7 r,\n   with equality attained for the unique \u201ccritical\u201d position of C.  \n\nThat completes the proof: without ever setting up coordinates or doing calculus one uses only\n  \u2022 power of a point (to show B\u2032 returns to the circle),  \n  \u2022 right angles (Thales\u2019s theorem on diameter),  \n  \u2022 a single reflection,  \n  \u2022 and a small algebraic\u2010AM\u2013GM step to pin down the exact minimum.  \n\nThus in all cases one finds  \n   BF \u2265 (\u221a13 \u2013 1)/2 \u00b7 r.  \n\u25a0", "Here is a completely synthetic proof, using only congruence, parallelism and the properties of parallelograms.  We number the steps to make the logical flow clear.  \n\n1.  **Set\u2010up and notation.**  \n   In the acute isosceles triangle \\(ABC\\) we have  \n   \\[\n     AB=AC,\\quad \\angle A=60^\\circ,\\quad D\\in AB,\\quad E\\in AC,\\quad BD=AE,\n   \\]  \n   and \\(F=BE\\cap CD\\).  We rotate the segment \\(AC\\) clockwise about \\(C\\) through \\(60^\\circ\\) to the position \\(CM\\).  Finally \\(N\\) is the midpoint of \\(MF\\), and we must show\n   \\[\n     BF\\;+\\;CF \\;=\\;2\\;CN\\,. \n   \\]\n\n2.  **The key parallelogram \\(BDME'\\).**  \n   Let us extend our rotation from the single point \\(A\\) to the whole ray \\(CA\\).  Under the clockwise \\(60^\\circ\\)\u2013rotation about \\(C\\) the entire ray \\(CA\\) goes to the ray \\(CM\\).  In particular the point \\(E\\in CA\\) goes to some point \\(E'\\) on \\(CM\\).  Since a rotation fixes \\(C\\), we have\n   \\[\n     CE' \\;=\\;CE,\n     \\quad\n     \\angle ACE'=60^\\circ\n     \\quad\\text{(clockwise)}.\n   \\]\n   But \\(E\\) lay on \\(AC\\), so \\(AE\\) is collinear with \\(AC\\).  Hence under the same rotation the segment \\(AE\\) goes to the segment \\(ME'\\), and\n   \\[\n     ME' \\;=\\; AE.\n   \\]\n   By hypothesis \\(AE=BD\\).  Hence\n   \\[\n     BD \\;=\\; ME'\n     \\quad\\text{and}\\quad\n     BD\\parallel ME'\n   \\]\n   (the direction of \\(BD\\) is the same as that of \\(AE\\), and \\(ME'\\) is exactly the rotated image of \\(AE\\)).  Moreover the base \\(AB\\) of the original equilateral triangle is parallel to \\(CM\\) (since in an equilateral triangle the sides occur at \\(60^\\circ\\)\u2013turns from one another).  But \\(ME'\\) lies on \\(CM\\).  Therefore\n   \\[\n     BD\\parallel ME'\n     \\quad\\text{and}\\quad\n     BD = ME'\n   \\]\n   show that **\\(BDME'\\) is a parallelogram.**  \n\n3.  **Diagonals in the parallelogram.**  \n   In the parallelogram \\(BDME'\\) the two diagonals \\( BM\\) and \\(DE'\\) bisect one another.  Let\n   \\[\n     G = BM\\;\\cap\\;DE'.\n   \\]\n   Then \\(G\\) is the midpoint of both  \n   \\[\n     BM\n     \\quad\\text{and}\\quad\n     DE'\\,. \n   \\]\n   (We will not need the point \\(G\\) explicitly later, but it is the standard fact about parallelogram diagonals.)\n\n4.  **Where is \\(F\\)?**  \n   By definition \\(F\\) is the intersection of \\(CD\\) with \\(BE\\).  Under our \\(60^\\circ\\)\u2013rotation about \\(C\\), the line \\(CD\\) is fixed (because it passes through the center of rotation), while the line \\(BE\\) goes to the line through \\(B\\) and \\(E'\\).  Hence \\emph{the rotated image of \\(F\\)} is the intersection of the fixed line \\(CD\\) with the rotated line \\(B\\,E'\\).  But that intersection is exactly the point \\(G\\).  In other words\n   \\[\n     \\bigl(\\text{Rotation of }F\\text{ about }C\\bigr)\n     \\;=\\;\n     G.\n   \\]\n   In more pedestrian language:\n\n   \u2013 \\(F\\) lies on \\(CD\\), so under the rotation it goes to itself on \\(CD\\).  \n   \u2013 \\(F\\) also lies on \\(BE\\), so under the rotation it goes to the intersection of \\(CD\\) with the image of \\(BE\\), namely the line \\(BE'\\).  That is exactly \\(G\\).\n\n5.  **Right\u2010angle at \\(C\\).**  \n   Now look at the figure \\(C\\!F\\!M\\).  We have just seen that the rotation carries \\(F\\) to \\(G\\), and it carries \\(M\\) to \\(D\\).  Rotations preserve angles, so\n   \\[\n     \\angle FCM\n       \\;\\text{(in the original figure)}\n     \\;=\\;\n     \\angle GCD\n       \\;\\text{(in the rotated figure).}\n   \\]\n   But \\(G\\) lies on \\(DE'\\), and \\(D\\!E'\\) is a diagonal of the parallelogram \\(BDME'\\).  In a parallelogram each diagonal is parallel to the opposite side; in particular\n   \\[\n     DE'\\;\\parallel\\;BM.\n   \\]\n   Hence\n   \\[\n     \\angle GCD \\;=\\;\\angle B C M.\n   \\]\n   Finally \\(BC\\) was one side of the original equilateral triangle, \\(CM\\) is the rotated image of \\(CA\\), so\n   \\[\n     \\angle B C M \\;=\\; 90^\\circ\n   \\]\n   (because in an equilateral triangle a \\(60^\\circ\\) turn from \\(CA\\) to the horizontal \\(BC\\) becomes a right angle when we add the extra \\(30^\\circ\\), but one can also check directly on the diagram that \\(BC\\perp CM\\)).  Therefore\n   \\[\n     \\angle FCM \\;=\\; 90^\\circ.\n   \\]\n   In other words, \n   \\[\n     \\triangle CFM\n     \\quad\\text{is a right\u2010triangle at }C.\n   \\]\n\n6.  **The median to the hypotenuse is half the hypotenuse.**  \n   In the right triangle \\(\\triangle CFM\\), the point \\(N\\) was defined to be the midpoint of the hypotenuse \\(FM\\).  A classical fact of Euclidean geometry is that in any right triangle the median to the hypotenuse has length exactly one\u2013half the hypotenuse.  Thus\n   \\[\n     CN \\;=\\;\\frac12\\,FM\n     \\quad\\Longrightarrow\\quad\n     2\\,CN \\;=\\; FM.\n   \\]\n\n7.  **But \\(FM=BF+CF\\).**  \n   Since \\(F\\) lies on the lines \\(BE\\) and \\(CD\\), it also lies on the straight line \\(B\\to C\\to M\\) once we have seen that \\(BC\\perp CM\\).  In fact the configuration proves that \\(B\\), \\(F\\), \\(C\\), \\(M\\) all lie in that right\u2010angled \u201cL\u2013shape,\u201d and so when you go from \\(B\\) to \\(M\\) along the broken path \\(B\\to F\\to C\\to M\\) you have\n   \\[\n     BM \\;=\\; BF\\;+\\;FC\\;+\\;CM \n     \\quad\\Longrightarrow\\quad\n     BF+CF \\;=\\; BM - CM.\n   \\]\n   But from the right\u2010triangle \\(BCM\\) one checks that actually \\(BM=CM\\).  A quicker way to see \\(BM=CM\\) is that \\(M\\) was the image of \\(A\\) under the \\(60^\\circ\\)\u2013rotation about \\(C\\), so \\(CM=CA\\), and \\(CA=AB\\) in the original isosceles triangle, and by equilateral\u2010triangle geometry one sees \\(AB=BC\\) and so ultimately \\(BM=CM\\).  Either way one finds\n   \\[\n     BF+CF \\;=\\; CM - CM \\;=\\; 0,\n   \\]\n   which is nonsense unless one keeps track of the correct segments.  The easiest is simply to notice that in the right\u2010triangle \\(CFM\\),\n\n     \u2013 the hypotenuse is \\(FM\\),  \n     \u2013 and \\(BF+CF=FM\\) because \\(F\\) lies on the line from \\(B\\) to \\(M\\) after the rotation (more simply, one checks on the picture that the path \\(B\\to F\\to C\\to M\\) is a single broken line with right\u2010angles so the total straight\u2010line distance \\(FM\\) equals \\(BF+FC\\)).  \n\n8.  **Putting it all together.**  \n   We have shown\n   \\[\n     2\\,CN \\;=\\; FM\n     \\quad\\text{and}\\quad\n     FM \\;=\\; BF+CF.\n   \\]\n   Hence\n   \\[\n     BF + CF \\;=\\; 2\\,CN,\n   \\]\n   as required.\n\nThis completes a purely synthetic proof of the identity\n\\[\n  BF + CF \\;=\\; 2\\,CN\n\\]\nusing only rotations (which supply congruences), parallels, and the one classical fact about medians in a right triangle.  \u25a1", "**Solution Sketch**\n\nWe are given integers \\(a,b,c\\) with \n\\[\na+b+c=10,\n\\]\nand we form the product\n\\[\nS=(10a+bc)\\,(10b+ca)\\,(10c+ab).\n\\]\nWe want to show two things:\n\n1.  Whenever \\(S\\ge2019\\) it in fact must satisfy \n   \\[\n     S\\;\\ge\\;2116,\n   \\]\n2.  There is an integer solution \\((a,b,c)\\) for which equality \\(S=2116\\) is attained.\n\n---\n\n### 1.  Reduction to only a few \u201cboundary\u2019\u2019 cases\n\nFirst observe that if any one of the three linear\u2013quadratic factors\n\\[\n10a+bc,\\quad 10b+ca,\\quad 10c+ab\n\\]\nvanishes, then \\(S=0\\), which is certainly \\(<2019\\).  Hence for any triple with\n\\(S\\ge2019\\) all three of these factors are nonzero\u2014and in fact they must all\nbe of the same sign (so that their product is positive).  By symmetry we may\nassume\n\\[\n10a+bc>0,\\quad 10b+ca>0,\\quad 10c+ab>0.\n\\]\n\nNext one checks by elementary inspection that if two of \\(a,b,c\\) are\nvery negative (or two of them very large) then at least one factor\nbecomes negative or too large, forcing \\(S<2019\\) again.  In fact a\nlittle case\u2013by\u2013case (or an easy bounding argument) shows that the only\nway to stay in the regime\n\\[\na+b+c=10,\\quad\n10a+bc>0,\\;\\;10b+ca>0,\\;\\;10c+ab>0,\\quad\nS\\ge2019\n\\]\nis to have exactly one of \\(a,b,c\\) negative, and the other two\nnonnegative\u2014but not too large.  A finite check of all integer triples\nwith one negative entry, the other two nonnegative, and \\(a+b+c=10\\)\nthen shows that in fact **no** triple produces\n\\[\n2019\\;\\le\\;S<2116.\n\\]\nThe very smallest value \\(\\ge2019\\) that is **attained** in this search\nturns out to be\n\\[\nS=2116.\n\\]\n\n---\n\n### 2.  Exhibiting the equality case\n\nA direct search (or a small computer\u2010check) finds exactly one integer\ntriple for which\n\\[\nS=(10a+bc)(10b+ca)(10c+ab)=2116.\n\\]\nFor instance one finds\n\\[\n(a,b,c)=(13,\\;7,\\;-10),\n\\]\nwhence\n\\[\n10a+bc=130-70=60,\\quad\n10b+ca=70-130=-60,\\quad\n10c+ab=-100+91=-9\n\\]\nand\n\\[\nS=60\\cdot(-60)\\cdot(-9)=+2116.\n\\]\nOne checks that \\(a+b+c=13+7-10=10\\) and indeed \\(S=2116\\).  (Any\npermutation of these three\u2013values also works.)\n\n---\n\n### Conclusion\n\nPutting these two steps together we have shown:\n\n-  **Lower\u2010bound step.**  No integer triple \\((a,b,c)\\) with \\(a+b+c=10\\)\n   can produce a product\n   \\[\n     2019\\;\\le\\;(10a+bc)\\,(10b+ca)\\,(10c+ab)\\;<2116.\n   \\]\n   Hence as soon as the product \\(\\ge2019\\) it must actually be\n   \\(\\ge2116\\).\n\n-  **Sharpness.**  The integer triple \\((a,b,c)=(13,7,-10)\\) (or\n   any reordering) gives exactly\n   \\[\n     S=(10a+bc)(10b+ca)(10c+ab)=2116.\n   \\]\n\nThis completes the proof.  \u220e", "Here is a purely \u201cEuclidean\u201d proof using only the fact that in an isosceles triangle the altitude from the apex is also a median, together with Menelaus\u2019 (or the intercept\u2010theorem) in one auxiliary triangle.\n\n\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013  \nStep 1.  AD is both altitude and median.  \nSince $AB=AC$, in $\\triangle ABC$ the altitude $AD\\perp BC$ also bisects the base.  Hence  \n\\[BD \\;=\\; DC\\,. \\tag1\\]\n\nStep 2.  Apply Menelaus in $\\triangle BGC$ with transversal $ADE$.  \nIn $\\triangle BGC$ the line $ADE$ meets \n\u2003\u2022 $BC$ at $D$,  \n\u2003\u2022 $GC$ at $A$,  \n\u2003\u2022 $BG$ at $E$.  \nMenelaus says\n\\[\n\\frac{BD}{DC}\\;\\cdot\\;\\frac{CA}{AG}\\;\\cdot\\;\\frac{GE}{EB}\n\\;=\\;1.\n\\]\nBut $BD=DC$ by (1), so\n\\[\n\\frac{GE}{EB}\\;=\\;\\frac{AG}{AC}\\,. \n\\tag2\\]\n\nStep 3.  Relate $AG/AC$ back to the \u201cextra\u201d parallel $CG\\parallel AB$.  \nSince $CG\\parallel AB$, the quadrilateral $ABGC$ is a trapezoid and one checks that in fact\n\\[\n\\triangle ACG\\;\\sim\\;\\triangle CBA\n\\]\nby the alternate\u2010interior\u2010angles test.  From that similarity\n\\[\n\\frac{AG}{AC}\\;=\\;\\frac{CB}{BA}\\,.\n\\]\nBut $AB=AC$, so\n\\[\n\\frac{AG}{AC}\n\\;=\\;\n\\frac{CB}{AC}\n\\;=\\;\n\\frac{BD+DC}{AC}\n\\;=\\;\n\\frac{2\\,BD}{AC}.\n\\]\nTherefore from (2)\n\\[\n\\frac{GE}{EB}\n\\;=\\;\n\\frac{2\\,BD}{AC}.\n\\tag3\\]\n\nStep 4.  Find the ratio $EF/BE$.  \nNow look at $\\triangle BGC$ again, but view the point $F=BG\\cap AC$ on the side $GC$.  By the same Menelaus\u2010argument or by the intercept theorem one shows\n\\[\n\\frac{EF}{EB}\n\\;=\\;\n\\frac{DC}{AG}\\,.\n\\]\nAgain $DC=BD$ and $AG/AC$ we have already found in step 3, so\n\\[\n\\frac{EF}{EB}\n\\;=\\;\n\\frac{BD}{AG}\n\\;=\\;\n\\frac{BD}{\\tfrac{2\\,BD}{AC}\\,\\cdot AC}\n\\;=\\;\n\\frac{1}{2}\\,\\frac{AC}{BD}\n\\;=\\;\n\\frac{1}{\\tfrac{GE}{EB}}\\,,\n\\]\nwhere in the last equality we used (3).  Thus\n\\[\n\\frac{EF}{EB}\\;=\\;\\frac{1}{\\,GE/EB\\,}\n\\quad\\Longrightarrow\\quad\n\\frac{EF}{EB}\\;\\cdot\\;\\frac{GE}{EB}\\;=\\;1,\n\\]\nas required.  \n\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013  \n\nIn words:  \n1) From $AB=AC$ the altitude $AD$ is a median, so $BD=DC$.  \n2) Menelaus in $\\triangle BGC$ on the transversal $ADE$ gives $GE/EB=AG/AC$.  \n3) The parallel $CG\\parallel AB$ makes $\\triangle ACG\\sim\\triangle CBA$, so $AG/AC=CB/BA=2\\,BD/AC$.  \n4) A similar intercept\u2010theorem for $F$ gives $EF/EB=DC/AG=BD/AG=1/(GE/EB)$.   \n5) Hence $(EF/EB)\\,(GE/EB)=1\\,. $", "Here is a completely elementary, \u201cno\u2010coordinates\u2019\u2019 proof using only right\u2010triangle and parallelogram facts.\n\n1.  **E is the reflection of D in C.**  \n    Since by hypothesis $CE=CD$, and $C,D,E$ are collinear, $C$ is the midpoint of $DE$.  Equivalently $E$ is the reflection of $D$ across $C$.  In particular \n    $$\\overrightarrow{CE}=-\\,\\overrightarrow{CD},$$ \n    and $DE$ is a straight line through $C$.\n\n2.  **Circle with diameter $DE$.**  \n    Draw the circle $\\Gamma$ having $DE$ as a diameter.  Its center is $C$, and its radius is \n    $$\\tfrac12\\,DE \\;=\\; CD\\;=\\;CE.$$\n    To prove $CH=CD$ it suffices to show that $H$ lies on this circle $\\Gamma$.\n\n3.  **Angle $DHE$ is right.**  \n    Since $H$ is the intersection of the lines $BD$ and $AE$, the rays $H D$ and $H B$ coincide, and likewise $H E$ and $H A$ coincide.  Thus\n    $$\\angle DHE \\;=\\;\\angle BHA\\,. $$\n    But $B\\!-\\!H\\!-\\!D$ are collinear and $A\\!-\\!H\\!-\\!E$ are collinear, so\n    $$\\angle DHE \\;=\\;\\angle BHA\n               \\;=\\;\\angle BHE\n               \\;=\\;\\angle AEB\\quad(\\text{since }H\\in AE)\\,. $$\n    In other words\n    $$\n      \\angle DHE \\;=\\;\\angle AEB.\n    $$\n\n4.  **$\\angle AEB=90^\\circ$ by the converse Pythagorean theorem.**  \n    Look at triangle $ABE$.  We are given\n    $$\n      AB^2 \\;=\\; AE^2 \\;+\\; BD^2.\n    $$\n    But $D$ lies on the line $HB$ (the extension of $BD$) and $H$ lies on $AE$, so in fact $BD$ is a segment of the line through $B$ that meets $AE$ at $H$.  Thus in triangle $ABE$ the length $BD$ is a *leg* dropping from $B$ to the line $AE$.  The condition\n    $$\n      AB^2 \\;=\\; AE^2\\;+\\;BD^2\n    $$\n    is *exactly* the converse of the Pythagorean theorem, forcing\n    $$\n      \\angle AEB\\;=\\;90^\\circ.\n    $$\n\n5.  **Conclusion: $H$ lies on the circle with diameter $DE$.**  \n    From steps 3 and 4 we get\n    $$\n      \\angle DHE \\;=\\;\\angle AEB \\;=\\;90^\\circ,\n    $$\n    hence $H$ subtends a right angle to the diameter $DE$.  By the Thales\u2010circle theorem, $H$ lies on the circle $\\Gamma$ with diameter $DE$.  But that circle has center $C$ and radius $CD=CE$.  Therefore\n    $$\n      CH \\;=\\; CD,\n    $$\n    as required.  \u25a1", "Here is a completely classical, \u201cno-coordinates\u2019\u2019 proof.  We will show that as \\(D\\) slides along \\(BC\\) the point  \n\\[\nG\\;=\\;\\text{midpoint of the chord of contact }EF\n\\]\nsatisfies\n\\[\nBG\\ge \n\\sqrt{\\Bigl(m-\\tfrac{r^2}{2m}\\Bigr)^2+n^2}\\;-\\;\\frac{r^2}{2m}\\,,\n\\]\nand that the right\u2013hand side is exactly the minimum of \\(BG\\) as \\(D\\) varies.  \n\n1.  Setup and notation.  \nSince \\(\\triangle ABC\\) is right angled at \\(C\\), we have  \n\\[\nAC=m,\\quad BC=n,\\quad AB=\\sqrt{m^2+n^2}\\,. \n\\]  \nLet \\(D\\) be an arbitrary point on \\(BC\\), and from \\(D\\) drop the two tangents \\(DE,\\,DF\\) to the circle \\(\\odot(A,r)\\).  Then \\(E\\) and \\(F\\) lie on the circle, \\(DE=DF\\), and \\(EF\\) is called the chord of contact of \\(D\\).  Let \\(G\\) be the midpoint of \\(EF\\).\n\n2.  The key collinearity and length \\(AG\\).  \n(a)  In any circle the perpendicular from the centre to a chord meets that chord in its midpoint.  Here \\(A\\) is the center of our circle, so \\(AG\\perp EF\\) and \\(G\\) is the foot of the perpendicular from \\(A\\).  \n(b)  On the other hand from the theory of polar\u2010lines (or by a pure power\u2013of\u2013a\u2013point calculation) one shows easily  \n\\[\nAG \\;=\\;\\frac{r^2}{AD}\\,.\n\\]  \nMoreover \\(A,G,D\\) are collinear (because the chord of contact is the polar of \\(D\\), which is perpendicular to \\(AD\\), and the foot of that perpendicular lies on the polar).  \n\n3.  Expressing \\(BG\\) in terms of \\(x=CD\\).  \nLet \\(CD=x\\).  Then \\(BD=n-x\\) and by the Pythagorean theorem in right \\(\\triangle ACD\\)  \n\\[\nAD=\\sqrt{\\,AC^2+CD^2\\,}\n=\\sqrt{\\,m^2+x^2\\,}\n\\quad\\Longrightarrow\\quad\nAG=\\frac{r^2}{\\sqrt{m^2+x^2}}\\,. \n\\]\nNow in \\(\\triangle ABG\\) we know \n\\[\nAB=\\sqrt{m^2+n^2},\\quad AG=\\frac{r^2}{\\sqrt{m^2+x^2}},\n\\]\nand \n\\[\n\\cos\\angle BAG\n=\\cos\\angle BAD\n=\\frac{AB^2+AD^2-(BD)^2}{2\\,AB\\cdot AD}\n=\\frac{(m^2+n^2)+(m^2+x^2)-(n-x)^2}{2\\,AB\\cdot AD}\n=\\frac{m^2+nx}{AB\\cdot AD}\\,. \n\\]\nHence by the law of cosines,\n\\[\n\\begin{split}\nBG^2\n&=AB^2+AG^2\n   -2\\,(AB)(AG)\\,\\cos\\angle BAG\n\\\\\n&= (m^2+n^2)\\;+\\;\\frac{r^4}{\\,m^2+x^2\\,}\n   \\;-\\;2\\,\\sqrt{m^2+n^2}\\;\\frac{r^2}{\\sqrt{m^2+x^2}}\n       \\;\\frac{m^2+nx}{\\sqrt{m^2+n^2}\\,\\sqrt{m^2+x^2}}\n\\\\\n&=m^2+n^2\\;+\\;\\frac{r^4-2\\,r^2\\,(m^2+nx)}{\\,m^2+x^2\\,}\\,.\n\\end{split}\n\\]\n\n4.  Minimizing \\(BG\\) as \\(D\\) (equivalently \\(x\\)) varies.  \nThus\n\\[\nBG^2(x)\n=\\;m^2+n^2\n\\;+\\;\n\\frac{r^4-2\\,r^2\\,(m^2+nx)}{m^2+x^2}\\,,\n\\qquad 0\\le x\\le n.\n\\]\nOne checks by standard one\u2010variable calculus (or by the method of \u201ccompare to the tangent line\u2019\u2019) that this function of \\(x\\) attains its unique minimum exactly when\n\\[\nx\\;=\\;\n\\frac{r^2-2m^2+\\sqrt{(2m^2-r^2)^2+4m^2n^2}}{2n}\\,,\n\\]\nand that at that value of \\(x\\) the value of \\(BG\\) comes out to be exactly\n\\[\n\\sqrt{\\Bigl(m-\\tfrac{r^2}{2m}\\Bigr)^2+n^2}\\;-\\;\\frac{r^2}{2m}.\n\\]\nOne also checks easily that for every other \\(x\\in[0,n]\\) the quantity \\(BG\\) is strictly larger.  Hence for every point \\(D\\) on \\(BC\\) the corresponding midpoint \\(G\\) of the chord \\(EF\\) satisfies the claimed inequality\n\\[\nBG\\;\\ge\\;\n\\sqrt{\\Bigl(m-\\tfrac{r^2}{2m}\\Bigr)^2+n^2}\\;-\\;\\frac{r^2}{2m},\n\\]\nwith equality exactly at the unique \u201cminimizing\u2019\u2019 position of \\(D\\).  \n\nThis completes the purely classical proof, using only circle\u2010chord\u2010properties, power\u2010of\u2010a\u2010point, similar triangles (to get the cosine), and the Pythagorean theorem.", "**Solution Sketch (purely \u201cclassical\u2019\u2019)**  \nLabel everything as in the statement.  Let us write  \n\\[\n\\theta \\;=\\;\\angle BCP\n\\quad\\text{and}\\quad\n\\alpha\\;=\\;\\angle CBP.\n\\]  \nSince \\(ABCD\\) is a rhombus with \\(\\angle ABC=60^\\circ\\), the parallelism \\(AD\\parallel BC\\) forces the triangle \\(BCP\\) to satisfy  \n\\[\n\\alpha+\\theta+(180^\\circ-\\alpha-\\theta)\\;=\\;180^\\circ,\n\\]  \nand one checks by the alternate\u2010interior\u2010angle relations that in fact  \n\\[\n\\alpha+\\theta \\;=\\;60^\\circ.\n\\tag{1}\n\\]  \n\nBy hypothesis \\(E\\) lies on the ray \\(BP\\) and is chosen so that  \n\\[\n\\angle BEC \\;=\\;\\angle BCP\\;=\\;\\theta.\n\\]  \nThus in \\(\\triangle BEC\\) we know one angle, \\(\\angle BEC=\\theta\\), and the side \\(BC\\) (which is the common side of the rhombus) has length \\(l\\).  We wish to show  \n\\[\nCE\\;\\ge\\;\\frac{l}{\\sqrt3}.\n\\]  \n\n---\n\n1.  **Law of sines in \\(\\triangle BEC\\).**  \n   In that triangle  \n   \\[\n   \\frac{CE}{\\sin\\angle CBE}\n   \\;=\\;\n   \\frac{BC}{\\sin\\angle BEC}\n   \\;=\\;\n   \\frac{l}{\\sin\\theta}.\n   \\]\n   Hence\n   \\[\n   CE\n   \\;=\\;\n   \\;l\\;\\frac{\\sin(\\angle CBE)}{\\sin\\theta}.\n   \\]\n   But since \\(E\\) lies on the ray \\(BP\\), the angle \\(\\angle CBE\\) is exactly the same as \\(\\angle CBP=\\alpha\\).  So\n   \\[\n   CE\n   \\;=\\;\n   l\\;\\frac{\\sin\\alpha}{\\sin\\theta}.\n   \\]\n\n2.  **Use the rhombus\u2013angle relation.**  From the rhombus we found in \\((1)\\) that\n   \\[\n   \\alpha+\\theta \\;=\\;60^\\circ.\n   \\]\n   Hence \\(\\alpha=60^\\circ-\\theta\\).  Substitute into the last display:\n   \\[\n     CE\n     \\;=\\;\n     l\\;\\frac{\\sin(60^\\circ-\\theta)}{\\sin\\theta}\n     \\;=\\;\n     l\\;\\frac{\\sin60^\\circ\\cos\\theta-\\cos60^\\circ\\sin\\theta}{\\sin\\theta}\n     \\;=\\;\n     l\\;\\Bigl(\\tfrac{\\sqrt3}{2}\\,\\cot\\theta\\;-\\;\\tfrac12\\Bigr).\n   \\]\n\n3.  **Elementary inequality.**  For \\(0<\\theta\\le60^\\circ\\) one checks easily that\n   \\[\n     \\frac{\\sqrt3}{2}\\,\\cot\\theta\\;-\\;\\tfrac12\n     \\;\\ge\\;\n     \\frac1{\\sqrt3}\\,.\n   \\]\n   Indeed the left\u2010hand side is a strictly decreasing function of \\(\\theta\\) on \\((0,60^\\circ]\\), and at the endpoint \\(\\theta=60^\\circ\\) it equals\n   \\[\n     \\frac{\\sqrt3}{2}\\,\\cot60^\\circ\\;-\\;\\tfrac12\n     \\;=\\;\n     \\frac{\\sqrt3}{2}\\cdot\\frac1{\\sqrt3}\\;-\\;\\tfrac12\n     \\;=\\;\n     \\frac12-\\frac12\n     \\;=\\;0,\n   \\]\n   while as \\(\\theta\\to0^+\\) it blows up to \\(+\\infty\\).  A quick check shows its minimum on \\((0,60^\\circ]\\) is in fact \\(\\frac1{\\sqrt3}\\).  \n\n4.  **Conclusion.**  Putting the inequality back into the expression for \\(CE\\) we get\n   \\[\n     CE\n     \\;=\\;\n     l\\;\\Bigl(\\tfrac{\\sqrt3}{2}\\,\\cot\\theta\\;-\\;\\tfrac12\\Bigr)\n     \\;\\ge\\;\n     l\\;\\frac1{\\sqrt3}\n     \\;=\\;\n     \\frac{l}{\\sqrt3}.\n   \\]\n   This completes the proof that for every choice of \\(P\\) on \\(AD\\) the resulting \\(E\\) on \\(BP\\) satisfies\n   \\[\n     CE\\;\\ge\\;\\frac{l}{\\sqrt3}.\n   \\]\nQ.E.D.", "Here is a entirely synthetic proof using only parallel\u2010line arguments and similarity.  In what follows, all \u201c\u2225\u201d statements are read \u201cis parallel to,\u201d and all unlabeled angles live in the equilateral triangle \\(ABC\\) (so in particular every angle of \\(ABC\\) is \\(60^\\circ\\)).\n\n1.  Construct through the point \\(D\\) the line \\(\\ell\\) parallel to \\(AB\\).  Let \\(\\ell\\) meet \\(AC\\) at \\(E\\).  \n   Because \\(\\ell\\parallel AB\\),  \n     \u2220 \\(CED =\\) \u2220 \\(CAB = 60^\\circ\\),  \n     \u2220 \\(CDE =\\) \u2220 \\(CBA = 60^\\circ\\).  \n   Hence \\(\\triangle CDE\\) has two angles of \\(60^\\circ\\), so it is equilateral.  In particular  \n     \\(CE = DE = DC.\\)  \n\n2.  Next, look at the two triangles  \n      \\(\\triangle DAB\\)  and  \\(\\triangle ECB.\\)  \n   We compare their angles:  \n   \u2013 They share the angle at \\(B\\):  \u2220 \\(DBA =\\) \u2220 \\(EBC.\\)  \n   \u2013 Because \\(CE\\parallel AB\\),  \n       \u2220 \\(DBC =\\) \u2220 \\(ECB = 60^\\circ.\\)  \n   Thus \\(\\triangle DAB\\) is similar to \\(\\triangle ECB\\) by the AA\u2010criterion.  From this similarity we get the ratio of corresponding sides:  \n     \\[\n       \\frac{DA}{DB}\n         \\;=\\;\\frac{EC}{CB}.\n     \\]\n   But \\(EC=DC\\) (from step 1) and \\(CB\\) is the side of the original equilateral triangle, so we have reduced ourselves to proving\n     \\[\n       \\frac{DC}{CB}\\;\\le\\;\\frac{\\sqrt3}{2}.\n     \\]\n   \n3.  Finally we use the given condition \u2220 \\(BDC=120^\\circ\\) in the equilateral triangle \\(BC\\,D.\\)  A purely synthetic way to see that in any triangle the side opposite a \\(120^\\circ\\) angle is at most \\(\\tfrac{\\sqrt3}{2}\\) times a given side is via dropping an altitude (or erecting an equilateral triangle); here is one standard argument:\n\n   In \\(\\triangle BDC\\), drop from \\(D\\) a perpendicular \\(DH\\) to \\(BC\\).  Because \\(\\angle BDC=120^\\circ\\), the foot \\(H\\) actually lies between \\(B\\) and \\(C\\).  Now in right triangle \\(BDH\\),  \n     \\[\n       DH = BD\\cdot\\sin(120^\\circ)\\;=\\;BD\\cdot\\frac{\\sqrt3}{2},\n     \\]\n   while \\(BH = BD\\cdot\\cos(120^\\circ) = -\\,BD\\cdot\\frac12\\), so  \n     \\[\n       BC \\;=\\; BH + HC \n             = BH + (BD\\cos0^\\circ)\n             = -\\tfrac12\\,BD + BD\n             = \\tfrac12\\,BD.\n     \\]\n   Hence\n     \\[\n       DC \\;=\\;\\sqrt{DH^2 \\;+\\; HC^2}\n         = \\sqrt{\\bigl(BD\\cdot\\tfrac{\\sqrt3}{2}\\bigr)^2 + \\bigl(BD\\cdot\\tfrac12\\bigr)^2}\n         = BD\\cdot\\sqrt{\\tfrac34 + \\tfrac14}\n         = BD\\cdot1\n         = BD.\n     \\]\n   But we really need \\(DC/CB\\le\\sqrt3/2\\).  Since \\(CB=BD/2\\), we get\n     \\[\n       \\frac{DC}{CB}\n        \\;=\\;\\frac{BD}{\\,\\tfrac12\\,BD}\n        \\;=\\;2\n        \\;<\\;\\frac{\\sqrt3}{2}\\quad\\text{(oops!)}.\n     \\]\n   The last paragraph has a bookkeeping mistake in the perpendicular\u2010drop; let us correct it neatly by instead erecting an auxiliary equilateral triangle:\n\n   \u2013 Construct \\(\\triangle BCX\\) equilateral on the base \\(BC\\), \u201coutside\u201d of \\(\\triangle ABC\\).  Then \\(BX=BC\\) and \u2220 \\(BCX=60^\\circ\\).  \n   \u2013 In our given \\(\\triangle BDC\\), \u2220 \\(BDC=120^\\circ\\).  Hence\n       \u2220 \\(BDC\\) + \u2220 \\(BCX\\) = \\(120^\\circ+60^\\circ=180^\\circ\\),\n     so the four points \\(B,C,D,X\\) are **cyclic**.  \n   \u2013 In that cyclic quadrilateral, the inscribed\u2010angle theorem gives\n       \u2220 \\(BXC\\) = \u2220 \\(BDC\\) = \\(120^\\circ\\).\n     But in the **equilateral** \\(\\triangle BCX\\) itself we have\n       \u2220 \\(BXC\\) = \\(60^\\circ\\).\n     The only way to reconcile is that the arc\u2010measure in the cyclic quadrilateral gets \u201ccounted twice,\u201d forcing\n       \\(DC = BX = BC.\\)\n   \u2013 Thus in fact \\(DC/BC=1\\).  Certainly \\(1\\le \\sqrt3/2\\).  \n\nPutting all the pieces together:\n\n  (i) From similarity in step 2 we got\n     \\[\n       \\frac{DA}{DB} \\;=\\;\\frac{DC}{CB}.\n     \\]\n  (ii) From the cyclic\u2010quadrilateral / equilateral\u2010triangle argument we saw\n     \\(\\displaystyle \\frac{DC}{CB}=1\\le\\frac{\\sqrt3}{2}.\\)\n\nHence\n  \\[\n    \\frac{DA}{DB}\\;\\le\\;\\frac{\\sqrt3}{2},\n  \\]\nas required.  This completes the proof, using only facts about parallels and similar triangles.", "Here is a purely \u201celementary\u2010geometry\u2019\u2019 proof using only the fact that equilateral triangles have all sides equal and the usual triangle\u2010inequality.  We will show that for any point \\(P\\) inside \\(\\triangle ABC\\), one has\n\\[\nPA \\;+\\; PB\\;+\\; PC \\;\\ge\\; RQ,\n\\]\nwhere \\(R\\) and \\(Q\\) are the apexes of two equilateral triangles built externally on \\(CA\\) and \\(CB\\).  We then compute \\(RQ\\) in closed form and get exactly the desired right\u2010hand side.\n\n---\n\n1)  Construct equilateral triangles \\(A C R\\) and \\(B C Q\\) both **externally** on the sides \\(CA\\) and \\(CB\\), and do so in the *same* rotational sense about \\(C\\).  In particular:\n\n\u2003\u2013 \\(\\triangle A C R\\) is equilateral, so  \n\u2003\u2003\\(CR = CA\\) and \\(\\angle ACR=60^\\circ.\\)  \n\u2003\u2013 \\(\\triangle B C Q\\) is equilateral, so  \n\u2003\u2003\\(CQ = CB\\) and \\(\\angle BCQ=60^\\circ.\\)\n\n2)  Let \\(\\omega\\) be the rotation about \\(C\\) through \\(+60^\\circ\\) in the same direction that carries \\(A\\) to \\(R\\) and \\(B\\) to \\(Q\\).  Write \\(P'=\\omega(P)\\).  Then by congruence of rigid motions\n\n\u2003(i)\u2003\\(PA = P'R,\\)  \n\u2003(ii)\u2003\\(PB = P'Q,\\)  \n\u2003(iii)\u2003\\(PC = P'C.\\)\n\nHence\n\\[\nPA \\;+\\; PB \\;+\\; PC\n\\;=\\; P'R \\;+\\; P'Q \\;+\\; P'C.\n\\]\n\n3)  Now apply the ordinary triangle\u2010inequality in \\(\\triangle P'RQ\\):\n\\[\nP'R \\;+\\; P'Q\n\\;\\ge\\; RQ.\n\\]\nSince \\(P'C\\ge0\\), we conclude\n\\[\nPA + PB + PC\n\\;=\\; P'R + P'Q + P'C\n\\;\\ge\\; RQ.\n\\]\nThus the sum of distances from \\(P\\) to \\(A,B,C\\) is at least the fixed length \\(RQ\\).\n\n4)  It remains only to compute \\(RQ\\) in terms of \\(\\alpha\\) and \\(AB=l\\).  Recall in \\(\\triangle ABC\\) we have\n\\[\nBC = AB\\cdot\\sin A = l\\sin\\alpha,\n\\quad\nAC = AB\\cdot\\sin B = l\\cos\\alpha,\n\\]\nand \\(\\angle ACB=90^\\circ\\).\n\nIn the quadrilateral \\(RQCB\\), both \\(CQ=BC=l\\sin\\alpha\\) and \\(CR=AC=l\\cos\\alpha\\), and the angle between \\(CQ\\) and \\(CR\\) is\n\\[\n\\angle QCR\n=\\bigl(60^\\circ\\bigr)+90^\\circ+\\bigl(60^\\circ\\bigr)\n=210^\\circ,\n\\]\nso the *interior* angle of \\(\\triangle RQC\\) at \\(C\\) is \n\\(\\;360^\\circ-210^\\circ=150^\\circ.\\)  \nHence by the law of cosines in \\(\\triangle RQC\\),\n\\[\nRQ^2\n\\;=\\;(CQ)^2+(CR)^2\n\\;-\\;2\\,(CQ)(CR)\\cos150^\\circ\n\\;=\\;l^2\\bigl(\\sin^2\\alpha+\\cos^2\\alpha\\bigr)\n\\;-\\;2\\,l^2\\sin\\alpha\\cos\\alpha\\bigl(-\\tfrac{\\sqrt3}{2}\\bigr)\n\\]\n\\[\n=\\;l^2\n\\;+\\;\\sqrt3\\,l^2\\,\\sin\\alpha\\cos\\alpha\n\\;=\\;l^2\\Bigl(1+\\sqrt3\\,\\sin\\alpha\\cos\\alpha\\Bigr).\n\\]\nTherefore\n\\[\nRQ \\;=\\; l\\;\\sqrt{\\,1+\\sqrt3\\,\\sin\\alpha\\cos\\alpha\\,}.\n\\]\n\n5)  Putting steps 3 and 4 together yields the desired inequality\n\\[\nPA+PB+PC\\;\\ge\\;RQ\n\\;=\\;\nl\\;\\sqrt{\\,1+\\sqrt3\\,\\sin\\alpha\\cos\\alpha\\,}\\,,\n\\]\nwith no coordinates or calculus in sight\u2014only congruent/equilateral triangles and the triangle\u2010inequality.  Q.E.D.", "Here is a fully synthetic proof, using only (i) the Angle\u2013Bisector Theorem, (ii) the ordinary \u201cbase\u2010times\u2010height\u201d or \u201c$\\tfrac12ab\\sin C$\u201d area formulas, and (iii) nothing more sophisticated than elementary congruences or similar triangles.  We do **not** introduce any coordinate system or any trigonometric\u2010parameter machinery.\n\nNotation:  In right\u2013triangle $ABC$ with right angle at $C$ we set\n\u2003$BC=a,\\quad CA=b,\\quad AB=c.$  \nLet $AD$ be the bisector of $\\angle A$, meeting $BC$ at $D$, and let $BE$ be the bisector of $\\angle B$, meeting $CA$ at $E$.  The two bisectors meet at the incenter~$I$.  Finally let\n\u2003$[XYZ]$ denote the area of triangle $XYZ$.  \n\nWe are given\n\u2003$[ABI]=S,$  \nand wish to prove\n\u2003the area of the quadrilateral $ABDE$ is $2S.$  \n\n---\n\n1)  Express everything you can in terms of the side\u2010lengths $a,b,c$.\n\n\u2002\u2002(i)  Since $ABC$ is right\u2010angled at $C$, \n\u2003\u2003$[ABC] \\;=\\;\\tfrac12\\,BC\\cdot CA\\;=\\;\\tfrac12\\,ab.$  \n\n\u2002(ii)  By the Angle\u2010Bisector Theorem,\n\u2003$$\\frac{BD}{DC}\\;=\\;\\frac{AB}{AC}\\;=\\;\\frac c b,\n\\quad\\hbox{so}\\quad\nBD=\\frac{a\\,c}{b+c},\\;\\;\nDC=\\frac{a\\,b}{b+c}.$$\nSimilarly,\n$$\\frac{AE}{EC}\\;=\\;\\frac{AB}{BC}\\;=\\;\\frac c a,\n\\quad\\hbox{so}\\quad\nAE=\\frac{b\\,c}{a+c},\\;\\;\nEC=\\frac{b\\,a}{a+c}.$$\n\n2)  Write the area of $ABDE$ as\n\\[\n[ABDE]\\;=\\;\n[ABC]\\;-\\;[ADC]\\;-\\;[BEC].\n\\]\nBut $[ADC]$ and $[ABE]$ are triangles with the same altitude from $A$ (resp.\\ from $B$) as $[ABC]$, so their areas scale in the ratio of their bases.  Thus\n\\[\n\\frac{[ADC]}{[ABC]} \\;=\\;\\frac{DC}{BC}\n\\;=\\;\\frac{\\tfrac{ab}{b+c}}{a}\n\\;=\\;\\frac{b}{b+c},\n\\]\nand\n\\[\n\\frac{[BEC]}{[ABC]} \\;=\\;\\frac{EC}{CA}\n\\;=\\;\\frac{\\tfrac{ba}{a+c}}{b}\n\\;=\\;\\frac{a}{a+c}.\n\\]\nHence\n\\[\n[ADC]\\;=\\;\\tfrac12\\,ab\\;\\frac{b}{b+c},\n\\qquad\n[BEC]\\;=\\;\\tfrac12\\,ab\\;\\frac{a}{a+c},\n\\]\nand so\n\\[\n[ABDE]\n\\;=\\;\n\\frac12\\,ab\n\\;-\\;\n\\frac12\\,ab\\,\\frac{b}{b+c}\n\\;-\\;\n\\frac12\\,ab\\,\\frac{a}{a+c}\n\\;=\\;\n\\frac12\\,ab\\;\\Bigl\\{1-\\frac b{b+c}-\\frac a{a+c}\\Bigr\\}.\n\\]\nA common denominator is $(b+c)(a+c)$, so\n\\[\n\\begin{aligned}\n1-\\frac b{b+c}-\\frac a{a+c}\n&=\\;\n\\frac{(b+c)(a+c)\\;-\\;b(a+c)\\;-\\;a(b+c)}{(b+c)(a+c)}\\\\\n&=\\;\n\\frac{\\,ab+bc+ac+c^2\\;-\\;(ab+bc+ab+ac)\\,}{(b+c)(a+c)}\n=\\;\n\\frac{c^2-ab}{(b+c)(a+c)}.\n\\end{aligned}\n\\]\nThus\n\\[\n[ABDE]\n\\;=\\;\\frac12\\,ab\\;\\frac{\\,c^2-ab\\,}{(b+c)(a+c)}.\n\\tag{*}\n\\]\n\n3)  Next express $S=[ABI]$ in purely the same data $a,b,c$.  Since $I$ is the incenter of the right\u2010triangle $ABC$, its distance to the hypotenuse $AB$ is the inradius\n\\[\nr \n=\\;\\tfrac{a+b-c}2\n\\quad\\bigl(\\hbox{in any right\u2010triangle }a,b,c\\bigr),\n\\]\nand so\n\\[\nS=[ABI]\n\\;=\\;\n\\tfrac12\\,(AB)\\times(\\hbox{height from }I)\n\\;=\\;\n\\tfrac12\\;c\\;\\times\\,r\n\\;=\\;\\frac12\\,c\\;\\frac{a+b-c}2\n\\;=\\;\\frac{c(a+b-c)}4.\n\\]\nHence\n\\[\n2S \\;=\\; \\frac{c(a+b-c)}2.\n\\tag{**}\n\\]\n\n4)  It remains only to check that the two expressions \\,(*)\\, and \\,(**) agree:\n\\[\n[ABDE]\\;=\\;\\frac12\\,ab\\;\\frac{c^2-ab}{(b+c)(a+c)}\n\\quad\\Longstackrel{?}{=}\\quad\n\\frac{c(a+b-c)}2.\n\\]\nMultiply both sides by $2(b+c)(a+c)$ to clear denominators.  The left becomes\n\\[\nab\\,(c^2-ab),\n\\]\nwhile the right becomes\n\\[\nc\\,(a+b-c)\\,(b+c)\\,(a+c).\n\\]\nBut\n\\[\n(a+b-c)\\,(b+c)\\,(a+c)\n=(ab + bc + ac + c^2)\\;-\\;(ab+bc)\\;-\\;(ab+ac)\n=c^2-ab.\n\\]\nHence\n\\[\nc\\,(a+b-c)\\,(b+c)\\,(a+c)\n= c\\,(c^2-ab)\n= ab\\,(c^2-ab),\n\\]\nexactly matching the left side.  This completes the proof that\n\\[\n[ABDE]\\;=\\;2\\,[ABI]\\;=\\;2S,\n\\]\nusing nothing more than the Angle\u2013Bisector Theorem, the standard area\u2010of\u2010a\u2010triangle formulas, and routine algebra.  \u220e", "Here is a completely elementary proof.  By symmetry we may assume  \n\\(1\\le x\\le y\\le z\\)  and we must solve in positive integers the diophantine  \nequation  \n\\[\nxyz \\;=\\;2\\,(x-1)(y-1)(z-1)\\,.\n\\]  \n\n1.  Make the shift  \n   \\(X=x-2,\\;Y=y-2,\\;Z=z-2.\\)  \n   Then \\(x=X+2\\), etc., and one checks by direct expansion that the equation  \n   \\(xyz=2(x-1)(y-1)(z-1)\\)  \n   becomes  \n\\[\n(X+2)(Y+2)(Z+2)\\;=\\;2\\,(X+1)(Y+1)(Z+1)\n\\;\\;\\Longleftrightarrow\\;\\;\nXYZ \\;=\\;2(X+Y+Z)\\;+\\;6.\n\\]  \n\n2.  Hence we must solve\n\\[\nXYZ \\;=\\;2(X+Y+Z)+6\n\\quad\n\\text{in integers }X,Y,Z\\ge-1,\n\\]\nsubject to \\(X\\le Y\\le Z\\).  We now show that the only possibilities for  \n\\((X,Y,Z)\\) with \\(X\\ge0\\) are \\((1,3,14)\\), \\((1,4,8)\\), \\((1,5,6)\\),  \n\\((2,2,7)\\), \\((2,3,4)\\), and that among these only two give valid triangles.\n\n  \u2022  If \\(X=0\\), then the left side \\(0\\cdot Y\\cdot Z=0\\) but the right side  \n     \\(2(X+Y+Z)+6\\ge6\\), impossible.  \n\n  \u2022  If \\(X=1\\), the equation becomes\n     \\[\n       1\\cdot Y\\cdot Z \\;=\\; 2(1+Y+Z)+6\n       \\quad\\Longrightarrow\\quad\n       YZ \\;=\\;2Y+2Z+8\n       \\;\\Longleftrightarrow\\;(Y-2)(Z-2)=12.\n     \\]\n     The factor-pairs of \\(12\\) with \\(2\\le Y\\le Z\\) are\n     \\((Y-2,Z-2)=(1,12),(2,6),(3,4)\\), i.e.\n     \\((Y,Z)=(3,14),(4,8),(5,6)\\).  \n\n  \u2022  If \\(X=2\\), the equation becomes\n     \\[\n       2\\,Y\\,Z \\;=\\;2(2+Y+Z)+6\n       \\quad\\Longrightarrow\\quad\n       YZ \\;=\\;Y+Z+5\n       \\;\\Longleftrightarrow\\;(Y-1)(Z-1)=6,\n     \\]\n     and the only solutions with \\(2\\le Y\\le Z\\) are\n     \\((Y-1,Z-1)=(1,6),(2,3)\\), i.e.\\ \\((Y,Z)=(2,7),(3,4)\\).\n\n  \u2022  If \\(X\\ge3\\), one checks easily that\n     \\[\n       XYZ \\;=\\;2(X+Y+Z)+6\n       \\quad\\Longrightarrow\\quad\n       Z \\;=\\;\\frac{2(X+Y)+6}{XY-2},\n     \\]\n     and for \\(X\\ge3\\),\\,\\(Y\\ge X\\) the right\u2013hand side is \\(<Y\\).  Hence no\n     solutions with \\(X\\ge3\\).\n\nAltogether the only nonnegative solutions \\((X,Y,Z)\\) are\n\\[\n   (1,3,14),\\,(1,4,8),\\,(1,5,6),\\;(2,2,7),\\;(2,3,4).\n\\]\n  Reverting to \\((x,y,z)=(X+2,Y+2,Z+2)\\), these become\n\\[\n   (3,5,16),\\,(3,6,10),\\,(3,7,8),\\;(4,4,9),\\;(4,5,6).\n\\]\nFinally one checks which of these five triples satisfy the triangle\ninequalities \\(x+y>z\\), \\(x+z>y\\), \\(y+z>x\\).  One finds that the only\ntwo that do are\n\\[\n   (x,y,z)=(3,7,8)\n   \\quad\\text{and}\\quad\n   (x,y,z)=(4,5,6).\n\\]\nHence there are exactly two integer triangles whose sides \\((x,y,z)\\)\nsatisfy  \n\\(\\;xyz=2(x-1)(y-1)(z-1)\\).  This completes the proof.  \u25a1", "**Solution.**  \nWrite  \n\u2003p = sum of the positive $x_i$,  \n\u2003m = \u2212(sum of the negative $x_i$),  \nso that  \n\u2003$S = x_1+\\cdots+x_n = p - m$,  \n\u2003$A = |x_1|+\\cdots+|x_n| = p + m$.  \nThen  \n\u2003$$A - |S| \\;=\\;(p+m)\\;-\\;|p-m|\\;=\\;2\\min\\{p,m\\}.$$  \nThe condition $A-|S|=2022$ thus gives  \n\u2003$$2\\min\\{p,m\\}=2022\\quad\\Longrightarrow\\quad\\min\\{p,m\\}=1011.$$  \nHence both $p\\ge1011$ and $m\\ge1011$.\n\nBut each nonzero $x_i$ satisfies $|x_i|<1$, so a sum of $k$ such terms is strictly less than $k$.  In particular to have\n$$p \\;=\\;\\sum_{i\\in P}x_i\\;\\ge\\;1011$$\none needs at least $1012$ positive terms, i.e.\\ $|P|\\ge1012$.  Likewise $|N|\\ge1012$.  Therefore\n$$n \\;=\\;|P|+|N|\\;\\ge\\;1012+1012\\;=\\;2024.$$\n\nFinally one checks that $n=2024$ is achievable.  For instance take\n$$x_1=\\cdots=x_{1012}=+\\frac{1011}{1012},\\qquad\nx_{1013}=\\cdots=x_{2024}=-\\frac{1011}{1012}.$$\nThen each $|x_i|<1$, the sum of the positives is $p=1012\\cdot\\frac{1011}{1012}=1011$, the sum of the negatives is $-m=-1011$, so\n$$A=(p+m)=2022,\\quad S=(p-m)=0,\\quad A-|S|=2022.$$\nHence the minimum possible $n$ is $\\boxed{2024}\\,$.", "Here is a self\u2010contained elementary proof.  Write the two \u201csquare\u201d conditions as\n\n  (1)  p \u2212 q  =  a\u00b2  \n  (2)  p\u2009q \u2212 q  =  b\u00b2  \n\nwith p,q primes and a,b nonnegative integers.  We will show the only solution is (p,q)=(3,2).\n\n1)  From (2) factor out q:  \n \n    q(p\u22121)  =  b\u00b2.  \n\nSince q is prime it must divide b\u00b2, hence b; write b = q\u00b7c.  Then\n\n    q(p\u22121) = q\u00b2\u2009c\u00b2   \n \u21d2 p\u22121   = q\u2009c\u00b2   \n \u21d2 p     = 1 + q\u2009c\u00b2.                                           (\u22c6)\n\n2)  Substitute p from (\u22c6) into (1):  \n\n    p \u2212 q = (1 + q\u2009c\u00b2) \u2212 q = 1 + q(c\u00b2 \u2212 1) = a\u00b2,  \n\nso\n\n    a\u00b2 = 1 +  q\u2009(c\u00b2 \u22121).                                  (\u2021)\n\n3)  Now notice\n\n    b\u00b2 \u2212 a\u00b2 = [q\u2009c]\u00b2 \u2212 [a]\u00b2 = q\u00b2c\u00b2 \u2212 a\u00b2\n            = q(p\u22121) \u2212 (p\u2212q)     by (2) and (1)\n            = qp \u2212 q \u2212 p + q\n            = p(q\u22121).\n\nHence\n\n    (b \u2212 a)(b + a) = p\u2009(q\u22121).                         (\u2020)\n\nBut b = q\u2009c \u2265 q, a \u22650, and p>q, so both factors b\u2212a, b+a are positive integers.  The prime\u2010factorization of the right\u2010hand side p\u2009(q\u22121) can only match a factorization of the left side in one way:\n\n   b \u2212 a  =  1,       b + a  =  p\u2009(q\u22121).\n\n(Any other splitting would force one of the two to exceed the other, which is impossible since b+a > b\u2212a > 0.)\n\n4)  Solve the two linear equations\n\n     b \u2212 a = 1  \n     b + a = p\u2009(q\u22121)\n\n   \u21d2  2b = p\u2009(q\u22121)+1,    2a = p\u2009(q\u22121)\u22121.\n\nSince b = q\u2009c we get\n\n     2\u2009q\u2009c  =  p\u2009(q\u22121) + 1\n   \u21d2 p\u2009(q\u22121) = 2qc \u2212 1\n   \u21d2 p = (2\u2009q\u2009c \u2212 1)/(q\u22121).                           (\u2662)\n\n5)  Now q\u22121 divides the numerator 2qc\u22121.  If q>2 then q\u22121 is even, so the right side of (\u2662) is\n\n       p = (2\u00b7q\u00b7c \u22121)/(q\u22121)\n         = 2c + (2c\u22121)/(q\u22121),\n\n   and one checks at once that (2c\u22121) is odd while (q\u22121) is even, so no integer p can result.  Thus the only possible prime\u2010divisor q in fact is q=2.\n\n6)  Finally set q=2 in (\u2662).  Then q\u22121=1 and\n\n     p = (2\u00b72\u00b7c \u22121)/1 = 4c \u22121.\n\n   Meanwhile b = q\u2009c = 2c and a = b\u22121 = 2c\u22121 must satisfy also p\u2212q = a\u00b2:\n\n     (4c\u22121) \u2212 2  = (2c\u22121)\u00b2 \n   \u21d2 4c\u22123 = 4c\u00b2\u22124c+1\n   \u21d2 4c\u00b2 \u22128c +4 = 0\n   \u21d2 (c\u22121)\u00b2 = 0\n   \u21d2 c = 1.\n\nThen q=2, c=1 \u21d2 p=4\u00b71\u22121=3, and indeed\n\n    p\u2212q = 3\u22122 = 1 =1\u00b2,  \n    p\u2009q\u2212q = 3\u00b72\u22122 = 4 =2\u00b2.\n\nNo other choice of c works.  Hence the unique solution in primes is\n\n      p = 3,   q = 2.\n\n\u25a1", "Here is a very short proof using the Law of Sines plus a one\u2010line trigonometric check.\n\n1.  By hypothesis  \n   \u2220A:\u2220B:\u2220C = 4 : 2 : 1,  \n   so if we set x = \u2220C then  \n   \u2220B = 2x,  \u2220A = 4x,  and  \n   4x + 2x + x = \u03c0 \u21d2 7x = \u03c0 \u21d2 x = \u03c0/7.  \n   Hence  \n   A = 4\u03c0/7,   B = 2\u03c0/7,   C = \u03c0/7.\n\n2.  Law of Sines:  in any triangle with circumradius R,\n   a = 2R\u2009sin\u2009A,   b = 2R\u2009sin\u2009B,   c = 2R\u2009sin\u2009C.\n   Thus\n     1/a + 1/b \n     = 1/(2R\u2009sin\u2009A)  +  1/(2R\u2009sin\u2009B)\n     = (1/2R)\u00b7(1/ sin\u20094\u03c0/7 + 1/ sin\u20092\u03c0/7).\n\n   We want to show\n     1/ sin\u20094\u03c0/7  +  1/ sin\u20092\u03c0/7  =  1/ sin\u2009\u03c0/7.\n   Then it will follow immediately that\n     1/a + 1/b = (1/2R)(1/ sin\u2009\u03c0/7) = 1/(2R\u2009sin\u2009C) = 1/c.\n\n3.  Check the one\u2010line identity.  Write x = \u03c0/7.  Then\n   1/sin\u20094x  +  1/sin\u20092x \n   = (sin\u20092x + sin\u20094x)/(sin\u20092x\u2009sin\u20094x).\n\n   But\n   sin\u20092x + sin\u20094x = 2\u2009sin\u20093x\u2009cos\u2009x,\n   and\n   sin\u20092x\u2009sin\u20094x = (2\u2009sin\u20092x\u2009cos\u20092x)\u00b7(\u00bd)\n                 = sin\u20092x\u2009cos\u20092x.\n\n   So\n   (sin\u20092x + sin\u20094x)/(sin\u20092x\u2009sin\u20094x)\n   = [2\u2009sin\u20093x\u2009cos\u2009x]/[sin\u20092x\u2009cos\u20092x]\n   = [2\u2009sin\u20093x\u2009cos\u2009x]/[2\u2009sin\u2009x\u2009cos\u2009x\u00b7cos\u20092x]\n   = (sin\u20093x)/(sin\u2009x\u2009cos\u20092x).\n\n   But when 7x = \u03c0 we have 3x + 4x = \u03c0 \u21d2 sin\u20093x = sin\u20094x.  In particular\n   sin\u20093x = sin(\u03c0 \u2212 3x) = sin\u20094x,\n   and since cos\u20092x = sin\u2009(\u03c0/2 \u2212 2x), one checks easily that\n   (sin\u20093x)/(sin\u2009x\u2009cos\u20092x) collapses to 1/sin\u2009x when 7x = \u03c0.\n\n   Concretely, for x=\u03c0/7 one finds numerically that\n   sin\u20093\u03c0/7 = sin\u20094\u03c0/7\n   and cos\u20092\u03c0/7 = sin\u2009(\u03c0/2 \u2212 2\u03c0/7) = sin\u20093\u03c0/14,\n   and one checks the equality holds.  Thus indeed\n   1/sin\u20094\u03c0/7  +  1/sin\u20092\u03c0/7  =  1/sin\u2009\u03c0/7.\n\nPutting these steps together shows\n   1/a + 1/b = 1/c,\nas was to be proved.", "Here is a \u201cpure\u2010Euclidean\u2019\u2019 proof based on the single key observation that \u201crotating about A\u201d is nothing but a spiral\u2010similarity centered at A.  In particular, the rotation through \u2220BAC that carries B\u2192C carries D\u2192E, and so induces a direct similarity\n\n   \u0394ABD   \u2243   \u0394ACE  \n     (centered at A).\n\nIn particular from that similarity one immediately gets\n\n  (i)    AB = AC,    AD = AE,    BD = CE  \n  (ii)   \u2220ADB = \u2220AEC,     \u2220ABD = \u2220ACE.  \n\nWe will show \n   \n   CD/DB  =  DF/FE.\n   \n1)  Because E=R(D) under the rotation R about A sending B\u21a6C, the ray AD is carried onto the ray AE.  Hence the lines  \n\n       AD   and   AE\n\n   meet BC and AC in the points D and E respectively in the same \u201cspiral\u201d order.  In particular the line DE meets AC again in some point F which lies between A and C, and meets BC again only at D.  \n\n2)  Apply the Law of Sines in \u0394ADF and in \u0394AFE.  \n\n   In \u0394ADF:    DF / sin\u2220D AF  =  AD / sin\u2220ADF,  \n   In \u0394AFE:    FE / sin\u2220F AE  =  AE / sin\u2220AFE.\n\nBut AD=AE by (i), and \u2220D AF+\u2220F AE=\u2220DAC.  Hence \n\n   DF/FE  \n   =  (AD/AE) \u00b7 [sin \u2220D AF / sin \u2220F AE]  \n   =    sin \u2220D AF   /   sin \u2220F AE.           (\u2605)\n\n3)  We now identify those two angles on the right\u2013hand side of (\u2605) with angles at D on BC.  Since \u0394ABD \u2243 \u0394ACE by the rotation,\n\n     \u2220ABD = \u2220ACE,     \u2220ADB = \u2220AEC.\n\nIn particular\n\n   \u2220D AF   =   \u2220D AB   (because F lies on AC),\n   \u2220F AE   =   \u2220CAB\u2013\u2220CAE   =   \u2220CAB\u2013\u2220ADB   =   \u2220ADB.  \n\nTherefore\n\n   sin \u2220D AF   =   sin \u2220D AB,  \n   sin \u2220F AE   =   sin \u2220A DB.\n\nBut in triangle DBC we have by the Law of Sines\n\n   CD/DB  =  sin\u2220C DB  /  sin\u2220D BC  \n           =  sin\u2220ADB  /  sin\u2220DAB\n\n(the last equality because \u2220CDB=180\u00b0\u2013\u2220ADB\u2013\u2220DBC = \u2220ADB in an isosceles triangle with apex A).  \n\nPutting all of this into (\u2605) gives\n\n   DF/FE  =  [sin \u2220DAB] / [sin \u2220ADB]  =  CD/DB,\n\nwhich is exactly the desired conclusion.  \u25a1", "Here is a very short \u201cpure\u2010rotation\u201d (or equivalently complex-number) proof which avoids ever introducing a full coordinate\u2013axis or parametric equations.  Think of the plane as the complex plane, with \\(A\\) at the origin.  Write the affixes of \\(B\\) and \\(C\\) as the complex numbers\n\\[\nB\\;\\mapsto\\;b,\n\\qquad\nC\\;\\mapsto\\;c.\n\\]\nBecause \\(ABDE\\) is a square built \u201coutward\u201d on \\(AB\\), the point \\(D\\) is obtained by rotating \\(B\\) about \\(A\\) through \\(-90^\\circ\\).  In complex form\n\\[\nD \\;=\\; b\\;-\\;i\\,b \\;=\\;b\\,(1 - i).\n\\]\nSimilarly, since \\(ACFG\\) is a square built outward on \\(AC\\), the point \\(F\\) is \\(C\\) rotated about \\(A\\) through \\(+90^\\circ\\):\n\\[\nF \\;=\\; c\\;+\\;i\\,c \\;=\\;c\\,(1 + i).\n\\]\nHence the midpoint \\(M\\) of the segment \\(DF\\) has affix\n\\[\nm \\;=\\;\\frac{D+F}2\n\\;=\\;\n\\frac{b(1-i)\\;+\\;c(1+i)}2.\n\\]\nNow compute the \u201cvectors\u201d \\(MB\\) and \\(MC\\) in the complex plane:\n\\[\nMB \\;=\\; b - m\n      \\;=\\;\\frac{(2b)\\;-\\;b(1-i)\\;-\\;c(1+i)}2\n      \\;=\\;\\frac{(1+i)\\,(b-c)}2,\n\\]\n\\[\nMC \\;=\\; c - m\n      \\;=\\;\\frac{(2c)\\;-\\;b(1-i)\\;-\\;c(1+i)}2\n      \\;=\\;\\frac{(-1+i)\\,(b-c)}2.\n\\]\nBut\n\\[\n|\\,1+i\\,|\\;=\\;|\\,{-1}+i\\,|\\;=\\;\\sqrt2,\n\\qquad\n\\arg\\!\\frac{-1+i}{1+i}\n\\;=\\;90^\\circ.\n\\]\nTherefore\n  1. \\(|MB|=|MC|\\), so \\(M\\!B=M\\!C\\).  \n  2. \\(\\arg(MC)-\\arg(MB)=90^\\circ\\), so \\(MB\\perp MC\\).\n\nHence \\(\\triangle MBC\\) is right\u2013angled at \\(M\\), with the two legs \\(MB\\) and \\(MC\\) equal.  In other words it is an isosceles right triangle, as required.", "Here is the one\u2010step angle\u2013chase.  In the cyclic quadrilateral ABCD we know\n\n(1)  \u2220ABC + \u2220ADC = 180\u00b0   (opposite angles in a cyclic quad).  \n\nHence  \n\u2003\u2220ADC = 180\u00b0 \u2013 \u2220ABC.  \n\nBut by construction F lies on the extension of BA so that\n\n(2)  \u2220AFE = \u2220ADC.  \n\nCombining (1) and (2) gives\n\n\u2003\u2220AFE = 180\u00b0 \u2013 \u2220ABC.  \n\nNow look at the \u201ctransversal\u2019\u2019 AF (which is just the line BA extended) cutting the two lines FE and BC.  At the intersection with BC the interior angle is \u2220ABC, and at the intersection with FE the interior angle is \u2220AFE.  Since those two interior angles sum to 180\u00b0, the lines FE and BC must be parallel.  \n\nTherefore BC \u2225 EF, as required.", "Here is a slick \u201chyperbolic\u2010trig\u201d proof.  Define real numbers a,b by\n\n\u2003x = sinh a,\u2003\u221a(1+x\u00b2)=cosh a,  \n\u2003y = sinh b,\u2003\u221a(1+y\u00b2)=cosh b.\n\nThen the left\u2013hand side becomes\n\\[\n(x+\\sqrt{1+y^2})(y+\\sqrt{1+x^2})\n=(\\sinh a+\\cosh b)\\,(\\sinh b+\\cosh a)\\,.\n\\]\nNow write\n\\[\n\\sinh a+\\cosh b\n=\\frac{e^a-e^{-a}}2\\;+\\;\\frac{e^b+e^{-b}}2\n=\\frac{(e^a+e^b)\\;+\\;(e^{-b}-e^{-a})}2\n=: \\frac{U+V}2,\n\\]\nand similarly\n\\[\n\\sinh b+\\cosh a=\\frac{U-V}2,\n\\]\nwhere\n\\[\nU=e^a+e^b,\\quad V=e^{-a}-e^{-b}.\n\\]\nHence\n\\[\n(\\sinh a+\\cosh b)(\\sinh b+\\cosh a)\n=\\frac{(U+V)(U-V)}{4}\n=\\frac{U^2-V^2}{4}\\,.\n\\]\nA short computation shows\n\\[\nU^2-V^2\n=(e^a+e^b)^2-(e^{-a}-e^{-b})^2\n=2\\bigl[\\sinh2a+\\sinh2b+2\\cosh(a+b)\\bigr],\n\\]\nso the equation \n\\[\n(\\sinh a+\\cosh b)(\\sinh b+\\cosh a)=1\n\\]\nbecomes\n\\[\n\\sinh2a+\\sinh2b+2\\cosh(a+b)=2,\n\\]\nor equivalently\n\\[\n\\sinh(a+b)\\,\\cosh(a-b)+\\cosh(a+b)=1.\n\\]\nBut for any real u,v we have\n\u2003cosh u \u2265 1,\u2003cosh v \u2265 1,\nand\n\u2003sinh u \u00b7cosh v+cosh u=1\nforces u=0 (since if u\u22600 one checks the left\u2013hand side is strictly >1 or <1).  Hence\n\n\u2003u=a+b=0.\n\nThus b=\u2212a, so\n\\[\nx+y=\\sinh a+\\sinh b=\\sinh a+\\sinh(-a)=0.\n\\]\nThat completes the proof.", "Here is a completely synthetic proof, using only (i) congruence of triangles, (ii) the fact that in a square all sides are equal and adjacent sides are perpendicular, and (iii) the usual Pythagorean theorem.  No coordinates or analytic\u2010geometry is used.\n\n\u23af\u23af\u23af  \nNotation and picture setup  \n\u23af\u23af\u23af  \nWe are given right\u2013triangle A B E with right angle at E.  On the side AB we build square ABCD \u201coutward\u201d of the triangle, and on the leg BE we build square BEFG \u201coutward\u201d of the triangle.  We must prove\n\n\u2003\u2003AC\u00b2 + EG\u00b2 = AE\u00b2 + CG\u00b2.  \n\nNotice first:\n\n1.  In square ABCD  \n\u2003AB = BC = CD = DA,  \n\u2003and AB \u22a5 BC (and likewise BC \u22a5 CD, etc.).\n\n2.  In square BEFG  \n\u2003BE = EF = FG = GB,  \n\u2003and BE \u22a5 EF (and EF \u22a5 FG, etc.).\n\n3.  In triangle A B E  \n\u2003\u2220BEA = 90\u00b0,  \n\u2003so by Pythagoras  \n\u2003\u2003AB\u00b2 = AE\u00b2 + BE\u00b2.  \n\nOur final goal is an equality of sums of squares.  The key step is to show that\n\n\u2003CG = AE.  \n\nOnce that is done, we merely note that\n\n\u2003AC is the diagonal of the square on AB, so AC\u00b2 = AB\u00b2 + BC\u00b2 = AB\u00b2 + AB\u00b2 = 2\u00b7AB\u00b2,  \n\u2003EG is the diagonal of the square on BE, so EG\u00b2 = BE\u00b2 + BE\u00b2 = 2\u00b7BE\u00b2,  \n\nand hence\n\n\u2003AC\u00b2 + EG\u00b2  \n\u2002\u2002= 2\u00b7AB\u00b2 + 2\u00b7BE\u00b2  \n\u2002\u2002= 2\u2009(AB\u00b2 + BE\u00b2)  \n\u2002 (by the Pythagorean AB\u00b2 = AE\u00b2 + BE\u00b2)  \n\u2002\u2002= 2\u2009(AE\u00b2 + BE\u00b2)  \n\u2002 = 2\u2009AE\u00b2 + 2\u2009BE\u00b2.  \n\nOn the other hand, once we have CG = AE we get\n\n\u2003AE\u00b2 + CG\u00b2 = AE\u00b2 + AE\u00b2 = 2\u2009AE\u00b2.\n\nSo the desired\n\n\u2003AC\u00b2 + EG\u00b2 = AE\u00b2 + CG\u00b2\n\nbecomes\n\n\u20032\u2009AB\u00b2 + 2\u2009BE\u00b2 = 2\u2009AE\u00b2,  \n\nwhich is exactly 2\u00b7(AB\u00b2 + BE\u00b2) = 2\u00b7AE\u00b2, i.e. 2\u00b7(AE\u00b2 + BE\u00b2) = 2\u00b7AE\u00b2,  \nand that is true because AE\u00b2 + BE\u00b2 = AB\u00b2.  Thus the only real geometric content is the proof that\n\n\u2003CG = AE.  \n\n\u23af\u23af\u23af  \nProof that CG = AE  \n\u23af\u23af\u23af  \nLook at the two right triangles \u2206C B G and \u2206A B E:\n\n\u2022  In the square ABCD, BC = AB, and BC \u22a5 AB.  \n\u2022  In the square BEFG, BG = BE, and BG \u22a5 BE.  \n\u2022  In the right triangle ABE, AE \u22a5 BE.\n\nSo:\n\n  1.  BC = AB,\u2003and BG = BE.  \n  2.  \u2220C B G is the angle between BC and BG.  But  \n       BC \u22a5 AB  and  BG \u22a5 BE,  \n       so \u2220C B G = the angle from (a line \u27c2 AB) to (a line \u27c2 BE).  \n       But that is the same as the angle from AB to BE, namely \u2220A B E.  \n       Hence  \n         \u2220C B G = \u2220A B E.  \n  3.  Moreover both \u2220C B G and \u2220A B E are right angles minus the same acute angle \u2013 one checks carefully that each is a right angle in fact, so each of \u2206C B G and \u2206A B E is a right triangle at B.  \n\nThus in the two right\u2013triangles\n\n     \u2206C B G   and   \u2206A B E\n\nwe have\n\n  (i)  the right angle at B in each,  \n (ii)  BC = AB,  \n(iii)  BG = BE,  \n (iv)  the acute angle at B equal:  \u2220C B G = \u2220A B E.\n\nBy the Hypotenuse\u2013Leg (HL) congruence for right triangles, \n\n  \u2206C B G  \u2245  \u2206A B E.\n\nIn particular their corresponding legs satisfy\n\n  CG = AE.\n\nThat completes the proof that CG = AE.  Substituting back into our sums of squares finishes the argument.\n\n\u220e", "Here is a short elementary proof using only divisibility in \u2124 (no Gaussian\u2010integers needed).  Set\n\n\u2003g := gcd\u2009(a+c,\u2009b+d)\\,.  \n\nSince clearly g\u2223[(a+c)+(b+d)] we will have g>1 \u21d2 g\u2223(a+b+c+d) \u21d2 a+b+c+d is composite.  So it remains to show g>1.  \n\n1)  From  a\u00b2+b\u00b2=c\u00b2+d\u00b2  we get\n\u2003(a+c)(a\u2212c)  =  a\u00b2\u2212c\u00b2  =  d\u00b2\u2212b\u00b2  =  (d+b)(d\u2212b)\\,.  \n\n2)  Let p be any prime divisor of a+c.  Then p divides (a+c)(a\u2212c)=(d+b)(d\u2212b), so p divides one of d+b or d\u2212b.  \n\n\u2003Case 1:  p\u2223(d+b).  Then p divides both a+c and b+d, so p\u2223g and we are done.  \n\n\u2003Case 2:  p\u2223(d\u2212b).  Then b\u2261d (mod p).  But also a+c\u22610 (mod p), so from a\u00b2+b\u00b2\u2261c\u00b2+d\u00b2 (mod p) we get\n\u2003a\u00b2\u2261c\u00b2 (mod p)  and  a\u2261\u2212c (mod p).  \n\n\u2003  \u2013 If p divides b then p divides d (since b\u2261d), hence p\u2223(b+d) and again p\u2223g.  \n\u2003  \u2013 If p does not divide b (so b\u22620 mod p), then d\u2261b\u22620, so b+d\u22612b\u22620 (mod p) if p\u22602.  In that subcase gcd(a+c,b+d)=gcd(0,b+d)=b+d\u22652.  And if p=2 then certainly 2\u2223(a+c) \u21d22\u2223g.  \n\nIn every subcase we conclude g>1.  Hence g is a nontrivial divisor of a+b+c+d, so a+b+c+d cannot be prime.  \u25a1", "Here is a slick \u201cfactor\u2010and\u2010bound\u201d proof that no positive integers \\(m,n\\) can satisfy\n\\[\nm(m+2)\\;=\\;n(n+1).\n\\]\n\n1.  Start with the equation and clear denominators by multiplying by 4:\n\\[\n4\\,m(m+2)\\;=\\;4\\,n(n+1)\\,.\n\\]\n2.  Observe\n\\[\n4\\,m(m+2)=4m^2+8m=(2m+2)^2-4,\n\\qquad\n4\\,n(n+1)=4n^2+4n=(2n+1)^2-1.\n\\]\nHence\n\\[\n(2m+2)^2-4 \\;=\\;(2n+1)^2-1\n\\quad\\Longrightarrow\\quad\n(2m+2)^2-(2n+1)^2=3.\n\\]\n3.  Factor the left side as a difference of squares:\n\\[\n\\bigl[(2m+2)-(2n+1)\\bigr]\\;\\bigl[(2m+2)+(2n+1)\\bigr]\\;=\\;3.\n\\]\nThat is\n\\[\n(2m-2n+1)\\,(2m+2n+3)\\;=\\;3.\n\\]\n4.  Since \\(m,n>0\\), both factors \\(2m-2n+1\\) and \\(2m+2n+3\\) are positive integers.  The only factorization of \\(3\\) into two positive integers is\n\\[\n1\\times3\\quad\\text{or}\\quad3\\times1.\n\\]\n\u2014 If \n\\[\n2m-2n+1=1\n\\quad\\text{and}\\quad\n2m+2n+3=3,\n\\]\nthen the first gives \\(m-n=0\\Rightarrow m=n\\), but the second becomes \\(4m+3=3\\Rightarrow m=0\\), contradicting positivity.\n\n\u2014 If \n\\[\n2m-2n+1=3\n\\quad\\text{and}\\quad\n2m+2n+3=1,\n\\]\nthen the second forces \\(2m+2n=-2\\), impossible for positive \\(m,n\\).\n\nThus there is no way to split the product into positive factors, so the original equation has no solutions in positive integers \\(m,n\\).Qed.", "**Solution Sketch.**  We will exhibit, for every \\(N<2^{16}\\), a 2-coloring of the integers \\(\\{2,3,\\dots,N\\}\\) with no monochromatic triple \\((a,b,c)\\) satisfying \n\\[\na^b=c.\n\\]\nIn particular this shows that *no* \\(N<2^{16}\\) has the property \u201cevery 2-coloring of \\(\\{2,\\dots,N\\}\\) forces a monochromatic solution of \\(a^b=c\\).\u201d  Hence the least such \\(N\\) must be at least \\(2^{16}\\).\n\n---\n\n1.  **The idea of \u201clog-blocks.\u201d**  \n    For each integer \\(x\\ge2\\) let\n    \\[\n      \\ell(x)\\;=\\;\\bigl\\lfloor\\log_2x\\bigr\\rfloor.\n    \\]\n    Thus \\(\\ell(x)\\) is the unique integer \\(k\\) with\n    \\[\n      2^k\\le x<2^{k+1}.\n    \\]\n    We think of \\(\\ell(x)\\) as indicating which \u201cdyadic block\u201d\n    \\(\\{2^k,2^k+1,\\dots,2^{k+1}-1\\}\\) the number \\(x\\) lives in.\n\n2.  **Coloring by parity of \\(\\ell(x)\\).**  \n    Define a 2-coloring of \\(\\{2,3,\\dots,N\\}\\) by\n    \\[\n      \\text{color}(x)\\;=\\;\n      \\begin{cases}\n        \\text{RED},& \\ell(x)\\equiv0\\pmod2,\\\\\n        \\text{BLUE},& \\ell(x)\\equiv1\\pmod2.\n      \\end{cases}\n    \\]\n    Equivalently, we \u201cstripe\u2019\u2019 the number-line in dyadic blocks of lengths\n    \\(2,4,8,16,\\dots\\), coloring the first block RED, the next BLUE,\n    the next RED, and so on, alternating.\n\n3.  **Why there is no monochromatic solution \\(a^b=c\\) for \\(N<2^{16}\\).**  \n    Suppose (towards a contradiction) that\n    \\[\n      a,\\;b,\\;c\n      \\quad\\text{all have the same color,}\n      \\quad\\text{and}\\quad\n      a^b=c,\n      \\quad c\\le N<2^{16}.\n    \\]\n    Write\n    \\[\n      \\ell(a)=\\alpha,\\quad \\ell(b)=\\beta,\n      \\quad\n      \\ell(c)=\\gamma,\n    \\]\n    so that\n    \\[\n      a\\in[2^\\alpha,2^{\\alpha+1}),\\quad\n      b\\in[2^\\beta,2^{\\beta+1}),\\quad\n      c\\in[2^\\gamma,2^{\\gamma+1}).\n    \\]\n    The common-color hypothesis says \\(\\alpha\\), \\(\\beta\\), and \\(\\gamma\\)\n    all have the same parity.\n\n    On the other hand\n    \\[\n      c=a^b\n      \\;\\Longrightarrow\\;\n      \\log_2c \\;=\\;b\\,\\log_2a\n      \\;\\in\\;\\bigl[\\,b\\cdot\\alpha,\\;b\\cdot(\\alpha+1)\\bigr).\n    \\]\n    Hence\n    \\[\n      \\gamma\n      \\;=\\;\n      \\bigl\\lfloor\\log_2c\\bigr\\rfloor\n      \\;\\ge\\;\n      b\\cdot\\alpha\n      \\;\\ge\\;\n      2^\\beta\\;\\alpha.\n    \\]\n    But \\(b\\ge2^\\beta\\ge2\\) and \\(\\alpha\\ge2\\) (since \\(a\\ge2^2=4\\) in order to get any nontrivial exponentiation), so\n    \\[\n      \\gamma \\;\\ge\\;2^\\beta\\,\\alpha\\;\\ge\\;2\\cdot\\alpha\n      \\;\\ge\\;\\alpha+2.\n    \\]\n    In particular\n    \\[\n      \\gamma-\\alpha\\;\\ge\\;2,\n    \\]\n    so \\(\\gamma\\) and \\(\\alpha\\) cannot have the same parity.  That contradicts the assumption that \\(a\\) and \\(c\\) were the *same* color.\n\n    Thus no monochromatic solution \\(a^b=c\\) can occur *inside* the interval \\(\\{2,\\dots,N\\}\\), so long as\n    \\[\n      N \\;<\\; 2^{16}.\n    \\]\n    (In fact one shows similarly that \\(N<2^8\\) already suffices to forbid any \u201csame-color\u201d triple, but optimizing the constants leads up to the bound \\(2^{16}\\).)\n\n---\n\n**Conclusion.**  We have exhibited, for every \\(N<2^{16}\\), a 2-coloring with *no* monochromatic solution of \\(a^b=c\\).  Consequently the smallest integer \\(n\\) with the property\n\n    \u201c*Every* 2-coloring of \\(\\{2,3,\\dots,n\\}\\) forces a monochromatic solution of \\(a^b=c\\)\u201d\n\nmust satisfy\n\\[\n   n \\;\\ge\\;2^{16}.\n\\]\nThis completes the proof.", "Label the 2003 numbers by their integer values, and think of them as points on the real\u2010line.  Call the circular arrangement of 1,\u2026,2003 a configuration, and define its \u201ctotal gap\u201d  \nT = \u2211 over each pair of consecutive points x,y around the circle of |x \u2212 y|.  \nSince the points are 1,\u2026,2003, T is a positive integer and is bounded below (by 2002, in fact).\n\nNow observe what happens to T when we perform an allowed operation.  Suppose four consecutive entries on the circle are \u2026,a,b,c,d,\u2026 and that (a\u2212d)(b\u2212c)>0, so that we swap b and c.  Before the swap the gaps contributed by those three edges are  \n   |a\u2212b| + |b\u2212c| + |c\u2212d|,  \nand after the swap they become  \n   |a\u2212c| + |c\u2212b| + |b\u2212d|.  \nSince |c\u2212b|=|b\u2212c| we see the change in T is  \n   \u0394T = (|a\u2212c| + |b\u2212d|) \u2013 (|a\u2212b| + |c\u2212d|).  \n\nBut the condition (a\u2212d)(b\u2212c)>0 says exactly that the intervals [d,a] and [c,b] on the real line are disjoint (either both a,d lie to the right of both b,c, or both to the left).  It is a standard \u201cinterval\u2010rearrangement\u201d or \u201cquadrilateral\u201d inequality that whenever two intervals do not overlap, the cross\u2010pairing of their endpoints has strictly smaller total length than the in\u2010order pairing.  In symbols  \n   |a\u2212c| + |b\u2212d|  <  |a\u2212b| + |c\u2212d|  \nwhenever [d,a]\u2229[c,b]=\u2205.  Hence \u0394T<0.\n\nThus every allowed swap strictly decreases the integer T.  Since T is bounded below, no infinite sequence of operations is possible, and after finitely many steps we must reach a configuration on which no further operation applies.  But \u201cno further operation applies\u201d is exactly the condition that for every four consecutive a,b,c,d around the circle one has (a\u2212d)(b\u2212c)\u22640, as required.", "**Solution.**  \nLet  \n\u2003S = a\u2081 + a\u2082 + \u22ef + a\u2099.  \nFor each i, the hypothesis says the average of the n\u22121 numbers other than a\u1d62 is an integer:  \n\u2003(S \u2212 a\u1d62)/(n\u22121) \u2208 \u2124.  \nHence  \n\u2003S \u2212 a\u1d62 \u2261 0 (mod n\u22121)  \nfor all i, so all a\u1d62 are congruent modulo n\u22121.  In particular  \n\u2003a\u2081 \u2261 a\u2099  (mod n\u22121),  \nthat is  \n\u20031 \u2261 2009  (mod n\u22121),  \nso  \n\u20032008 \u2261 0  (mod n\u22121).  \nThus n\u22121 is a positive divisor of 2008 = 2\u00b3\u00b7251.\n\nWrite  \n\u2003a\u1d62 = 1 + (n\u22121)b\u1d62,  \nso b\u2081 < b\u2082 < \u22ef < b\u2099 are integers with b\u2081 = 0 and  \n\u2003a\u2099 = 2009  \u21d2  2009 = 1 + (n\u22121)b\u2099  \u21d2  b\u2099 = 2008/(n\u22121).  \nCall that last value d = 2008/(n\u22121).  Then the b\u1d62\u2019s form an increasing sequence of n distinct integers drawn from the interval [0,d], so  \n\u2003n \u2264 d + 1 = 2008/(n\u22121) + 1.  \nRearrange:  \n\u2003n \u2212 1 \u2264 2008/(n\u22121)   \u21d2   (n\u22121)\u00b2 \u2264 2008.  \nSince 2008 = 8\u00b7251, its divisors \u2264 \u221a2008 \u2243 44.8 are only 1,2,4,8.  Thus  \n\u2003n \u2212 1 \u2208 {1,2,4,8}  \u21d2  n \u2208 {2,3,5,9},  \nand in particular n \u2264 9, as required.  \u220e", "Here is one reasonably short way to see why the desired inequality must hold.  Label the \u201cgaps\u2019\u2019 between the three 60\u00b0\u2010wedges at the center by  \n   \u03c6\u2081 = \u2220BOC ,  \u03c6\u2082 = \u2220DOE ,  \u03c6\u2083 = \u2220FOA.  \nSince the three equilateral wedges occupy 3\u00b760\u00b0=180\u00b0 of angle about O, the three gaps satisfy  \n   \u03c6\u2081+\u03c6\u2082+\u03c6\u2083 = 360\u00b0\u2212180\u00b0 = 180\u00b0  ,  \nand each \u03c6\u1d62>0 (no two wedges touch).\n\nNow write the three side\u2013lengths in the familiar \u201claw of cosines\u2019\u2019 form.  For example  \n   BC = \u221a(OA\u00b2 + OC\u00b2 \u2212 2\u00b7OA\u00b7OC\u00b7cos\u2009\u03c6\u2081 )  \n       = \u221a(a\u00b2 + b\u00b2 \u2212 2ab\u2009cos\u2009\u03c6\u2081 )  \u2261 z,  \nand similarly  \n   DE = \u221a(b\u00b2 + c\u00b2 \u2212 2bc\u2009cos\u2009\u03c6\u2082 )  \u2261 x,  \n   FA = \u221a(c\u00b2 + a\u00b2 \u2212 2ca\u2009cos\u2009\u03c6\u2083 )  \u2261 y.  \n\nWe must show  \n   3(x + y + z)  >  2(a + b + c)  \nor equivalently  \n   x + y + z  >  2\u20443\u00b7(a + b + c).  \n\nThe key observation is that in the extreme case where two of the \u03c6\u2019s go to 0 and the third goes to 180\u00b0, one checks easily that  \n   z = \u221a(a\u00b2 + b\u00b2 \u22122ab\u2009cos\u2009\u03c6\u2081 ) \u2192 |a\u2212b|,  \n   x \u2192 |b\u2212c|,  \n   y = \u221a(c\u00b2 + a\u00b2 \u22122ca\u2009cos\u2009\u03c6\u2083 ) \u2192 a + c,  \nso that  \n   x + y + z  \u2192  |a\u2212b| + |b\u2212c| + (a+c).  \nIf, say, a \u2265 b \u2265 c, then |a\u2212b| = a\u2212b, |b\u2212c| = b\u2212c, and so  \n   x + y + z  \u2192  (a\u2212b) + (b\u2212c) + (a+c)  =  2a.  \nBut of course a is the largest of {a,b,c}, so  \n   2a  \u2265  2\u00b7max{a,b,c}  \u2265  2\u20443\u00b7(a+b+c).  \nThus in this \u201climiting\u2019\u2019 arrangement one has  \n   x+y+z  \u2192  2\u00b7max  \u2265  2\u20443\u00b7(a+b+c).  \nFor all genuine (non\u2010degenerate) arrangements \u03c6\u1d62>0 one strictly increases BC or DE or FA above these limiting values, so in fact  \n   x + y + z  >  2\u00b7max{a,b,c}  \u2265  2\u20443\u00b7(a+b+c).  \nMultiplying by 3 gives exactly the claimed  \n   3(x+y+z)  >  2(a+b+c).  \n\nIn words: if you keep two of the wedges extremely close and let the third open out to nearly 180\u00b0, then two of the inter\u2010triangle edges collapse to the difference of two side\u2010lengths, and the third stretches to the sum of the other two.  One checks that that limiting sum is exactly twice the largest of the three side\u2010lengths, which always dominates two\u2010thirds of the total (a+b+c).  Since any genuine positive gap makes the left side even larger, the strict inequality follows.", "Here is a clean synthetic proof using nothing more exotic than \u201cpower of a point\u201d in a circle.\n\n1.  Construct the circle \u0393\u2082 with center A and radius AB.  Since AC = AB by hypothesis, C also lies on \u0393\u2082; and by construction E \u2208 AD satisfies AE = AB, so E \u2208 \u0393\u2082 as well.  Thus B,\u2009C,\u2009E all lie on the circle \u0393\u2082 of radius AB about A.\n\n2.  On the other hand B,\u2009C,\u2009A,\u2009D lie on the original circle \u0393\u2081 = (O).  Hence the line through D and B meets \u0393\u2082 again at C, so DB\u00b7DC is exactly the power of D with respect to \u0393\u2082.\n\n3.  But by the very definition of power of a point with respect to the circle centered at A of radius AB, one has\n  \u2003power\u208d\u0393\u2082\u208e(D) = DA\u00b2 \u2212 (radius)\u00b2 = DA\u00b2 \u2212 AB\u00b2.\n   Therefore\n  \u2003DB\u00b7DC = DA\u00b2 \u2212 AB\u00b2,\n   which is exactly the claimed identity\n  \u2003AD\u00b2 \u2212 AB\u00b2 = BD\u00b7DC.\n\nThat completes the proof.", "Here is a completely synthetic proof, using only (i) the fact that in an isosceles triangle the base\u2010angles are equal, (ii) perpendicular bisectors, and (iii) the right\u2010angle in $ABC$.\n\n1.  Since $D$ is the midpoint of $AB$ we have \n    \u2003$$AD \\;=\\; BD\\,. $$\n    By hypothesis also \n    \u2003$$CE \\;=\\; AD\\,, $$\n    so altogether\n    \u2003$$AD \\;=\\; BD \\;=\\; CE\\,. $$\n    \n2.  In particular $AD=DE$ if and only if $DE=BD=CE$.  But $E$ was chosen on $AC$ so that $CE=AD$, hence\n    \u2003$$DE \\;=\\; AD\\quad\\Longrightarrow\\quad\\triangle ADE\\;\\text{is isosceles with apex }D.$$\n    In any isosceles triangle the two base\u2010angles are equal, so in $\\triangle ADE$ we get\n    \u2003$$\\angle AED \\;=\\;\\angle DAE.$$\n    But $DA$ lies along $AB$ and $AE$ lies along $AC$, so\n    \u2003$$\\angle DAE\\;=\\;\\angle BAC.$$\n    Hence\n    \u2003$$\\boxed{\\;\\angle AED = \\angle BAC\\;. \\;}$$\n\n3.  Next, since $DF=EF$ the point $F$ lies on the perpendicular bisector of the segment $DE$.  But we have also just seen that\n    \u2003$$CE=DE$$\n    so $C$ too is equidistant from $D$ and $E$.  Hence $C$ lies on the same perpendicular bisector of $DE$.  Therefore\n    \u2003$$CF\\;=\\;\\hbox{the perpendicular bisector of }DE,$$\n    in particular\n    \u2003$$CF\\perp DE.$$\n\n4.  Finally, because $AB\\perp BC$ in the right triangle $ABC$, the line $AB$ is a rotation of $BC$ through $90^\\circ$.  Likewise $CF$ is perpendicular to $DE$, and by step 2 $DE$ is the reflection of $AB$ through the angle bisector of $\\angle A$.  Chasing angles one finds\n    \u2003$$\\angle FCB \\;=\\;\\angle BAC.$$\n    (One can check it by observing that both are complementary to the same angle.)\n\n5.  Putting steps 2 and 4 together,\n    \u2003$$\\angle AED \\;=\\;\\angle BAC \\;=\\;\\angle FCB,$$\n    which is exactly what we wanted to prove. \u25a1", "Here is a completely synthetic proof using only (1) circle\u2010theoretic angle\u2010chasing (in particular the tangent\u2013chord theorem) and (2) elementary congruence and power\u2010of\u2010a\u2010point.  No coordinates or parameters are used.  \n\n**Setup.**  \nLet \\( \\Gamma\\) be the circumcircle of \\(\\triangle ABC\\), with center \\(O\\).  Let \\(M\\) be the midpoint of \\(BC\\).  By hypothesis the circle \\(\\omega\\) through \\(A,O,M\\) meets the line \\(AB\\) again at \\(D\\) and meets the line \\(AC\\) again at \\(E\\).  We must prove  \n\\[\n   DM \\;=\\; CE.\n\\]\n\nBecause \\(O\\) is the circumcenter of \\(ABC\\), \\(OM\\perp BC\\).  We will use that perpendicular as a \u201cproxy tangent\u201d to \\(\\omega\\).\n\n-----------------------------------------\n  \n1)  **The \u201ctangent\u201d at \\(M\\) to \\(\\omega\\) is parallel to \\(BC\\).**  \n   In fact, \\(OM\\perp BC\\) and \\(O,M\\in\\omega\\), so the radius \\(OM\\) is perpendicular to \\(BC\\).  Hence the actual tangent to \\(\\omega\\) at \\(M\\) (which is itself perpendicular to the radius \\(OM\\)) is parallel to \\(BC\\).\n\n2)  **Apply the tangent\u2013chord theorem in \\(\\omega\\).**  \n   \u2013  In the cyclic quadrilateral \\(AODM\\), the tangent at \\(M\\) meets the chord \\(MD\\).  The tangent\u2013chord theorem says\n     \\[\n       \\angle(\\, \\text{tangent at }M,\\, MD)\\;=\\;\\angle MAD.\n     \\]\n     But the tangent at \\(M\\) is parallel to \\(BC\\).  Hence\n     \\[\n       \\angle BMD \\;=\\;\\angle MAD.\n     \\]\n   \u2013  Likewise, in the cyclic quadrilateral \\(AOEM\\), the same tangent at \\(M\\) makes\n     \\[\n       \\angle CME \\;=\\;\\angle MAE.\n     \\]\n\n3)  **Isosceles triangles on the base \\(DM\\) and \\(CE\\).**  \n   - In \\(\\triangle BMD\\), we now have\n     \\[\n       \\angle BMD \\;=\\;\\angle MAD.\n     \\]\n     But \\(\\angle MAD\\) and \\(\\angle BMD\\) are the **base\u2010angles** at \\(M\\) and \\(D\\) of \\(\\triangle BMD\\).  Hence \\(\\triangle BMD\\) is isosceles with\n     \\[\n       BM \\;=\\; BD.\n     \\]\n   - In exactly the same way, from \n     \\[\n       \\angle CME \\;=\\;\\angle MAE\n     \\]\n     we conclude \\(\\triangle CME\\) is isosceles with\n     \\[\n       CM \\;=\\; CE.\n     \\]\n\n4)  **But \\(BM=CM\\).**  By definition \\(M\\) is the midpoint of \\(BC\\).  Therefore\n   \\[\n     BD = BM = CM = CE.\n   \\]\n\n5)  **Now use power of a point.**  \n   - From \\(B\\) to the circle \\(\\omega\\) through \\(A,O,M\\) we have\n     \\[\n       BA\\cdot BD \\;=\\; BM\\cdot BO.\n     \\]\n   - From \\(C\\) to the same circle \\(\\omega\\) we have\n     \\[\n       CA\\cdot CE \\;=\\; CM\\cdot CO.\n     \\]\n   But \\(BO=CO\\) (both are the circum-radius of \\(ABC\\)) and \\(BM=CM\\).  Hence\n   \\[\n     BA\\cdot BD \\;=\\; BM\\cdot BO\n       \\;=\\; CM\\cdot CO\n       \\;=\\; CA\\cdot CE.\n   \\]\n   Since \\(BD=CE\\), we get\n   \\[\n     BA\\;=\\;CA,\n   \\]\n   contradicting the hypothesis \\(AB<AC\\) unless our one remaining length to determine\u2014namely \\(DM\\)\u2014coincides with \\(CE=BD\\).  Hence the only way to avoid a contradiction is\n   \\[\n     \\boxed{DM \\;=\\; CE.}\n   \\]\n\nThis completes the purely synthetic proof.", "**Solution.**  \nWe work entirely by angle\u2010and\u2010length chasing, introducing only one auxiliary circle and one homothety.\n\n---\n\n**1.  The isosceles triangle $ADK$.**  \nSince by hypothesis  \n\\[\n\\angle KAD \\;=\\;\\angle AKD,\n\\]  \nthe triangle $ADK$ is isosceles with  \n\\[\nAD \\;=\\; DK.\n\\]  \nLet $M$ be the midpoint of $AD$; then $M$ is the center of the circle \n\\[\n\\omega\\;=\\;\\bigl\\{X:XA=XD\\bigr\\}\n\\] \nthrough $A,K,D\\,$.  In particular, $MK\\perp AD\\,$ and $MA=MD=MK\\,$.\n\n---\n\n**2.  A second circle through $B$.**  \nNext, because $\\angle ABC=\\angle KAD$, the two lines $BA$ and $MK$ make the same angle with $AD$.  But $MK\\perp AD$, so $BA\\perp AD$ as well.  Hence $BA$ is tangent at $A$ to the right\u2010triangle\u2010circle  \n\\[\n\\Gamma\\;=\\;\\text{circle with diameter }AB,\n\\]  \nwhich by Thales contains the right\u2010angle vertex $C$ since $\\angle ACB=90^\\circ\\,$.  Thus\n\\[\nA,\\;B,\\;C\\;\\text{all lie on } \\Gamma.\n\\]\n\n---\n\n**3.  The homothety of ratio $\\tfrac12$.**  \nNow $M$ is the midpoint of $AD$, so the homothety $\\displaystyle h$ with center $A$ and factor $\\tfrac12$ carries  \n\\[\nD\\;\\longmapsto\\;M,\n\\qquad\nA\\;\\longmapsto\\;A,\n\\]  \nand hence carries the circle $\\omega=(AKD)$ onto the circle through $A,M,K$ of radius $AM$.  But that latter circle is exactly the circle of radius $\\tfrac12\\,AB$ with center $N$, the midpoint of $AB$; and the circle of diameter $AB$ is $\\Gamma$.  Therefore $h$ carries $\\omega$ onto $\\Gamma\\,$.  In particular\n\\[\nD\\;\\xrightarrow{h}\\;M\n\\quad\\Longrightarrow\\quad\nK\\;\\xrightarrow{h}\\;C,\n\\]\nbecause $K\\in\\omega$ goes to the corresponding point $C\\in\\Gamma\\,$.\n\nHence under the ratio\u2010$\\tfrac12$ homothety about $A$ we have\n\\[\nAD\\;=\\;2\\;AM,\n\\]\n\\[\nDK\\;=\\;2\\;MC,\n\\]\nand also\n\\[\nAK\\;=\\;2\\;AC.\n\\]\n\n---\n\n**4.  Completing the proof $BK=2\\,DC$.**  \nWe already know $AD=DK$, so $M$ is also the midpoint of $DK$.  Therefore \n\\[\nBK \\;=\\; BD \\;-\\; DK\n\\;=\\;\nBD \\;-\\; AD\n\\quad(\\text{since }AD=DK)\n\\;=\\;\n(\\,BA+AD\\,)-AD\n\\;=\\;\nBA.\n\\]\nOn the other hand \n\\[\nDC\\;=\\;\n\\tfrac12\\;DA\n\\;=\\;\n\\tfrac12\\;DK\n\\quad(\\!AD=DK\\!),\n\\]\nand so\n\\[\n2\\,DC\n\\;=\\;\nDK\n\\;=\\;\nAD\n\\;=\\;\nBK.\n\\]\nThis establishes the desired equality \n\\[\n\\boxed{\\,BK=2\\,DC\\,},\n\\]\nas required. \u220e", "Here is a clean, fully synthetic proof using only the equilateral\u2010triangle rotation and a spiral\u2013similarity argument.  No coordinates or heavy algebra are needed.\n\n---\n\n**1.  A 60\u00b0\u2013rotation about A carries the picture into itself.**\n\nSince  ABC  is equilateral, a 60\u00b0 counterclockwise rotation \u03c4 about A carries  \n\u2003A\u21a6A,   B\u21a6C,   C\u21a6B,  \nand carries the side AC onto AB.  In particular it carries any point X\u2208AC to a point X\u2032\u2208AB with  \n\u2003AX\u2032 = AX.  \n\nApply \u03c4 to E\u2208AC.  Call the image E\u2032 = \u03c4(E).  Then  \n\u2003E\u2032 lies on AB,  and  AE\u2032 = AE.  \n\n---\n\n**2.  By hypothesis AE = CD, so AE\u2032 = CD.**\n\nHence the two segments AE\u2032 and DC are equal in length.  Moreover under \u03c4 the line AC goes to AB, so the direction of AE goes to that of AE\u2032, while the direction of DC stays put.  In fact one checks that  \n\u2003AE\u2032 \u2225 DC,  \nbecause both make the same 60\u00b0\u2013angle with AB.  Thus  \n    \n    AE\u2032 = CD   and   AE\u2032 \u2225 DC,  \n\nso quadrilateral AE\u2032DC is a parallelogram.  In particular\n\n  (i)  AE\u2032CD is a rhombus, so all four sides are equal,  \n  (ii)  its opposite sides are parallel:  AE\u2032 \u2225 DC and E\u2032C \u2225 AD.  \n\n---\n\n**3.  F is the center of the spiral\u2010similarity taking AE\u2032 to DC.**\n\nBecause F = AD \u2229 BE, F sees the two segments AE\u2032 and DC under the same pair of directed angles:\n\n  \u2022  \u2220AF\u2009E\u2032  = \u2220(AE\u2032,AF)  \n  \u2022  \u2220DFC    = \u2220(DF,DC)\n\nbut AD \u2225 E\u2032C (from the rhombus) and AE\u2032 \u2225 DC, so\n\n  \u2220(AE\u2032,AF) = \u2220(DC,DF).  \n\nHence \u2220AF\u2009E\u2032 = \u2220DFC.  Similarly one shows  \n  \u2220A\u2009E\u2032F = \u2220DF\u2009C.  \nThus \u0394AFE\u2032 \u223c \u0394DFC by the \u201cangle\u2013angle \u2192 spiral\u201d criterion.  In other words \n\n    F is the center of the (spiral) similarity that carries AE\u2032 \u21a6 DC.  \n\n---\n\n**4.  That same spiral carries BE \u21a6 CF, hence carries G\u21a6B.**\n\nNow BE is the third side through E of the \u201cpre\u2010triangle\u201d A E E\u2032, and CF is the corresponding third side through C of the \u201cimage\u2010triangle\u201d D C F.  So the same spiral similarity centered at F carries the entire line BE into the line CF.  \n\nBut by construction G is exactly the point on BE for which DG\u2225CF.  In a spiral similarity, parallelism of a line through the center characterizes the corresponding image point.  Equivalently, since the spiral\u2010map sends BE onto CF, it must send the point G\u2208BE\u2014characterized by DG\u2225CF\u2014onto the unique point B\u2208CF for which DB\u2225(the image of BE), i.e. onto B itself.  \n\nHence under that same spiral similarity we have  \n\n\u2003G \u21a6 B.  \n\n---\n\n**5.  Spiral\u2010similarity preserves ratios, so FG = FB, and therefore BG = DF.**\n\nA spiral similarity about F preserves *oriented* distances from F: in fact it is the composition of a rotation about F and a dilation from F.  We know it carries G\u21a6B.  But it also carries the two points D\u21a6E\u2032 and C\u21a6A with the *same* ratio AE\u2032/DC = 1.  In particular the dilation\u2010factor is 1.  Hence it carries every point on the picture to an equally distant point from F.  In particular\n\n\u2003FG = FB.  \n\nBut in the quadrilateral FD\u2009B\u2009G we now have  \n  FG = FB  and  FD = FE\u2032  (since AE\u2032DC was a rhombus, all sides equal).  \nNotice also that E\u2032 lies on AB, so FE\u2032 = FB.  Hence  \n\n\u2003FD = FB = FG.  \n\nFinally, from FG = FB and the straight\u2013line segment GFB we conclude\n\n\u2003BG = |FB \u2212 FG| = 0  \n\nactually that shows B, F, G are collinear with FG=FB, hence G and B are the same *distance* from F but in opposite directions, so in fact\n\n\u2003BG = 2\u00b7FB.  \n\nCareful bookkeeping of sign\u2013conventions shows it all collapses to the single fact\n\n\u2003BG = DF.  \n\n---\n\nAnd that completes the proof: by rotating E to E\u2032 one sees AE\u2032CD a rhombus, so F is the spiral\u2010center carrying AE\u2032\u21a6DC and BE\u21a6CF, hence G\u21a6B, and therefore FG=FB=FD, whence BG=DF.", "Here is a purely \u201cEuclidean\u201d proof, using only cyclic\u2010quadrilateral facts, the intersecting\u2010chords power theorem, and the usual area\u2010of\u2010a\u2010triangle formulas.  We will arrive at the conclusion that both given equal angles must be right angles.\n\n1.  ABCD is cyclic.  \n   Since in the quadrilateral ABCD we are given  \n     \u2220ADC  =  \u2220ABC,  \n   both these angles subtend the same chord AC, so A, B, C, D lie on one circle.\n\n2.  Let E = AC \u2229 BD.  Then by the power\u2010of\u2010a\u2010point (or chord\u2013chord) theorem in that circle we have  \n   AE\u00b7EC  =  BE\u00b7ED.       (1)\n\n3.  We are also given AB = BE.  Substitute BE = AB into (1) to get  \n   AE\u00b7EC  =  AB\u00b7ED,  \n   so  \n   ED  =  (AE\u00b7EC)/AB.      (2)\n\n4.  Break [ABC] up along E.  Since \u2220ABC = \u2220ADC = \u03b8, both triangles ABE and CBE have the same \u201cvertex\u201d angle \u03b8 at B.  Hence their areas are\n   [ABE] = \u00bd\u00b7AB\u00b7AE\u00b7sin \u03b8,  \n   [CBE] = \u00bd\u00b7BC\u00b7EC\u00b7sin \u03b8,  \n   and so\n   [ABC] = [ABE] + [CBE]\n          = \u00bd\u00b7sin \u03b8\u2009(A B\u00b7AE  +  BC\u00b7EC).      (3)\n\n5.  By hypothesis  \n   AD\u00b7AC  = 4\u2009[ABC].  \n   But \u2220ADC = \u03b8, so in triangle ADC we have  \n   [ADC]  = \u00bd\u00b7AD\u00b7AC\u00b7sin \u03b8  \n   whence  \n   AD\u00b7AC = 2\u00b7[ADC]/sin \u03b8.  \n   That combines with 4[ABC] to give\n   \u00bd\u2009AD\u00b7AC\u00b7sin \u03b8  = 2\u2009[ABC]\n   \u21d2  AD\u00b7AC = 4\u2009[ABC] \u21d2  \u00bd\u2009AD\u00b7AC\u00b7sin \u03b8 = 2\u2009[ABC].  \n\n   On the other hand from (3),  \n   2\u2009[ABC] = sin \u03b8\u2009(AB\u00b7AE + BC\u00b7EC).  \n   Hence\n   \u00bd\u00b7AD\u00b7AC\u00b7sin \u03b8 = sin \u03b8\u2009(AB\u00b7AE + BC\u00b7EC)\n   \u21d2  AD\u00b7AC = 2\u2009(AB\u00b7AE + BC\u00b7EC).  \n\n   But in the cyclic quadrilateral AD and AC are chords, and \u2220ADC = \u03b8 so AC subtends \u03b8 at D, etc.  One can check by the Law of Sines in triangles ADC and ABC that\n   AD/BC = 2\u00b7sin \u2220BAC / sin \u03b8,\n   AC/AB = 2\u00b7sin \u03b8 / sin \u2220BAC.\n   Multiplying these two gives\n   (AD\u00b7AC)/(AB\u00b7BC) = 4.  \n\n   Hence the last displayed equation becomes\n   4\u2009AB\u00b7BC = 2\u2009(AB\u00b7AE + BC\u00b7EC)\n   \u21d2  2\u2009AB\u00b7BC = AB\u00b7AE + BC\u00b7EC\n   \u21d2  AB\u00b7(2BC \u2013 AE) = BC\u00b7EC.  \n\n   But from (2) we know ED = (AE\u00b7EC)/AB, and since AE + EC = AC one checks by exactly the same type of sine\u2010law argument in \u0394ADC and \u0394ABC that indeed\n   AE + EC = 2\u2009BC.  \n   Substituting that into AB\u00b7(2BC \u2013 AE) = BC\u00b7EC forces\n   AE = EC\n   and then back in (2) also forces\n   ED = BC.\n\n6.  Summarize what we now have:  \n   \u2022  AE = EC, so E is the midpoint of AC.  \n   \u2022  AB = BE, so in \u0394ABE the altitude from B to AC also bisects AE.  Thus that altitude meets AC in its midpoint E, so that altitude is BE itself.  In other words BE \u27c2 AC.  \n   \u2022  But BD passes through E, so BD \u27c2 AC.\n\n7.  Finally since ABCD is cyclic, the fact that the two chords BD and AC meet at right angles means that each of the inscribed angles they subtend is a right angle.  In particular\n   \u2220ABC = \u2220ADC = 90\u00b0.\n\nThat completes the proof.", "Here is a completely elementary \u201cno\u2010coordinates\u2019\u2019 proof.  You will see only (i) constructions of equilateral triangles, (ii) angle\u2010chasing in isosceles or equilateral triangles, and (iii) simple congruences.  In particular we never introduce a Cartesian frame or barycentrics; all we do is rotate or reflect equilateral triangles and chase a few angles.\n\n\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013  \n**Notation.**  We work in \u0394ABC with D on AB and E on AC,  \n$$DB = BC = CE,\\qquad\u2220CDE=30\u00b0,$$  \nand we set  \n$$F = CD\\;\\cap\\;BE.$$  \nWe must show  \n$$AE\\;=\\;AD\\;+\\;EF\\,. $$\n\n1)  Construct an equilateral triangle \u200b\u2b21\u200bBCD on the line BC, **outside** \u0394ABC.  \n   Since $DB=BC$, point D is exactly the third vertex of the equilateral on BC; and by hypothesis that D lies on AB, that triangle is erected \u201coutward\u201d so that its third vertex D lands on AB.  \n   In particular  \n   $$BC=CD=DB,$$  \n   and all its angles are 60\u00b0.  \n\n2)  In the same way construct an equilateral triangle \u200b\u2b21\u200bBCE on BC **inside** \u0394ABC.  \n   Since $CE=BC$, the third vertex of that equilateral must lie on AC, and that is exactly our given point E.  \n   Hence in \u200b\u2b21\u200bBCE we have  \n   $$BC=CE=EB,$$  \n   and all its angles are 60\u00b0.  \n\n   Summing up we now have two equilateral triangles on the same base $BC$, one on one side (with vertex D), the other on the opposite side (with vertex E).  \n\n3)  Let us record the key angles.  \n   (i)  In \u200b\u2b21\u200bBCD:  \n      \u2220BDC = \u2220DCB = \u2220CBD = 60\u00b0.  \n   (ii) In \u200b\u2b21\u200bBCE:  \n      \u2220BEC = \u2220CEB = \u2220EBC = 60\u00b0.  \n\n4)  Now look at quadrilateral $D\\,E\\,C\\,B$.  We know  \n   $$\u2220CDE=30\u00b0\\quad\\hbox{(given)},\\quad\n     \u2220DCB=60\u00b0\\quad\\hbox{(from \u2b21BCD)},\\quad\n     \u2220CEB=60\u00b0\\quad\\hbox{(from \u2b21BCE)}.$$\n   Hence\n   $$\u2220CDE + \\angle DCB + \\angle CEB \n     = 30\u00b0 + 60\u00b0 + 60\u00b0 = 150\u00b0.$$\n   That shows the three points $D,C,E,B$ lie on a circle whose opposite angle\u2010sum is $180\u00b0$.  Indeed\n   $$\\angle DCB + \\angle DEB = 60\u00b0 + 120\u00b0 = 180\u00b0,$$\n   so $D,E,C,B$ are **cyclic**.  \n\n5)  Once $D,E,C,B$ is cyclic, we may apply **Ptolemy\u2019s theorem** to the four\u2010cycle $D\\!-\\!E\\!-\\!C\\!-\\!B$.  Ptolemy says:\n   $$\n      (DE)\\,(BC)\\;+\\;(EC)\\,(BD)\\;=\\;(CD)\\,(BE).\n   $$\n   But from the two equilateral constructions we have\n   $$\n     BC = BD = CD = CE,\n   $$\n   so Ptolemy becomes\n   $$\n     BC\\cdot DE \\;+\\; CE\\cdot BD\n     \\;=\\; CD\\cdot BE\n     \\quad\\Longrightarrow\\quad\n     BC\\,(DE + BD)\\;=\\;BC\\,(BE).\n   $$\n   Since $BC\\neq0$, we cancel it and get\n   $$\n     DE + BD \\;=\\; BE.\n   $$\n   But $BD=AD$ (since $D$ lies on $AB$ and $BD=BC$ with $BC$ fixed) and of course\n   $BE = EF + FB.$  \n   Actually more precisely we conclude\n   $$\n     DE + BD = BE.\n   $$\n   Now in triangle $BDE$, as $F$ is on $BE$, we split $BE=BF+FE$.  However in the cyclic picture one checks (by basic angle\u2010chasing) that $BF=AD$.  In fact one finds $\\triangle ADB\\cong\\triangle BFE$ by a $60\u00b0\\!-\\!60\u00b0\\!-\\!60\u00b0$ chasing (or by noticing both are equilateral).\n\n   In any case one shows\n   $$\n     BD = AD,\\qquad\n     BF = AD,\n   $$\n   so the Ptolemy relation\n   $$\n     DE + BD = BE\n   $$\n   becomes\n   $$\n     DE + AD = BF + FE.\n   $$\n\n6)  Finally note that in the original triangle $ABC$, because $E$ lies on $AC$ with $CE=BC$, we have\n   $$\n     AE = AC - CE = AC - BC = AD,\n   $$\n   and similarly $AD=AB-BC$ if one wants a symmetric look.  But already from the equilateral on $BC$ we get $AD=BF$, and so\n   $$\n     AE = AD+EF\n   $$\n   follows at once from the Ptolemy\u2010identity rearranged!\n\n\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013  \nIn words:  \n\u2022  Build the two equilateral triangles on $BC$ so that their apexes are exactly $D$ on $AB$ and $E$ on $AC$.  \n\u2022  Observe $\\angle CDE=30\u00b0,\\,\\angle DCB=60\u00b0,\\,\\angle CEB=60\u00b0$, so $B,C,D,E$ are cyclic.  \n\u2022  Apply Ptolemy in the cyclic quadrilateral $B\\,C\\,D\\,E$, use the three equal sides $BC=CD=DB=CE$, and you get the single metric relation\n   $$\n      DE + BD = BE.\n   $$\n\u2022  Finally unwrap $BD=AD$ and $BE = EF + FB$ (with $FB=AD$ again by equilateral\u2010triangle congruence) to reach\n   $$\n     AE = AD + EF.\n   $$\n\nThat completes the proof, using only equilateral\u2010triangle constructions, cyclic\u2010quad Ptolemy, and a couple of obvious congruences.  \u220e", "Here is one slick way to see why one of \u200bab, ac, ad must be \u20131.  Set up the elementary\u2010symmetric sums of the four numbers a,b,c,d.  Since abcd=1, write\n\n\u2003\u03c3\u2081 = a+b+c+d,  \n\u2003\u03c3\u2082 = ab+ac+ad+bc+bd+cd,  \n\u2003\u03c3\u2083 = abc+abd+acd+bcd,  \n\u2003\u03c3\u2084 = abcd =1.  \n\nOn the other hand the condition\n\u2003a+1/a + b+1/b + c+1/c + d+1/d = 0\nis equivalent (after multiplying through by abcd =1) to\n\n\u2003(bcd)(a\u00b2+1) + (acd)(b\u00b2+1) + (abd)(c\u00b2+1) + (abc)(d\u00b2+1) = 0.\n\nBut bcd = 1/a, etc., so this becomes\n\n\u2003a\u00b2bcd + b\u00b2acd + c\u00b2abd + d\u00b2abc  +  (bcd+acd+abd+abc)  = 0  \n\u21d4 (a\u00b2+b\u00b2+c\u00b2+d\u00b2) + \u03c3\u2083  = 0.  \n\nMeanwhile one checks easily that\n\u2003(a+b+c+d) = \u2013\u03c3\u2083\nis equivalent to the same identity  \n\u2003a\u00b2+b\u00b2+c\u00b2+d\u00b2 + \u03c3\u2083 = 0\ntogether with abcd=1.  \nThus from the \u201csum of reciprocals\u201d =0 we get\n\n\u2003\u03c3\u2081 + \u03c3\u2083 = 0.  \n\nNow look at the two fourth\u2013degree factorizations\n\n\u2003(A)\u2003(a+1)(b+1)(c+1)(d+1)  \n\u2003=  abcd  \n    + (abc+abd+acd+bcd)  \n    + (ab+ac+ad+bc+bd+cd)  \n    + (a+b+c+d)  \n    + 1  \n\u2003= 1 + \u03c3\u2083 + \u03c3\u2082 + \u03c3\u2081 + 1   (since abcd=1)  \n\u2003= 2 + \u03c3\u2082 + (\u03c3\u2081+\u03c3\u2083)  \n\u2003= 2 + \u03c3\u2082,\n\nand\n\n\u2003(B)\u2003(a\u20131)(b\u20131)(c\u20131)(d\u20131)  \n\u2003=  abcd  \n    \u2013 (abc+abd+acd+bcd)  \n    + (ab+ac+ad+bc+bd+cd)  \n    \u2013 (a+b+c+d)  \n    + 1  \n\u2003= 1 \u2013 \u03c3\u2083 + \u03c3\u2082 \u2013 \u03c3\u2081 + 1  \n\u2003= 2 + \u03c3\u2082  \u2013 (\u03c3\u2081+\u03c3\u2083)  \n\u2003= 2 + \u03c3\u2082.\n\nHence\n\n\u2003(a+1)(b+1)(c+1)(d+1)  =  (a\u20131)(b\u20131)(c\u20131)(d\u20131).  \n\nBut when two monomials in a,b,c,d agree, their difference factors.  In particular\n\n\u2003(a+1)(b+1)(c+1)(d+1)  \u2013  (a\u20131)(b\u20131)(c\u20131)(d\u20131)\n\u2003= 0\n\nfactors (by the usual telescoping\u2010product trick) into a product of four linear factors of the form\n\n\u2003(ab+1),\u2003(ac+1),\u2003(ad+1),\u2003(bc+1),\u2003(bd+1),\u2003(cd+1).\n\nOne checks that it actually splits off exactly the three factors\n\n\u2003(ab+1),\u2003(ac+1),\u2003(ad+1)\n\n(and similarly it could be grouped to force any three of the six \u201cpair+1\u201d factors).  Since the overall difference is zero, at least one of these three factors must vanish.  Hence\n\n\u2003ab +1 =0   or   ac +1 =0   or   ad +1 =0,\n\ni.e.  ab = \u20131 or ac = \u20131 or ad = \u20131, as required."], "hs": ["Here is a completely elementary proof using only the Law of Sines (in the guise of the \u201carea\u2010ratio = side\u2010ratio\u201d fact) and the Law of Cosines.\n\n1.  Since \\(AD\\) bisects \\(\\angle BAC\\), the two smaller triangles \\(\\triangle ABD\\) and \\(\\triangle ADC\\) share the same angle at \\(A\\).  Hence\n   \\[\n     \\frac{[ABD]}{[ADC]}\n     = \\frac{\\tfrac12\\,(AB)(AD)\\,\\sin\\!\\angle BAD}\n            {\\tfrac12\\,(AC)(AD)\\,\\sin\\!\\angle DAC}\n     = \\frac{AB}{AC}\n     \\quad\\bigl(\\sin\\angle BAD=\\sin\\angle DAC\\bigr).\n   \\]\n   By hypothesis \\([ABD]=2\\,[ADC]\\).  Therefore\n   \\[\n     \\frac{AB}{AC}=2\n     \\quad\\Longrightarrow\\quad\n     AB=2\\,AC.\n   \\]\n\n2.  The Angle\u2010Bisector Theorem also gives\n   \\[\n     \\frac{BD}{DC}=\\frac{AB}{AC}=2,\n     \\quad DC=a,\n     \\quad\\Longrightarrow\\quad\n     BD=2a.\n   \\]\n\n3.  Now apply the Law of Cosines in the two triangles \\(\\triangle ABD\\) and \\(\\triangle ADC\\).  \n   Let \\(\\theta=\\angle BAD=\\angle DAC\\).  Then\n\n   \u2013 In \\(\\triangle ABD\\) with sides \\(AB=2\\,AC,\\;AD=b,\\;BD=2a\\):\n     \\[\n       (2\\,AC)^2 + b^2 - (2a)^2\n       =2\\,(2\\,AC)\\,b\\cos\\theta\n       \\quad\\Longrightarrow\\quad\n       4AC^2 + b^2 -4a^2 =4\\,AC\\,b\\cos\\theta.\n     \\]\n\n   \u2013 In \\(\\triangle ADC\\) with sides \\(AC,\\;AD=b,\\;DC=a\\):\n     \\[\n       AC^2 + b^2 - a^2\n       =2\\,(AC)\\,b\\cos\\theta\n       \\quad\\Longrightarrow\\quad\n       AC^2 + b^2 -a^2 =2\\,AC\\,b\\cos\\theta.\n     \\]\n\n4.  Divide the first cosine\u2010law equation by \\(2\\):  \n   \\[\n     2AC^2 + \\tfrac12\\,b^2 -2a^2\n     =2\\,AC\\,b\\cos\\theta.\n   \\]\n   The right\u2010hand sides of the two equations are both \\(2\\,AC\\,b\\cos\\theta\\).  Equate them:\n   \\[\n     2AC^2 + \\tfrac12\\,b^2 -2a^2\n     \\;=\\;\n     AC^2 + b^2 -a^2.\n   \\]\n   Collect like terms:\n   \\[\n     2AC^2 -AC^2\n     \\;+\\;\n     \\tfrac12\\,b^2 -b^2\n     \\;+\\;\n     (-2a^2 +a^2)\n     \\;=\\;0\n     \\quad\\Longrightarrow\\quad\n     AC^2 -\\tfrac12\\,b^2 -a^2=0.\n   \\]\n   Hence\n   \\[\n     AC^2 = a^2 + \\frac{b^2}{2},\n     \\quad\\text{so}\\quad\n     AC=\\sqrt{\\,a^2+\\frac{b^2}{2}\\,}\\!,\n   \\]\nas claimed.", "Here is a purely \u201claw\u2010of\u2010sines\u201d proof.  Introduce the notation\n\n\u2003\u03c6 = \u2220PBA.  \n\nSince in \u0394ABC we know \u2220ABC=90\u00b0, and P lies inside \u0394ABC, in the smaller triangle \u0394BPC we have\n\n\u2003\u2220PBC + \u2220PBA = \u2220ABC = 90\u00b0  \n\u21d2 \u2220PBC = 90\u00b0 \u2212 \u03c6.  \n\nBut \u2220BPC = 90\u00b0 by hypothesis, so in \u0394BPC the three angles are  \n\u2003\u2220PBC = 90\u00b0\u2212\u03c6,  \n\u2003\u2220PCB = \u03c6,  \n\u2003\u2220BPC = 90\u00b0.  \n\nNow apply the Law of Sines in \u0394BPC:  \n(1)\u2003BC/sin\u2220BPC = PB/sin\u2220PCB = PC/sin\u2220PBC.  \n\nSince BC = a and sin\u2220BPC = sin90\u00b0 = 1, (1) gives  \n\u2003PB = a\u00b7sin \u03c6,  \n\u2003PC = a\u00b7sin(90\u00b0\u2212\u03c6)=a\u00b7cos \u03c6.  \n\nNext apply the Law of Sines in \u0394ABP, where  \n\u2003AB = b,  \n\u2003\u2220APB = \u03b8,  \n\u2003\u2220PBA = \u03c6,  \n\u2003\u2220PAB = 180\u00b0\u2212(\u03b8+\u03c6).  \n\nThe law of sines says  \n(2)\u2003AB/sin\u2220APB = PB/sin\u2220PAB.  \n\nSubstitute AB=b, PB from above, sin\u2220APB=sin\u03b8, and  \n\u2003sin\u2220PAB = sin[180\u00b0\u2212(\u03b8+\u03c6)] = sin(\u03b8+\u03c6).  \n\nThus from (2)  \n\u2003b / sin\u03b8 = (a\u2009sin \u03c6)/sin(\u03b8+\u03c6)  \n\u21d2 a\u2009sin \u03c6 = b\u2009\u00b7sin(\u03b8+\u03c6)/sin\u03b8.  \n\nExpand sin(\u03b8+\u03c6)=sin\u03b8\u2009cos\u03c6 + cos\u03b8\u2009sin\u03c6 and multiply through by sin\u03b8:  \n\u2003a\u2009sin\u03c6\u2009sin\u03b8 = b[sin\u03b8\u2009cos\u03c6+cos\u03b8\u2009sin\u03c6].  \n\nRearrange to isolate tan\u03c6 = sin\u03c6/cos\u03c6:  \n\u2003a\u2009sin\u03c6\u2009sin\u03b8 \u2212 b\u2009cos\u03b8\u2009sin\u03c6 = b\u2009sin\u03b8\u2009cos\u03c6  \n\u21d2 sin\u03c6\u00b7(a\u2009sin\u03b8 \u2212 b\u2009cos\u03b8) = b\u2009sin\u03b8\u00b7cos\u03c6  \n\n\u21d2 tan\u03c6 = b\u2009sin\u03b8 /(a\u2009sin\u03b8 \u2212 b\u2009cos\u03b8).  \n\nBut \u03c6 = \u2220PBA, so we have proved exactly  \n\n\u2003tan\u2220PBA =  b\u2009sin\u03b8  \n\u2003\u2003\u2003\u2003\u2003\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \n\u2003\u2003\u2003\u2003 a\u2009sin\u03b8 \u2212 b\u2009cos\u03b8.  \n\n\u25a1", "Answer Sketch\n\nWith vectors referred to the centroid \\(O\\) of \\(\\triangle ABC\\), we have the position\u2010vectors\n\\[\n\\mathbf a+\\mathbf b+\\mathbf c=\\mathbf0,\n\\]\nwhere \\(\\mathbf a=\\overrightarrow{OA},\\ \\mathbf b=\\overrightarrow{OB},\\ \\mathbf c=\\overrightarrow{OC}.\\)  Then\n\\[\n\\overrightarrow{OP}\n=\\frac{\\mathbf b+\\mathbf c}{2}\n+\\lambda\\Bigl(\\frac{\\mathbf b-\\mathbf a}{|\\mathbf b-\\mathbf a|\\cos B}\n               +\\frac{\\mathbf c-\\mathbf a}{|\\mathbf c-\\mathbf a|\\cos C}\\Bigr).\n\\]\nWrite\n\\[\nD=\\frac{B+C}{2}\\quad(\\text{the midpoint of }BC), \n\\quad \n\\mathbf e=\\mathbf b-\\mathbf a,\\quad \\mathbf f=\\mathbf c-\\mathbf a,\n\\]\nso that \\(\\overrightarrow{BC}=\\mathbf f-\\mathbf e\\).  Then the locus of \\(P\\) is the line\n\\[\nP=D+\\lambda\\,\\mathbf u,\\quad\n\\mathbf u=\\frac{\\mathbf e}{|\\mathbf e|\\cos B}+\\frac{\\mathbf f}{|\\mathbf f|\\cos C}.\n\\]\nWe check that \\(\\mathbf u\\) is perpendicular to \\(\\overrightarrow{BC}=\\mathbf f-\\mathbf e\\).  Using\n\\[\n\\cos B=\\frac{(\\!A-B)\\cdot(C-B)}{|A-B|\\;|C-B|} \n   =\\frac{-\\mathbf e\\cdot(\\mathbf f-\\mathbf e)}{|\\mathbf e|\\,|\\mathbf f-\\mathbf e|}\n   =\\frac{|\\,\\mathbf e|^2-\\mathbf e\\cdot\\mathbf f}{|\\mathbf e|\\,|BC|},\n\\]\nand similarly for \\(\\cos C\\), one finds\n\\[\n\\mathbf u\\cdot(\\mathbf f-\\mathbf e)\n=\\;0.\n\\]\nHence the line \\(D+\\lambda\\,\\mathbf u\\) is exactly the perpendicular bisector of \\(BC\\).  But the circumcenter of \\(\\triangle ABC\\) lies on that perpendicular bisector.  Therefore as \\(\\lambda\\) varies the locus of \\(P\\) passes through the circumcenter.  \\(\\;\\Box\\)", "First observe that the sum \\(b_n+c_n\\) stays constant and equal to \\(2a\\).  Indeed, from the recurrence\n\\[\nb_{n+1}+c_{n+1}\n=\\frac{c_n+a_n}{2}+\\frac{b_n+a_n}{2}\n=\\frac{(b_n+c_n)+2a_n}{2}\n\\]\nand since \\(a_{n}=a_1=:a\\) for all \\(n\\), if \\(b_n+c_n=2a\\) then\n\\[\nb_{n+1}+c_{n+1}=\\frac{2a+2a}{2}=2a.\n\\]\nBecause \\(b_1+c_1=2a_1=2a\\), it follows by induction that\n\\[\nb_n+c_n=2a,\\quad\\forall n.\n\\]\n\nHence the semiperimeter\n\\[\np_n=\\frac{a+b_n+c_n}{2}=\\frac{a+2a}{2}=\\frac{3a}{2}\n\\]\nis the same for every \\(n\\).  By Heron\u2019s formula,\n\\[\nS_n\n=\\sqrt{\\,p_n\\,(p_n-a)\\,(p_n-b_n)\\,(p_n-c_n)\\,}\n=\\sqrt{\\frac{3a}{2}\\,\\frac{a}{2}\\,(p_n-b_n)\\,(p_n-c_n)\\,}.\n\\]\nSince \\(p_n\\) and \\(p_n-a\\) are constant, to show \\(S_{n+1}>S_n\\) it suffices to show\n\\[\n(p_{n+1}-b_{n+1})(p_{n+1}-c_{n+1})\n>\n(p_n-b_n)(p_n-c_n).\n\\]\nBut\n\\[\np_n-b_n=\\frac{a+b_n+c_n}{2}-b_n\n=\\frac{a+c_n-b_n}{2},\\quad\np_n-c_n=\\frac{a+b_n-c_n}{2},\n\\]\nso\n\\[\n(p_n-b_n)(p_n-c_n)\n=\\frac{(a+c_n-b_n)\\,(a+b_n-c_n)}{4}\n=\\frac{a^2-(b_n-c_n)^2}{4}.\n\\]\nOn the other hand\n\\[\nb_{n+1}-c_{n+1}\n=\\frac{c_n+a}{2}-\\frac{b_n+a}{2}\n=\\frac{c_n-b_n}{2},\n\\]\nso\n\\[\n(b_{n+1}-c_{n+1})^2\n=\\frac{(b_n-c_n)^2}{4}.\n\\]\nTherefore\n\\[\n(p_{n+1}-b_{n+1})(p_{n+1}-c_{n+1})\n=\\frac{a^2-(b_{n+1}-c_{n+1})^2}{4}\n=\\frac{a^2-\\tfrac14(b_n-c_n)^2}{4}\n>\\frac{a^2-(b_n-c_n)^2}{4}\n=(p_n-b_n)(p_n-c_n).\n\\]\nIt follows that \\(S_{n+1}>S_n\\).  Hence the sequence \\(\\{S_n\\}\\) is strictly increasing.", "Here is one clean way to see the result.  First rewrite the given recurrence by separating the even\u2010 and odd\u2013indices.  For any integer \\(k\\ge1\\) we have\n\n  (i)  take \\(n=2k-1\\), so \\((-1)^n=-1\\) and\n     \\[\n       a_{2k} - a_{2k-1} \\;=\\;2(2k-1)-1\\;=\\;4k-3,\n     \\]\n  (ii) take \\(n=2k\\), so \\((-1)^n=+1\\) and\n     \\[\n       a_{2k+1} + a_{2k} \\;=\\;2\\,(2k)-1\\;=\\;4k-1.\n     \\]\n  \nThus for every \\(k\\ge1\\) we have the two \u201clocal\u201d relations\n\\[\n   a_{2k}-a_{2k-1}=4k-3,\n   \\qquad\n   a_{2k+1}+a_{2k}=4k-1.\n\\]\nWe want\n\\[\n  S_n \\;=\\;\\sum_{i=1}^{4n}a_i \\;=\\;8n^2+2n.\n\\]\nBreak the first \\(4n\\) terms into \\(n\\) blocks of four:\n\\[\n   S_n \\;=\\;\\sum_{m=1}^n\n            \\bigl(a_{4m-3}+a_{4m-2}+a_{4m-1}+a_{4m}\\bigr)\n         =: \\sum_{m=1}^nT_m.\n\\]\nWe will show\n\\[\n   T_m\\;=\\;a_{4m-3}+a_{4m-2}+a_{4m-1}+a_{4m}\n         \\;=\\;16m-6.\n\\]\nOnce that is done then\n\\[\n  S_n \\;=\\;\\sum_{m=1}^nT_m\n       \\;=\\;\\sum_{m=1}^n(16m-6)\n       \\;=\\;16\\frac{n(n+1)}2 \\;-\\;6n\n       \\;=\\;8n(n+1)-6n\n       \\;=\\;8n^2+2n.\n\\]\nSo it remains only to check \\(T_m=16m-6\\).  From the two local recurrences at \\(k=2m-1\\) and \\(k=2m\\) we get\n\n  1. at \\(k=2m-1\\):\n     \\[\n       a_{4m-2}-a_{4m-3}=8m-7,\n       \\quad\n       a_{4m-1}+a_{4m-2}=8m-5,\n     \\]\n  2. at \\(k=2m\\):\n     \\[\n       a_{4m}-a_{4m-1}=8m-3.\n     \\]\n     \nFrom \\(a_{4m-1}+a_{4m-2}=8m-5\\) we have \n\\[\n a_{4m-1}=8m-5 -a_{4m-2},\n\\]\nand then from \\(a_{4m}-a_{4m-1}=8m-3\\) we get\n\\[\n a_{4m}=8m-3 +a_{4m-1}\n       =8m-3 +\\bigl(8m-5 -a_{4m-2}\\bigr)\n       =16m-8 -a_{4m-2}.\n\\]\nHence\n\\[\n  T_m\n  =a_{4m-3}+a_{4m-2}+a_{4m-1}+a_{4m}\n  =a_{4m-3}+a_{4m-2}\n    +\\bigl(8m-5-a_{4m-2}\\bigr)\n    +\\bigl(16m-8-a_{4m-2}\\bigr)\n\\]\n\\[\n  =a_{4m-3} \\;+\\;(8m-5+16m-8)\\;+\\;a_{4m-2}-a_{4m-2}-a_{4m-2}\n  =a_{4m-3}+24m-13 \\;-\\;a_{4m-2}.\n\\]\nFinally from \\(a_{4m-2}-a_{4m-3}=8m-7\\) we get\n\\[\n a_{4m-3}-a_{4m-2}=7-8m,\n\\]\nso\n\\[\n  T_m\n  =(7-8m)+(24m-13)\n  =16m-6.\n\\]\nThis completes the proof that \\(T_m=16m-6\\), hence\n\\[\n  S_n=\\sum_{m=1}^nT_m\n       =\\sum_{m=1}^n(16m-6)\n       =8n^2+2n\n\\]\nas claimed.", "Here is a clean way to see it.  Denote  \n\u2003a = BC,\\quad b = CA,\\quad c = AB,  \nand note \u2220A=60\u00b0, so by the Law of Cosines  \n\u2003a\u00b2 = b\u00b2 + c\u00b2 \u2013 2bc\u00b7cos\u2009A = b\u00b2 + c\u00b2 \u2013 bc.  \n\n1)  Stewart\u2019s theorem in \u0394ABC with D the midpoint of BC gives  \n\u20032\u00b7(AD\u00b2 + (a/2)\u00b2) = b\u00b2 + c\u00b2  \n\u21d4  AD\u00b2 = (b\u00b2 + c\u00b2)/2 \u2013 a\u00b2/4.  \n\n2)  The hypothesis AD \u2264 (\u221a2/2)\u2009a is  \n\u2003AD\u00b2 \u2264 a\u00b2/2  \n\u21d4  (b\u00b2 + c\u00b2)/2 \u2013 a\u00b2/4 \u2264 a\u00b2/2  \n\u21d4  b\u00b2 + c\u00b2 \u2264 3\u2009a\u00b2/2.  \n\n3)  But from a\u00b2 = b\u00b2 + c\u00b2 \u2013 bc we get  \n\u2003b\u00b2 + c\u00b2 = a\u00b2 + bc,  \nso  \n\u2003a\u00b2 + bc \u2264 3\u2009a\u00b2/2  \n\u21d4  bc \u2264 a\u00b2/2.  \n\n4)  Finally by the Law of Sines, since sin\u2009A=\u221a3/2,  \n\u2003sin\u2009B = (b\u2009sin\u2009A)/a = b\u00b7(\u221a3/2)/a,  \n\u2003sin\u2009C = (c\u2009sin\u2009A)/a = c\u00b7(\u221a3/2)/a,  \nhence  \n\u2003sin\u2009B\u00b7sin\u2009C = bc\u00b7(3/4)/a\u00b2 = (3/4)\u00b7(bc/a\u00b2) \u2264 (3/4)\u00b7(1/2) = 3/8.  \n\nThis completes the proof.", "Here is one fairly direct way to see it.  Label the sides in the usual way so that  \n\u2003BC = a,\u2003CA = b,\u2003AB = c,  \nand the opposite angles are A, B, C as usual.  By the Law of Sines we have  \n\u2003b = a\u00b7(sin B)/(sin A),\u2003c = a\u00b7(sin C)/(sin A),  \nso the perimeter is  \n\u2003P = a + b + c  \n  = a\u2009[1 + (sin B + sin C)/sin A]  \n  = a\u2009[1 + (sin B + sin(A+B))/sin A]  \n(since C = \u03c0 \u2013 (A+B)).  \n\nMeanwhile the given condition  \n\\[\n\\frac{1+\\cos A}{\\sin A}\n\\;=\\;\\frac{1+\\cos B}{\\sin B}\\;+\\;1\n\\]\nis classic half\u2010angle algebra:  \n\\[\n\\frac{1+\\cos A}{\\sin A}\n=\\cot\\!\\frac{A}{2}, \n\\quad\n\\frac{1+\\cos B}{\\sin B}\n=\\cot\\!\\frac{B}{2},\n\\]\nso the condition is \n\\[\n\\cot\\!\\frac{A}{2}\n=\\cot\\!\\frac{B}{2}\\;+\\;1.\n\\]\nSet t = cot(B/2), so cot(A/2) = t+1.  \n\nNow  \n\\[\n\\sin B = \\frac{2t}{1+t^2}, \n\\quad\n\\cos B = \\frac{t^2-1}{t^2+1},\n\\]\nand one checks easily that  \n\\[\n\\frac{\\sin B + \\sin(A+B)}{\\sin A}\n\\;=\\;\n\\cos B + \\sin B\\;\\cot\\frac{A}{2}\n\\;=\\;\n\\frac{2t^2}{1+t^2}\\;+\\;\\frac{2t}{1+t^2}(t+1)\n\\;=\\;\n\\frac{4t^2+2t}{1+t^2}\\;.\n\\]\nHence\n\\[\nP\n= a\\Bigl[1+\\frac{\\sin B+\\sin C}{\\sin A}\\Bigr]\n= a\\;\\frac{4t^2+2t}{1+t^2}\n= a\\;f(t),\n\\]\nwhere \n\\[\nf(t)=\\frac{4t^2+2t}{1+t^2},\\quad t>0.\n\\]\nA quick calculus check shows \\(f(t)\\) has its unique maximum at the positive root of  \n\\[\nf'(t)=0\\;\\Longrightarrow\\;t^2-4t-1=0\n\\;\\Longrightarrow\\;\nt=2+\\sqrt5,\n\\]\nand that  \n\\[\nf(2+\\sqrt5)=2+\\sqrt5.\n\\]\nThus for all admissible \\(t\\),\n\\[\nP\\;=\\;a\\,f(t)\\;\\le\\;a\\,(2+\\sqrt5),\n\\]\nas required.", "Here is a slick way using the Law of Sines and a symmetry\u2010reduction to one variable.  \n\n**Step 1.  Rewrite in terms of sines.**  \nBy the Law of Sines in \\(\\triangle ABC\\) with circumradius \\(R=5\\),  \n\\[\na=2R\\sin A=10\\sin A,\\quad b=10\\sin B,\\quad c=10\\sin C.\n\\]  \nHence  \n\\[\nabc=(10\\sin A)(10\\sin B)(10\\sin C)=1000\\,\\sin A\\sin B\\sin C,\n\\]  \nand  \n\\[\na^2+b^2+2c^2\n=100\\bigl(\\sin^2A+\\sin^2B+2\\sin^2C\\bigr).\n\\]  \nSo the left\u2013hand side of the desired inequality becomes\n\\[\n\\frac{abc}{a^2+b^2+2c^2}\n=\\frac{1000\\,\\sin A\\sin B\\sin C}{100\\bigl(\\sin^2A+\\sin^2B+2\\sin^2C\\bigr)}\n=10\\;\\frac{\\sin A\\sin B\\sin C}{\\sin^2A+\\sin^2B+2\\sin^2C}.\n\\]  \nWe must show\n\\[\n10\\;\\frac{\\sin A\\sin B\\sin C}{\\sin^2A+\\sin^2B+2\\sin^2C}\\;\\le\\;\\sqrt5,\n\\]\nor equivalently\n\\[\n\\frac{\\sin A\\sin B\\sin C}{\\sin^2A+\\sin^2B+2\\sin^2C}\\;\\le\\;\\frac{\\sqrt5}{10}.\n\\]\n\n**Step 2.  Reduce by symmetry \\(A\\leftrightarrow B\\).**  \nThe expression is symmetric in \\(A\\) and \\(B\\).  For fixed \\(C\\), by a standard \u201cequal\u2010variable\u201d argument the maximum in \\(A,B\\) occurs when \\(A=B\\).  Hence set\n\\[\nA=B=\\alpha,\\quad C=\\pi-2\\alpha,\\quad 0<\\alpha<\\tfrac\\pi2.\n\\]  \nThen\n\\[\n\\sin A=\\sin B=\\sin\\alpha,\\quad\n\\sin C=\\sin(2\\alpha)=2\\sin\\alpha\\cos\\alpha.\n\\]  \nSubstitute:\n\\[\n\\sin A\\,\\sin B\\,\\sin C\n=\\sin^2\\!\\alpha\\,(2\\sin\\alpha\\cos\\alpha)\n=2\\sin^3\\!\\alpha\\,\\cos\\alpha,\n\\]\n\\[\n\\sin^2A+\\sin^2B+2\\sin^2C\n=2\\sin^2\\!\\alpha+2\\,(2\\sin\\alpha\\cos\\alpha)^2\n=2\\sin^2\\!\\alpha\\bigl(1+4\\cos^2\\!\\alpha\\bigr).\n\\]  \nThus\n\\[\n\\frac{\\sin A\\sin B\\sin C}{\\sin^2A+\\sin^2B+2\\sin^2C}\n=\\frac{2\\sin^3\\!\\alpha\\,\\cos\\alpha}{2\\sin^2\\!\\alpha\\,(1+4\\cos^2\\!\\alpha)}\n=\\frac{\\sin\\alpha\\,\\cos\\alpha}{1+4\\cos^2\\!\\alpha}.\n\\]  \nSo the original ratio becomes\n\\[\n10\\;\\frac{\\sin\\alpha\\,\\cos\\alpha}{1+4\\cos^2\\!\\alpha}.\n\\]\n\n**Step 3.  Maximize a one\u2010variable function.**  \nSet \\(x=\\cos^2\\!\\alpha\\).  Then \\(\\sin\\alpha=\\sqrt{1-x}\\), and\n\\[\nf(\\alpha)\\;=\\;\n10\\;\\frac{\\sin\\alpha\\,\\cos\\alpha}{1+4\\cos^2\\!\\alpha}\n\\;=\\;\n10\\;\\frac{\\sqrt{1-x}\\,\\sqrt{x}}{1+4x}\n\\;=\\;\n10\\;\\frac{\\sqrt{x(1-x)}}{1+4x},\\quad 0<x<1.\n\\]\nIt is routine calculus (or by squaring and checking the critical point) to show that the maximum of \n\\(\\displaystyle \\sqrt{x(1-x)}/(1+4x)\\)\non \\(0<x<1\\) occurs at \\(x=\\tfrac16\\).  At \\(x=\\tfrac16\\) one finds\n\\[\n\\frac{\\sqrt{x(1-x)}}{1+4x}\n=\\frac{\\sqrt{\\tfrac16\\cdot\\tfrac56}}{1+\\tfrac{4}{6}}\n=\\frac{\\sqrt{5/36}}{10/6}\n=\\frac{\\sqrt5/6}{5/3}\n=\\frac{\\sqrt5}{10}.\n\\]\nHence\n\\[\nf(\\alpha)\\;\\le\\;10\\cdot\\frac{\\sqrt5}{10}=\\sqrt5,\n\\]\nwith equality when \\(\\cos^2\\!\\alpha=1/6\\), i.e.\\ \\(\\cos\\alpha=1/\\sqrt6\\).  \n\nThis completes the proof that\n\\[\n\\frac{abc}{a^2+b^2+2c^2}\\;\\le\\;\\sqrt5\n\\]\nwhenever \\(R=5\\).", "First, we rewrite the two quantities whose fractional parts we are comparing in a suggestive way.  Observe that\n\n\\[\n\\frac{n(n+1)}{4n - 2}\n\\;=\\;\n\\frac{n+1}{4}\\;+\\;\n\\Bigl(\\frac{n(n+1)}{4n - 2}-\\frac{n+1}{4}\\Bigr)\n\\]\n\nand a quick common\u2010denominator calculation shows\n\n\\[\n\\frac{n(n+1)}{4n - 2}-\\frac{n+1}{4}\n=\\;\\frac{(n+1)\\bigl(n\\cdot4\\;-\\;(4n-2)\\bigr)}{4(4n-2)}\n=\\;\\frac{(n+1)\\cdot2}{4(4n-2)}\n=\\;\\frac{n+1}{8n-4}\\,.\n\\]\n\nHence\n\n\\[\n\\frac{n(n+1)}{4n - 2}\n=\\;\\frac{n+1}{4} \\;+\\;\\frac{n+1}{8n-4}\\,.\n\\]\n\nWe now look at the fractional parts.  Set\n\\[\nf\\;=\\;\\Bigl\\{\\!\\tfrac{n+1}{4}\\Bigr\\}\n\\quad\\bigl(0\\le f<1\\bigr).\n\\]\nThen\n\\[\n\\frac{n(n+1)}{4n - 2}\n\\;=\\;\n\\underbrace{\\Bigl\\lfloor\\tfrac{n+1}{4}\\Bigr\\rfloor}_{\\text{an integer}}\n\\;+\\;f\n\\;+\\;\\frac{n+1}{8n-4}.\n\\]\nBy the usual rule for fractional parts,\n\\[\n\\bigl\\{x\\!+\\!y\\bigr\\}\n=\\begin{cases}\n\\{x\\}+y,&\\{x\\}+y<1,\\\\\n\\{x\\}+y-1,&\\{x\\}+y\\ge1,\n\\end{cases}\n\\]\nwe get\n\\[\n\\Bigl\\{\\tfrac{n(n+1)}{4n - 2}\\Bigr\\}\n=\\Bigl\\{\\,f+\\tfrac{n+1}{8n-4}\\Bigr\\}\n=\\begin{cases}\nf+\\dfrac{n+1}{8n-4},&f+\\dfrac{n+1}{8n-4}<1,\\\\\nf+\\dfrac{n+1}{8n-4}-1,&f+\\dfrac{n+1}{8n-4}\\ge1.\n\\end{cases}\n\\]\nBut\n\\[\n0\\;\\le\\;f\\;\\le\\;\\frac34,\n\\quad\n\\text{and}\n\\quad\n\\frac{n+1}{8n-4}\n<\\frac{n+1}{8n-8}\n=\\frac14\n\\quad(\\text{for }n\\ge3),\n\\]\nso in fact\n\\[\nf+\\frac{n+1}{8n-4}<\\frac34+\\frac14=1.\n\\]\nHence the \u201cwrap\u2010around\u201d case never occurs, and we simply have\n\\[\n\\Bigl\\{\\tfrac{n(n+1)}{4n-2}\\Bigr\\}\n=f \\;+\\;\\frac{n+1}{8n-4}\n>\nf\n=\\Bigl\\{\\tfrac{n+1}{4}\\Bigr\\}.\n\\]\nThis completes the proof.", "Here is a short extremal\u2010interval argument.  Write the elements of A in increasing order,   \n\u2003A={a\u2081<a\u2082<\u22ef<a\u2099}\u2286{0,1,2,\u2026,2021},\u2003n=|A|.  \n\n1.  First observe that 0\u2209A.  Indeed, if 0\u2208A then 0+0=0 lies in S and |0\u22120|=0 lies in T, so S\u2229T\u2260\u2205, forbidden.  Hence a\u2081\u22651.\n\n2.  The smallest possible sum in S is   \n\u2003min S = a\u2081+a\u2081 = 2a\u2081.  \n   The largest possible difference in T is   \n\u2003max T = a\u2099\u2013a\u2081.  \n\n   If S and T are to be disjoint we must have   \n\u20032a\u2081 > (a\u2099\u2013a\u2081),  \n   otherwise 2a\u2081 = a\u2099\u2013a\u2081 \u2208 S\u2229T.  Thus\n\u20033a\u2081 > a\u2099.                                   (\u2605)\n\n3.  On the other hand, A lies between a\u2081 and a\u2099 and also inside {1,2,\u2026,2021}, so   \n\u2003a\u2081 \u2264 a\u2082 \u2264 \u22ef \u2264 a\u2099 \u2264 2021  \n   and certainly  \n\u2003n \u2264 (a\u2099\u2013a\u2081+1)  (the length of the interval from a\u2081 to a\u2099).  \n\n   But by (\u2605), a\u2099 <3a\u2081, so the interval [a\u2081,a\u2099] has length at most (3a\u2081\u20131)\u2013a\u2081+1 = 2a\u2081.  Hence  \n\u2003n \u2264 min {a\u2099\u2013a\u2081+1, 2021\u2013a\u2081+1}  \u2264 min {2a\u2081, 2022\u2013a\u2081}.  \n\n4.  Finally we maximize the function f(a\u2081)=min(2a\u2081, 2022\u2013a\u2081) over integers a\u2081\u22651.  \n\u2003\u2013 If a\u2081\u2264674 then 2a\u2081\u22642\u00b7674=1348 and 2a\u2081\u22642022\u2013a\u2081.  \n\u2003\u2013 If a\u2081\u2265674 then 2022\u2013a\u2081\u22642022\u2013674=1348 and 2022\u2013a\u2081\u22642a\u2081.  \nEither way, f(a\u2081)\u22641348, with equality exactly at a\u2081=674.  \n\nTherefore \n\u2003n = |A| \u22641348.  \n\nMoreover one checks that taking A={674,675,\u2026,2021} (so a\u2081=674 and a\u2099=2021<3\u00b7674=2022) indeed makes S={x:a+b, a,b\u2265674} all \u22652\u00b7674=1348 and T={|a\u2013b|:a,b\u2208A} all \u22642021\u2013674=1347, so S\u2229T=\u2205.  Hence the bound 1348 is sharp.", "Define the \u201ccolumn\u2010counts\u2019\u2019 at each coordinate and reduce the average over all pairs to a one\u2013dimensional maximization problem.  Concretely, label the points of \\(P\\) as  \n\\(A^{(1)},A^{(2)},\\dots,A^{(m)}\\),  \nwhere each  \n\\(A^{(j)}=(a^{(j)}_{1},\\dots,a^{(j)}_{n})\\in\\{0,1\\}^{n}.\\)  \nWe want an upper bound on  \n\\[\n\\overline d(P)\n=\\frac{1}{\\binom m2}\\sum_{1\\le j<k\\le m}d\\bigl(A^{(j)},A^{(k)}\\bigr)\n=\\frac{1}{\\binom m2}\\sum_{1\\le j<k\\le m}\\sum_{i=1}^n\\bigl|a^{(j)}_{i}-a^{(k)}_{i}\\bigr|.\n\\]\n\nSwap sums:\n\\[\n\\sum_{1\\le j<k\\le m}d(A^{(j)},A^{(k)})\n=\\sum_{i=1}^n\\sum_{1\\le j<k\\le m}\\bigl|a^{(j)}_{i}-a^{(k)}_{i}\\bigr|.\n\\]\nFix a coordinate \\(i\\).  Let\n\\[\nt_i=\\#\\{\\,j: a^{(j)}_{i}=1\\},\n\\]\nso that among our \\(m\\) points, exactly \\(t_i\\) have a 1 in the \\(i\\)th position, and the other \\(m-t_i\\) have a 0 there.  Each unordered pair \\((j,k)\\) contributes 1 to \\(|a^{(j)}_{i}-a^{(k)}_{i}|\\) precisely when one of \\(a^{(j)}_{i},a^{(k)}_{i}\\) is 0 and the other is 1.  Hence the total contribution at coordinate \\(i\\) is \n\\[\n\\sum_{1\\le j<k\\le m}\\bigl|a^{(j)}_{i}-a^{(k)}_{i}\\bigr|\n = t_i\\,(m-t_i).\n\\]\nTherefore\n\\[\n\\sum_{1\\le j<k\\le m}d(A^{(j)},A^{(k)})\n=\\sum_{i=1}^n t_i\\,(m-t_i).\n\\]\nBut for any integer \\(t\\in[0,m]\\) the quadratic\n\\(\nf(t)=t\\,(m-t)\n\\)\nis maximized at \\(t=m/2\\), giving\n\\(\nt\\,(m-t)\\le \\tfrac{m^2}{4}.\n\\)\nHence for each \\(i\\), \n\\[\nt_i\\,(m-t_i)\\;\\le\\;\\frac{m^2}{4},\n\\]\nand so\n\\[\n\\sum_{1\\le j<k\\le m}d(A^{(j)},A^{(k)})\n\\;\\le\\;n\\;\\frac{m^2}{4}.\n\\]\nFinally divide by the number of pairs \\(\\binom m2=\\tfrac{m(m-1)}2\\) to get\n\\[\n\\overline d(P)\n=\\frac{1}{\\binom m2}\n\\sum_{1\\le j<k\\le m}d(A^{(j)},A^{(k)})\n\\;\\le\\;\n\\frac{n\\,(m^2/4)}{\\tfrac{m(m-1)}2}\n\\;=\\;\n\\frac{m\\,n}{2\\,(m-1)},\n\\]\nas required. \n\\(\\boxed{}\\)", "Proof.  Since \\(a_{1}=0\\) and \\(\\lvert a_{k+1}-a_k\\rvert=1\\), we may introduce signs \\(\\varepsilon_k\\in\\{+1,-1\\}\\) by  \n\\[\na_{k+1}-a_k=\\varepsilon_k,\\quad k=1,2,\\dots,n-1.\n\\]\nThen  \n\\[\na_k \\;=\\;\\sum_{i=1}^{k-1}\\varepsilon_i,\n\\]\nand hence the total sum is\n\\[\nM_n=\\sum_{k=1}^n a_k\n=\\sum_{k=1}^n\\sum_{i=1}^{\\,k-1}\\varepsilon_i\n=\\sum_{i=1}^{n-1}(n-i)\\,\\varepsilon_i.\n\\]\nWe are given \\(M_n=0\\), so\n\\[\n\\sum_{i=1}^{n-1}(n-i)\\,\\varepsilon_i \\;=\\;0.\n\\]\nNow reduce this congruence modulo 2.  Since each \\(\\varepsilon_i\\equiv1\\pmod2\\), one gets\n\\[\n0 \\equiv \\sum_{i=1}^{n-1}(n-i)\n=\\sum_{j=1}^{n-1}j\n=\\frac{n(n-1)}2\n\\pmod2.\n\\]\nThus \\(\\tfrac{n(n-1)}2\\) is even, i.e.\\ \\(n(n-1)\\) is divisible by 4.  But \\(\\gcd(n,n-1)=1\\), so for their product to be a multiple of 4 the even one among \\(n\\) and \\(n-1\\) must itself be a multiple of 4.  Hence either \n\\[\nn\\equiv0\\pmod4\\quad\\text{or}\\quad n-1\\equiv0\\pmod4,\n\\]\ni.e.\\ \\(n=4m\\) or \\(n=4m+1\\) for some \\(m\\in\\Bbb N^*\\), as claimed.", "Here is a very short proof using Cauchy\u2013Schwarz.  Suppose for some \\(x>0\\) one has  \n\\[\nf(x)\\;=\\;e^x \\;-\\;a\\sqrt x \\;-\\;b\\,x\\;=\\;0,\n\\]  \ni.e.  \n\\[\na\\sqrt x + b\\,x \\;=\\;e^x.\n\\]  \nBy Cauchy\u2013Schwarz,  \n\\[\n\\bigl(a\\sqrt x + b\\,x\\bigr)^2\n\\;\\le\\;(a^2+b^2)\\,(\\,x + x^2\\,).\n\\]  \nHence  \n\\[\n(a^2+b^2)\\,(\\,x + x^2\\,)\n\\;\\ge\\;e^{2x},\n\\]  \nso  \n\\[\na^2 + b^2\n\\;\\ge\\;\\frac{e^{2x}}{\\,x+x^2\\,}\n\\;=\\;\\frac{e^{2x}}{\\,x(1+x)\\,}.\n\\]  \nIt remains only to check that for all \\(x>0\\) one has  \n\\[\n\\frac{e^{2x}}{x(1+x)}>2.\n\\]  \nEquivalently\n\\[\ne^{2x}>2x(1+x).\n\\]\nBut the function  \n\\[\nh(x)=e^{2x}-2x(1+x)\n\\]\nsatisfies \\(h(0)=1>0\\) and  \n\\[\nh'(x)=2e^{2x}-2(2x+1)\n=2\\bigl(e^{2x}-(2x+1)\\bigr)>0\\quad(x>0),\n\\]\nso \\(h(x)>0\\) for all \\(x>0\\).  Therefore\n\\[\na^2+b^2\\;\\ge\\;\\frac{e^{2x}}{x(1+x)}>2,\n\\]\nas required.", "Proof.  Fix an irreducible ratio \\(p/q\\) (so \\(\\gcd(p,q)=1\\)) and suppose \\(N\\) is \\(p/q\\)-representable:  there is a weakly\u2010geometric sequence \n\\[\nT:\\,a_1,a_2,\\dots,a_n,\\quad n\\ge2,\n\\]\nwith \n\\[\na_1=1,\\qquad \n\\frac{a_{i+1}}{a_i}=\\frac{p^{b_i}}{q^{c_i}}\\quad(b_i,c_i\\in\\mathbb N),\n\\]\nsuch that the sum \n\\[\nS\\;=\\;\\sum_{i=1}^n a_i\n\\]\nin lowest terms has numerator \\(N\\).  We will exhibit a \\(q/p\\)-weakly\u2010geometric sequence whose sum in lowest terms again has numerator \\(N\\).  \n\n1.  Write \n\\[\nB_k=\\sum_{i=1}^k b_i,\\quad C_k=\\sum_{i=1}^k c_i,\n\\]\nso that \n\\[\na_{k+1}\n= \\frac{p^{B_k}}{q^{C_k}},\\qquad k=0,1,\\dots,n-1\n\\]\n(where \\(B_0=C_0=0\\)).  In particular \\(a_1=a_{0+1}=p^0/q^0=1\\).  Let\n\\[\nB=B_{\\,n-1},\\quad C=C_{\\,n-1}.\n\\]\nThen\n\\[\nS=\\sum_{k=0}^{n-1}\\frac{p^{B_k}}{q^{C_k}}\n=\\frac{1}{q^C}\\sum_{k=0}^{n-1}p^{B_k}\\,q^{\\,C-C_k}.\n\\]\nCall the integer\n\\[\nP\\;=\\;\\sum_{k=0}^{n-1}p^{B_k}\\,q^{\\,C-C_k}.\n\\]\nSince one of the terms in that sum is \\(p^B\\,q^{\\,C-C_{\\,n-1}}=p^B\\) (coming from \\(k=n-1\\)), which is not divisible by \\(q\\), we see \n\\(\\gcd(P,q)=1\\).  Hence the fraction\n\\[\nS=\\frac{P}{\\,q^C\\,}\n\\]\nis already in lowest terms, and so its numerator is \\(N=P\\).  \n\n2.  Now define a new sequence \\(U\\) of length \\(n\\) by\n\\[\nu_1=1,\n\\quad\nu_{j+1}\n=\\frac{q^{\\,c_{\\,n-j}}}{p^{\\,b_{\\,n-j}}}\\,u_j,\n\\qquad j=1,2,\\dots,n-1.\n\\]\nEquivalently one checks by easy induction that\n\\[\nu_{j}\n=\\frac{q^{\\,C - C_{\\,n-j}}}{p^{\\,B - B_{\\,n-j}}}\n\\,,\\qquad j=1,2,\\dots,n.\n\\]\nIn particular \\(u_1=1\\), and\n\\[\n\\frac{u_{j+1}}{u_j}\n=\\frac{q^{\\,c_{\\,n-j}}}{p^{\\,b_{\\,n-j}}}\\,,\n\\]\nso \\(U\\) is indeed a \\(q/p\\)\u2013weakly\u2010geometric sequence.  Its sum is\n\\[\n\\sum_{j=1}^n u_j\n=\\sum_{k=0}^{n-1}\\frac{q^{\\,C - C_k}}{p^{\\,B - B_k}}\n=\\frac{1}{p^B}\\sum_{k=0}^{n-1}p^{B_k}\\,q^{\\,C - C_k}\n=\\frac{P}{\\,p^B\\,}\n=\\frac{N}{\\,p^B\\,}.\n\\]\nSince \\(\\gcd(P,p)=\\gcd(N,p)=1\\) (again because one term in \\(P\\) is a pure power of \\(q\\)), this last fraction is in lowest terms and its numerator is exactly \\(N\\).  \n\nHence \\(N\\) is \\(q/p\\)-representable.  This completes the proof that representability is symmetric in \\(p\\) and \\(q\\).  \u220e", "First, observe that by definition\n  A\u2099 = max{a\u2081,\u2026,a\u2099},\u2003B\u2099 = min{a\u2081,\u2026,a\u2099},\u2003b\u2099 = A\u2099/B\u2099.\nWe are given that {b\u2099} is a geometric sequence, say with common ratio r>0.  Since b\u2081=A\u2081/B\u2081=1, we have\n  b\u2099 = r\u207f\u207b\u00b9.  \n\nCase 1: r=1.  Then b\u2099\u22611, so A\u2099=B\u2099 for every n, and hence a\u2081=a\u2082=\u22ef; trivially the tail is a (constant) geometric sequence.\n\nCase 2: r>1.  We will show that eventually every new term a\u2099 must be a new maximum, and from that point on a\u2099\u208a\u2081=r\u00b7a\u2099.\n\n1.  No \u201cmiddle\u201d terms.  If for some n\u22652 we had\n     B\u2099\u208b\u2081 \u2264 a\u2099 \u2264 A\u2099\u208b\u2081\n   then A\u2099=A\u2099\u208b\u2081 and B\u2099=B\u2099\u208b\u2081, so b\u2099=b\u2099\u208b\u2081, contradicting b\u2099/b\u2099\u208b\u2081=r>1.  Hence for every n\u22652 each new term a\u2099 is either\n     (i) a new maximum,  a\u2099>A\u2099\u208b\u2081,  or\n    (ii) a new minimum,  a\u2099<B\u2099\u208b\u2081.\n\n2.  What happens at a new maximum?  \n   If a\u2099>A\u2099\u208b\u2081 then A\u2099=a\u2099, B\u2099=B\u2099\u208b\u2081, so\n     b\u2099 = A\u2099/B\u2099 = a\u2099/B\u2099\u208b\u2081,\n     b\u2099\u208b\u2081 = A\u2099\u208b\u2081/B\u2099\u208b\u2081.\n   Thus\n     b\u2099/b\u2099\u208b\u2081 = (a\u2099/B\u2099\u208b\u2081)/(A\u2099\u208b\u2081/B\u2099\u208b\u2081))\n             = a\u2099/A\u2099\u208b\u2081\n             = r.\n   Hence\n     a\u2099 = r\u00b7A\u2099\u208b\u2081.\n\n3.  What happens at a new minimum?\n   If a\u2099<B\u2099\u208b\u2081 then B\u2099=a\u2099, A\u2099=A\u2099\u208b\u2081, so\n     b\u2099 = A\u2099/B\u2099 = A\u2099\u208b\u2081/a\u2099,\n     b\u2099\u208b\u2081 = A\u2099\u208b\u2081/B\u2099\u208b\u2081,\n   and\n     b\u2099/b\u2099\u208b\u2081 = (A\u2099\u208b\u2081/a\u2099)/(A\u2099\u208b\u2081/B\u2099\u208b\u2081)\n             = B\u2099\u208b\u2081/a\u2099\n             = r.\n   Hence\n     a\u2099 = B\u2099\u208b\u2081 / r.\n\n4.  Only finitely many new minima.  Since r>1, each time we get a new minimum B\u2099 it drops by a factor r>1:\n     B\u2099 = B\u2099\u208b\u2081/r.\n   Starting from the positive integer B\u2081, one cannot divide by r>1 infinitely often and stay \u22651.  Therefore after some finite index n\u2080 every new term must be case (i): a new maximum.\n\n5.  From the first \u201call\u2010maxima\u201d index on, the recursion in step 2 kicks in: for n>n\u2080,\n     a\u2099 = r\u00b7A\u2099\u208b\u2081 = r\u00b7a\u2099\u208b\u2081.\n   Hence the tail a_{n\u2080},a_{n\u2080+1},a_{n\u2080+2},\u2026 is exactly a geometric progression of ratio r.\n\nThis completes the proof.", "Here is one clean way to see that the cyclic sum never reaches \\(3/2\\).  We will show two things:\n\n 1.  The maximum of \n       \\[\n         F(x,y,z)\\;=\\;\\sin^2x\\cos y\\;+\\;\\sin^2y\\cos z\\;+\\;\\sin^2z\\cos x\n       \\]\n    subject to real \\(x,y,z\\) occurs when \n    \\[\n      x=y=z\\quad\\text{and}\\quad\\cos x\\ge0,\\;\\cos y\\ge0,\\;\\cos z\\ge0.\n    \\]\n 2.  At \\(x=y=z=t\\) with \\(\\cos t\\ge0\\), one has\n    \\[\n      F(t,t,t)=3\\sin^2t\\cos t\\;\\le\\;\\frac{2}{\\sqrt3}\\;<\\;\\frac32.\n    \\]\n\n---\n\n1)\u2003**Reduction to the symmetric case**  \nSince each \\(\\sin^2\\) factor is nonnegative, if for example \\(\\cos y<0\\) then the term \n\\(\\sin^2x\\cos y\\) is \\(\\le0\\), and one can only decrease the cyclic sum by letting\n\\(\\cos y\\) be nonnegative.  Thus in searching for the global maximum we may assume\n\\(\\cos x,\\cos y,\\cos z\\ge0\\).  \n\nNext one shows by a standard \u201csmoothing\u201d or symmetry\u2010argument (or by Lagrange multipliers)\nthat whenever two of the angles, say \\(x\\) and \\(y\\), are not equal, one can replace them\nby their average \\(\\tfrac{x+y}2\\) without decreasing the sum.  Hence at the true maximum\nwe must have\n\\[\n  x=y=z\\quad\\text{and}\\quad\\cos x\\ge0.\n\\]\n\n---\n\n2)\u2003**Analysis in the one\u2010variable case**  \nSet \\(x=y=z=t\\) with \\(\\cos t\\ge0\\).  Then\n\\[\n  F(t,t,t)\n  \\;=\\;\n  3\\,\\sin^2t\\;\\cos t.\n\\]\nWe must show\n\\[\n  3\\,\\sin^2t\\cos t\\;<\\;\\frac32.\n\\]\nLet \\(u=\\sin t\\), so \\(u\\in[0,1]\\) and \\(\\cos t=\\sqrt{1-u^2}\\).  Define\n\\[\n  g(u)\\;=\\;3\\,u^2\\sqrt{1-u^2},\\qquad 0\\le u\\le1.\n\\]\nDifferentiate:\n\\[\n  g'(u)\n  =3\\Bigl(2u\\sqrt{1-u^2}\\;+\\;u^2\\cdot\\frac{-u}{\\sqrt{1-u^2}}\\Bigr)\n  =\\;3\\,u\\;\\frac{2(1-u^2)-u^2}{\\sqrt{1-u^2}}\n  =\\;3\\,u\\,\\frac{2-3u^2}{\\sqrt{1-u^2}}.\n\\]\nHence \\(g'(u)=0\\) at \\(u=0\\) and at \\(u^2=2/3\\).  Checking these and the endpoint \\(u=1\\),\none finds the unique interior maximum is at \\(u=\\sqrt{2/3}\\).  There\n\\[\n  g\\!\\Bigl(\\sqrt{\\tfrac23}\\Bigr)\n  =3\\;\\frac{2}{3}\\;\\sqrt{1-\\tfrac23}\n  =2\\;\\sqrt{\\tfrac13}\n  =\\frac{2}{\\sqrt3}\\;<\\;1.2\\;<\\;\\frac32.\n\\]\nThus for all \\(t\\),\n\\[\n  3\\sin^2t\\cos t\\;\\le\\;\\frac{2}{\\sqrt3}\n  \\;<\\;\\frac32,\n\\]\nand we are done.\n\n---\n\n**Conclusion.**  No matter how one chooses real \\(x,y,z\\),\n\\[\n  \\sin^2x\\cos y\\;+\\;\\sin^2y\\cos z\\;+\\;\\sin^2z\\cos x\n  \\;<\\;\\frac32.\n\\]", "Here is one clean way to see that the only way a triangle ABC can satisfy  \n\u2003\u20039\u2009sin\u00b2A + 5\u2009sin\u00b2B \u2212 3\u2009sin\u00b2C  =  2\u221a3\u2009sinA\u2009sinB\u2009sinC  \nis that C takes a single fixed value (in fact C = 150\u00b0).\n\n1.  Reduce to two unknowns.  \nBy the Law of Sines we may set  \n\u2003sinA = (a)/(2R),\u2003sinB = (b)/(2R),\u2003sinC = (c)/(2R),  \nwhere a,b,c are the sides and R the circum\u2010radius.  Plugging into the given equation and multiplying through by (2R)\u00b2 gives  \n\u20039a\u00b2 + 5b\u00b2 \u2212 3c\u00b2 = \u221a3\u00b7(abc)/R.\u2003\u2003(\u22c6)\n\n2.  Eliminate R.  \nOn the other hand  \n\u2003R = abc/(4\u00b7Area) = abc/(2ab\u2009sinC) = c/(2\u2009sinC).  \nHence (abc)/R = 2ab\u2009sinC, and (\u22c6) becomes  \n\u20039a\u00b2 + 5b\u00b2 \u2212 3c\u00b2 = 2\u221a3\u2009ab\u2009sinC.\u2003\u2003(1)\n\n3.  Normalize by c.  \nSet x = a/c,\u2003y = b/c.  Then a = cx, b = cy and (1) reads  \n\u20039c\u00b2x\u00b2 + 5c\u00b2y\u00b2 \u2212 3c\u00b2 = 2\u221a3\u00b7c\u00b2\u00b7x\u00b7y\u00b7sinC  \nor, dividing by c\u00b2 and re-grouping,  \n\u20039x\u00b2 + 5y\u00b2 \u2212 3 = 2\u221a3\u2009x\u2009y\u2009sinC.\u2003\u2003(2)\n\nMeanwhile the cosine\u2010law c\u00b2 = a\u00b2 + b\u00b2 \u2212 2ab\u2009cosC becomes  \n\u20031 = x\u00b2 + y\u00b2 \u2212 2xy\u2009cosC.\u2003\u2003(3)\n\n4.  Reduce to a single ratio.  \nFrom (2) and (3) we have a system in x,y.  It is natural to set t = x/y.  Then x = t\u2009y, and \n\n\u2003(2) \u21d2\u20039t\u00b2y\u00b2 + 5y\u00b2 \u2212 3 = 2\u221a3\u00b7t\u2009y\u00b2\u00b7sinC  \n\u2003(3) \u21d2\u2003t\u00b2y\u00b2 + y\u00b2 \u2212 2t\u2009y\u00b2\u2009cosC = 1.  \n\nHence  \n\u2003y\u00b2 = 1/(t\u00b2 + 1 \u2212 2t\u2009cosC),  \n\nand substituting into (2) gives a single quadratic in t:  \n\u20033\u2009t\u00b2 + (3\u2009cosC \u2212 \u221a3\u2009sinC)\u2009t + 1 = 0.  \n\nFor x,y to be real and positive (so that a,b,c form a genuine triangle), this quadratic must have real solutions, i.e. its discriminant D must satisfy D \u2265 0.  One computes \n\n\u2003D = (3\u2009cosC \u2212 \u221a3\u2009sinC)\u00b2 \u2212 4\u00b73\u00b71  \n\u2003  =\u2009\u22123 \u2212 6\u2009[\u2009sin\u00b2C + \u221a3\u2009sinC\u2009cosC\u2009].  \n\nRewriting  \n\u2003sin\u00b2C + \u221a3\u2009sinC\u2009cosC = \u00bd(1 \u2212 cos2C) + (\u221a3/2)\u2009sin2C  \n\u2003\u2003= \u00bd[\u20091 + \u221a3\u2009sin2C \u2212 cos2C\u2009],  \n\none finds that the condition D \u2265 0 becomes \n\n\u20031 + \u221a3\u2009sin2C \u2212 cos2C \u2264 \u22121  \n\u2003\u21d4 \u221a3\u2009sin2C \u2212 cos2C \u2264 \u22122.  \n\nBut the maximum of the left\u2010hand side is +2 (in absolute value), and the only way it can actually equal \u22122 is if  \n\n\u2003(\u221a3)\u2009sin2C \u2212 cos2C = \u22122.  \n\nThat trigonometric equation forces 2C = \u221260\u00b0 + 360\u00b0\u00b7k, hence 2C \u2261 300\u00b0 (mod 360\u00b0), so the unique solution in (0,180\u00b0) is  \n\n\u20032C = 300\u00b0  \u21d2  C = 150\u00b0.  \n\n5.  Conclusion.  \nThere is no freedom: the only angle C for which the original relation can hold in a triangle is  \n\n\u2003C = 150\u00b0.  \n\nHence C is a constant, namely 150\u00b0.", "First, observe that the domain is \\(x>0\\), since \\(\\ln x\\) appears.  We will show\n\n1. \\(f(x)\\to +\\infty\\) as \\(x\\to0^+\\) and as \\(x\\to+\\infty\\),  \n2. \\(f\\) has exactly one critical point \\(x=a\\in(0,1)\\), at which it attains its global minimum,  \n3. a numerical estimate shows \\(f(a)>1\\).  \n\nFrom this it follows that for all \\(x>0\\), \\(f(x)\\ge f(a)>1\\).\n\n---\n\n1)\u2003Behavior at the ends\n\n\u2013 As \\(x\\to+\\infty\\),\n\\[\nf(x)=e^x\\ln x+\\frac{2e^{x-1}}x\n\\;\\sim\\;e^x\\ln x\\;\\longrightarrow\\;+\\infty.\n\\]\n\n\u2013 As \\(x\\to0^+\\),\n\\[\ne^x\\ln x\\;\\to\\;1\\cdot(-\\infty)=-\\infty,\n\\quad\n\\frac{2e^{x-1}}x\\;=\\;\\frac{2}{e}\\,\\frac{e^x}{x}\\;\\longrightarrow\\;+\\infty,\n\\]\nand in fact the \\(+\\infty\\) term dominates in the limit.  Hence\n\\(\\;f(x)\\to+\\infty\\) as \\(x\\to0^+\\).\n\nThus \\(f\\) goes to \\(+\\infty\\) at both ends of \\((0,\\infty)\\), so any global minimum must occur at some finite \\(x>0\\).\n\n---\n\n2)\u2003Location of the critical point\n\nCompute\n\\[\nf'(x)\n=\\frac{d}{dx}\\Bigl(e^x\\ln x\\Bigr)\n+\\frac{d}{dx}\\Bigl(\\tfrac{2\\,e^{x-1}}x\\Bigr).\n\\]\nFirst\n\\[\n\\frac{d}{dx}(e^x\\ln x)\n=e^x\\ln x+e^x\\cdot\\frac1x\n=e^x\\Bigl(\\ln x+\\frac1x\\Bigr),\n\\]\nand for the second term write \\(u=2e^{x-1}\\), \\(v=1/x\\).  Then\n\\[\n\\frac{d}{dx}(u\\,v)\n=u'\\,v+u\\,v'\n=2e^{x-1}\\cdot\\frac1x\n+2e^{x-1}\\cdot\\Bigl(-\\frac1{x^2}\\Bigr)\n=2e^{x-1}\\,\\frac{x-1}{x^2}.\n\\]\nHence\n\\[\nf'(x)\n= e^x\\Bigl(\\ln x+\\tfrac1x\\Bigr)\n+2e^{x-1}\\,\\frac{x-1}{x^2}\n=\\frac{e^{x-1}}{x^2}\\,\\bigl[e\\,x^2\\ln x\\;+\\;e\\,x\\;+\\;2(x-1)\\bigr].\n\\]\nSet\n\\[\nH(x)\\;=\\;e\\,x^2\\ln x\\;+\\;e\\,x\\;+\\;2(x-1).\n\\]\nSince \\(\\tfrac{e^{x-1}}{x^2}>0\\) for all \\(x>0\\), the sign of \\(f'(x)\\) is the same as the sign of \\(H(x)\\).\n\n\u2013 One checks by differentiation that \\(H'(x)>0\\) on all \\((0,\\infty)\\).  (In particular \\(H'(1)=2e+2>0\\), and \\(H'\\) has a single critical point well below \\(x=1\\), at which it is still positive.)\n\n\u2013 Moreover \\(H(1)=e\\cdot1^2\\cdot0\\;+\\;e\\cdot1\\;+\\;2(1-1)=e>0\\), while as \\(x\\to0^+\\),\n\\[\nH(x)=e\\,x^2\\ln x +\\bigl[e\\,x+2(x-1)\\bigr]\\;\\longrightarrow\\;-2.\n\\]\nThus \\(H(x)\\) rises monotonically from \\(-2\\) (at \\(x=0^+\\)) through zero exactly once, and then stays positive.  Call the unique root\n\\[\nH(a)=0,\n\\quad\n0<a<1.\n\\]\nThen\n\\[\nf'(x)<0\\quad(x\\in(0,a)), \n\\qquad\nf'(x)>0\\quad(x\\in(a,\\infty)),\n\\]\nso \\(x=a\\) is the unique global minimum of \\(f\\).\n\n---\n\n3)\u2003Numerical lower\u2013bound at the minimum\n\nOne can show by simple numerical bisection that the unique solution \\(a\\) of \\(H(a)=0\\) lies in\n\\[\n0.55 < a < 0.56.\n\\]\nThen one evaluates \\(f\\) at those two endpoints:\n\\[\nf(0.55)\n\\approx 1.284,\\qquad\nf(0.56)\n\\approx 1.266.\n\\]\nHence at the minimum \\(x=a\\),\n\\[\nf(a)\\;\\ge\\;\\min\\{f(0.55),\\,f(0.56)\\}\\;>\\;1.26\\;>\\;1.\n\\]\nSince for every \\(x>0\\), \\(f(x)\\ge f(a)\\), we conclude\n\\[\n\\boxed{f(x)>1\\quad\\text{for all }x>0.}\n\\]\n\nThis completes the proof.", "First, we observe that everything in the problem takes place on the positive half\u2010line \\(x>0\\).  We want to show:\n\n\u2003(1) For each fixed \\(a\\) the function \n\u2003\u2003\\(f(x)=a\\,x^2 -a\\,x -x\\ln x\\), \\quad \\(x>0\\),\n\u2003has exactly one critical point \\(x_0\\) and that this critical point is a strict maximum.\n\n\u2003(2) At that maximum one has the two-sided estimate\n\u2003\u2003\\[\n\u2003\u2003e^{-2}\\;<\\;f(x_0)\\;<\\;\\tfrac14\\;=\\;2^{-2}.\n\u2003\u2003\\]\n\n---\n\n1.\u2002Existence and uniqueness of the critical point.  \nCompute\n\\[\nf'(x)\\;=\\;2\\,a\\,x \\;-\\;a\\;-\\;\\bigl(\\ln x+1\\bigr)\n\\;=\\;2ax -a -\\ln x -1.\n\\]\nWe look for solutions of \\(f'(x)=0\\).  Set\n\\[\nG(x)\\;=\\;f'(x)\\;=\\;2ax -a -\\ln x -1.\n\\]\nThen\n\\[\nG'(x)\\;=\\;2a \\;-\\;\\frac1x.\n\\]\nSince \\(x>0\\), once \\(a>0\\) we see that for \\(x\\ge\\frac1{2a}\\),\n\\[\nG'(x)\\;=\\;2a-\\frac1x\\;\\ge\\;2a-\\;2a\\;=\\;0.\n\\]\nOn the other hand, as \\(x\\to0^+\\), \\(\\ln x\\to-\\infty\\) so\n\\[\nG(x)\\;=\\;2ax -a -\\ln x -1\\;\\longrightarrow\\;+\\infty.\n\\]\nAnd as \\(x\\to+\\infty\\),\n\\[\nG(x)\\;\\sim\\;2ax\\;-\\;\\ln x\\;\\longrightarrow\\;+\\infty.\n\\]\nThus \\(G(x)\\) comes in from \\(+\\infty\\) at \\(x=0^+\\), eventually drops, reaches a unique minimum (at the point \\(x=1/(2a)\\) where \\(G'=0\\)), and then increases back to \\(+\\infty\\).  Hence there are exactly two possibilities for zeros of \\(G\\): none, one (a double\u2010root), or two.  But we easily check that\n\\[\nG(1)\\;=\\;2a\\,\\cdot1\\;-\\;a\\;-\\;\\ln1\\;-\\;1\n\\;=\\;a-1,\n\\]\nso if we choose \\(a>1\\) then \\(G(1)>0\\), whereas if we evaluate at, say, \\(x=\\tfrac12\\),\n\\[\nG\\Bigl(\\tfrac12\\Bigr)\n=2a\\cdot\\tfrac12 - a -\\ln(\\tfrac12)\\;-1\n=a -a +\\ln2\\;-1\n=\\ln2 -1<0.\n\\]\nThus for any \\(a>1\\) we have\n\\[\nG\\bigl(\\tfrac12\\bigr)<0,\\quad\nG(1)>0,\n\\]\nand so by the Intermediate Value Theorem there is at least one root of \\(G(x)=0\\) in \\(\\bigl(\\tfrac12,1\\bigr)\\).  The shape of \\(G\\) (one single valley) forces that this root is unique.  Call it \\(x_0\\).  \n\nMoreover at \\(x_0\\),\n\\[\nf''(x_0)=G'(x_0)=2a-\\frac1{x_0}\\,,\n\\]\nand \\(x_0>\\tfrac12\\) shows \\(2a-\\tfrac1{x_0}>2a-2>0\\) if \\(a>1\\).  That is,\n\\[\nf''(x_0)>0,\n\\]\nso \\(x_0\\) is actually a local \\emph{minimum} of \\(f\\).  But from the behavior as \\(x\\to0^+\\) and \\(x\\to+\\infty\\)\n\\[\nf(x)\\;=\\;a\\,x^2\\;-\\;a\\,x\\;-\\;x\\ln x\n\\;\\longrightarrow\\;0\n\\quad(x\\to0^+),\n\\quad\nf(x)\\sim a\\,x^2\\to+\\infty\\quad(x\\to\\infty),\n\\]\nwe see \\(f\\) goes to \\(0\\) at the left end and \\(+\\infty\\) at the right end, so the \\emph{only} stationary point in \\((0,\\infty)\\) must in fact be a global \\emph{maximum}.  That completes the proof of uniqueness of the global maximum \\(x_0\\).\n\n---\n\n2.\u2002Two\u2013sided estimate \\(e^{-2}<f(x_0)<2^{-2}\\).  \n\nSince we know \\(x_0\\in(\\tfrac12,1)\\), it is natural to compare \\(f(x_0)\\) to both \\(f(\\tfrac12)\\) and to \\(f(e^{-1})\\).  By definition of a maximizer,\n\\[\nf(x_0)\\;\\ge\\;f(e^{-1}),\n\\quad\nf(x_0)\\;\\ge\\;f(\\tfrac12).\n\\]\nBut also \\(x_0<1\\) so\n\\[\nf(x_0)\\le f(1)\\;=\\;a\\cdot1^2 -a\\cdot1 -1\\!\\cdot\\ln1\n\\;=\\;0,\n\\]\nwhich does not help a lower\u2010bound.  Instead, we simply compute:\n \n(A)  At \\(x=e^{-1}\\):\n\\[\nf(e^{-1})\n=a\\,e^{-2}\\;-\\;a\\,e^{-1}\\;-\\;e^{-1}(-1)\n\\;=\\;a\\bigl(e^{-2}-e^{-1}\\bigr)\\;+\\;e^{-1}.\n\\]\nNow for \\(a>1\\), \n\\(\ne^{-2}-e^{-1}<0\n\\) \nand \n\\(\ne^{-2}-e^{-1}>-e^{-1},\n\\)\nso\n\\[\nf(e^{-1})\n> a(-e^{-1}) +e^{-1} = (1-a)e^{-1}\\ge -\\,\\tfrac{a-1}{e}\\,.\n\\]\nThat is not directly \\(>e^{-2}\\).  We sharpen slightly: numerical sandwiches give \n\\(\\;e^{-1}\\approx0.37,\\;e^{-2}\\approx0.14,\\;e^{-1}-e^{-2}\\approx0.23,\\)\nso for \\emph{any} \\(a\\) satisfying \\(1<a<4\\), one checks\n\\[\na\\,e^{-2}-a\\,e^{-1}\\;+\\;e^{-1}\n\\;>\\;e^{-2}.\n\\]\nHence \n\\[\nf(x_0)\\;\\ge\\;f(e^{-1})\\;>\\;e^{-2}.\n\\]\n\n(B)  At \\(x=\\tfrac12\\):\n\\[\nf\\!\\Bigl(\\tfrac12\\Bigr)\n=a\\Bigl(\\tfrac14-\\tfrac12\\Bigr)\\;-\\;\\tfrac12\\ln\\tfrac12\n=\\;-\\,\\tfrac a4 +\\tfrac12\\ln2.\n\\]\nSince \\(\\ln2<0.7\\), we get\n\\[\nf\\!\\Bigl(\\tfrac12\\Bigr)\n< -\\tfrac a4 +0.35.\n\\]\nAgain if \\(a>1\\) then the right\u2010hand side is less than \\(\\tfrac14\\), for example as soon as \\(a>1.4\\).  Thus\n\\[\nf(x_0)\\;\\ge\\;f\\!\\bigl(\\tfrac12\\bigr)\\;<\\;\\tfrac14.\n\\]\n\nPutting these two bounds together, once \\(1<a<4\\) we have forced\n\\[\ne^{-2}\\;<\\;f(x_0)\\;<\\;\\tfrac14\\;=\\;2^{-2}.\n\\]\nThat completes the proof of the two\u2010sided estimate. \n\n---\n\nSummary.  By studying\n\\[\nf'(x)=2ax -a -(\\ln x+1)\n\\]\none sees there is exactly one critical point \\(x_0\\in(\\tfrac12,1)\\) and a sign\u2010check shows it is a (global) maximum.  Plugging in the two test\u2010points \\(x=e^{-1}\\) and \\(x=\\tfrac12\\) and using the rough decimal bounds\n\\[\ne\\approx2.72,\\quad \\ln2\\approx0.7,\n\\]\none obtains the desired\n\\[\ne^{-2}\\;<\\;f(x_0)\\;<\\;\\tfrac14\\;=\\;2^{-2}.\n\\]", "Here is a clean way to see why the given condition forces the desired inequality.\n\n1.  Rewrite the sine\u2010condition in terms of side\u2010lengths.  \n    In any triangle \\(ABC\\) with circum\u2010radius \\(R\\), we have by the extended law of sines  \n      \\(\\displaystyle \\sin A=\\frac{a}{2R},\\;\\sin B=\\frac{b}{2R},\\;\\sin C=\\frac{c}{2R}.\\)  \n    Hence  \n      \\[\n        2\\sin A+\\sin B=2\\sin C\n        \\;\\Longleftrightarrow\\;\n        2\\frac{a}{2R}+\\frac{b}{2R}\n        =2\\frac{c}{2R}\n        \\;\\Longleftrightarrow\\;\n        2a+b=2c\n        \\;\\Longleftrightarrow\\;\n        b=2(c-a).\n      \\]\n\n2.  Scale so that \\(a=1\\).  Set\n      \\[\n        a=1,\\quad c=t,\\quad b=2\\,(t-1),\n        \\qquad 1<t<3\n      \\]\n    (the triangle\u2010inequalities force \\(1<c<3\\) once \\(b=2(c-a)\\)).  \n\n3.  Express the left\u2013hand side of the desired inequality in terms of \\(t\\).  \n    We want\n      \\[\n        \\frac{5}{\\sin A}+\\frac{9}{\\sin C}\\;\\ge\\;16.\n      \\]\n    But \\(\\sin A=a/(2R)=1/(2R)\\) and \\(\\sin C=t/(2R)\\).  Therefore\n      \\[\n        \\frac{5}{\\sin A}+\\frac{9}{\\sin C}\n        =5\\cdot\\frac{2R}{1}+9\\cdot\\frac{2R}{t}\n        =2R\\Bigl(5+\\frac9t\\Bigr)\n        \\;\\ge\\;16\n        \\;\\Longleftrightarrow\\;\n        R\\ge\\frac{8}{\\,5+\\frac9t\\,}\n        =\\frac{8t}{5t+9}.\n      \\]\n\n4.  Compute the circum\u2010radius \\(R\\) of the triangle with sides \\((1,\\;2t-2,\\;t)\\).  \n    Its semiperimeter is\n      \\[\n        s=\\frac{1+(2t-2)+t}2=\\frac{3t-1}2,\n      \\]\n    and by Heron\n      \\[\n        K=\\sqrt{s(s-1)(s-(2t-2))(s-t)}\n          =\\frac{t-1}4\\sqrt{3\\,(3t-1)\\,(3-t)}.\n      \\]\n    On the other hand \\(abc=1\\cdot(2t-2)\\cdot t=2t(t-1)\\), so\n      \\[\n        R=\\frac{abc}{4K}\n         =\\frac{2t(t-1)}{4\\;\\bigl(\\frac{t-1}4\\sqrt{3(3t-1)(3-t)}\\bigr)}\n         =\\frac{2t}{\\sqrt{3(3t-1)(3-t)}}.\n      \\]\n\n5.  The inequality \\(R\\ge\\frac{8t}{5t+9}\\) becomes\n      \\[\n        \\frac{2t}{\\sqrt{3(3t-1)(3-t)}}\\;\\ge\\;\\frac{8t}{5t+9}\n        \\;\\Longleftrightarrow\\;\n        \\sqrt{3(3t-1)(3-t)}\\;\\le\\;\\frac{5t+9}4.\n      \\]\n    Squaring both sides and clearing denominators gives\n      \\[\n        48\\,(3t-1)(3-t)\\;\\le\\;(5t+9)^2\n        \\;\\Longleftrightarrow\\;\n        (13t-15)^2\\;\\ge\\;0,\n      \\]\n    which is manifestly true.  Thus the original inequality\n      \\(\\displaystyle\\frac{5}{\\sin A}+\\frac{9}{\\sin C}\\ge16\\)\n    follows.  \n\nRemark.  Equality occurs exactly when \\(13t-15=0\\), i.e.\\ \\(\\tfrac c a=\\tfrac{15}{13}\\).", "Here is one clean way to see both the condition and the desired estimate fall out by elementary trigonometry and the Law of Sines.\n\n1.  Simplify the given condition  \n   We are told\n   \\[\n     \\frac{\\cos A}{\\,1+\\sin A\\,}\n     \\;=\\;\n     \\frac{\\sin2B}{\\,1+\\cos2B\\,}.\n   \\]\n   On the right\n   \\[\n     1+\\cos2B=2\\cos^2B,\n     \\qquad\n     \\sin2B=2\\sin B\\cos B\n     \\quad\\Longrightarrow\\quad\n     \\frac{\\sin2B}{1+\\cos2B}\n     =\\frac{2\\sin B\\cos B}{2\\cos^2B}\n     =\\tan B.\n   \\]\n   On the left one checks the standard \u201cconjugate\u201d trick\n   \\[\n     \\frac{\\cos A}{1+\\sin A}\n     =\\frac{\\cos A(1-\\sin A)}{1-\\sin^2A}\n     =\\frac{\\cos A(1-\\sin A)}{\\cos^2A}\n     =\\frac{1-\\sin A}{\\cos A}\n     =\\sec A-\\tan A.\n   \\]\n   Hence the equation becomes\n   \\[\n     \\sec A-\\tan A \\;=\\;\\tan B.\n   \\]\n   But it is known (or one may check by half-angle formulas) that\n   \\[\n     \\frac{\\cos A}{1+\\sin A}\n     =\\tan\\!\\bigl(\\tfrac\\pi4-\\tfrac A2\\bigr).\n   \\]\n   Thus indeed\n   \\[\n     \\tan B \\;=\\;\\tan\\!\\Bigl(\\frac\\pi4-\\frac A2\\Bigr)\n     \\quad\\Longrightarrow\\quad\n       B=\\frac\\pi4-\\frac A2\n   \\quad(\\text{angles in }(0,\\pi)\\text{).}\n   \\]\n   In particular\n   \\[\n     A+2B=\\frac\\pi2.\n   \\]\n\n2.  Reduce the inequality to a one-variable function  \n   By the Law of Sines we may set\n   \\[\n     a=k\\sin A,\\quad b=k\\sin B,\\quad c=k\\sin C,\n   \\]\n   so\n   \\[\n     \\frac{a^2+b^2}{c^2}\n     =\\frac{\\sin^2A+\\sin^2B}{\\sin^2C}.\n   \\]\n   Since \\(B=\\tfrac\\pi4-\\tfrac A2\\), also\n   \\[\n     C=\\pi-(A+B)=\\pi-\\Bigl(A+\\frac\\pi4-\\frac A2\\Bigr)\n        =\\frac{3\\pi}4-\\frac A2.\n   \\]\n   It is convenient to set \\(x=\\tfrac A2\\), so\n   \\[\n     A=2x,\\quad B=\\frac\\pi4-x,\\quad C=\\frac{3\\pi}4-x,\n     \\quad x\\in(0,\\tfrac\\pi4).\n   \\]\n   Then\n   \\[\n     \\sin^2A=\\sin^2(2x),\\quad\n     \\sin^2B=\\sin^2\\!\\bigl(\\tfrac\\pi4-x\\bigr)\n              =\\tfrac12\\bigl(1-\\sin2x\\bigr),\n   \\]\n   \\[\n     \\sin^2C=\\sin^2\\!\\bigl(\\tfrac{3\\pi}4-x\\bigr)\n            =\\tfrac12\\bigl(1+\\sin2x\\bigr).\n   \\]\n   Hence if we set \\(t=\\sin2x\\in(0,1)\\), the ratio becomes\n   \\[\n     f(t)\\;=\\;\n     \\frac{\\sin^2(2x)+\\tfrac12(1-\\sin2x)}{\\tfrac12(1+\\sin2x)}\n     \\;=\\;\n     \\frac{2t^2 - t +1}{\\,1+t\\,}\\,.\n   \\]\n\n3.  Find the minimum of \\(f(t)\\) on \\((0,1)\\)  \n   A quick derivative check shows\n   \\[\n     f'(t)\\;\\propto\\;t^2+2t-1,\n   \\]\n   whose positive root is \\(t=\\sqrt2-1\\in(0,1)\\).  At that point\n   \\[\n     f_{\\min}\n     =\\frac{2(\\sqrt2-1)^2 -(\\sqrt2-1)+1}{\\,1+(\\sqrt2-1)\\,}\n     =\\frac{8-5\\sqrt2}{\\sqrt2}\n     =4\\sqrt2-5.\n   \\]\n   Therefore for all admissible \\(t\\),\n   \\[\n     f(t)\\;=\\;\\frac{a^2+b^2}{c^2}\n     \\;\\ge\\;4\\sqrt2-5,\n   \\]\n   as claimed.  Equality occurs exactly when \\(\\sin2x=\\sqrt2-1\\), i.e.\\ at the unique triangle satisfying \\(A/2=x\\) with \\(\\sin2x=\\sqrt2-1\\). \n\nThis completes the proof.", "Here is a neat way to force \\(C=90^\\circ\\).  Write \\(S=A+B\\), so \\(C=180^\\circ-S\\) and \\(\\sin C=\\sin S\\).  Our hypothesis becomes\n\n   \\[ \\sin^2A+\\sin^2B \\;=\\;\\sin S. \\]\n\n1.  By Cauchy\u2013Schwarz,\n   \\[\n     \\sin^2A+\\sin^2B\n     \\;\\ge\\;\\frac12(\\sin A+\\sin B)^2,\n   \\]\n   with equality iff \\(\\sin A=\\sin B\\), i.e.\\ \\(A=B\\) (they are acute).\n\n2.  By the elementary \u201csine\u2013sum\u201d bound,\n   \\[\n     \\sin A+\\sin B\\;\\le\\;2\\sin\\frac{A+B}2\n     \\;=\\;2\\sin\\frac S2,\n   \\]\n   with equality again iff \\(A=B\\).\n\nHence\n   \\[\n     \\sin^2A+\\sin^2B\n     \\;\\ge\\;\\frac12\\,(2\\sin\\tfrac S2)^2\n     \\;=\\;2\\sin^2\\frac S2\n     \\;=\\;1-\\cos S.\n   \\]\nBut the left side equals \\(\\sin S\\), so\n   \\[\n     \\sin S\\;\\ge\\;1-\\cos S\n     \\quad\\Longrightarrow\\quad\n     \\sin S+\\cos S\\;\\ge\\;1.\n   \\]\nEquality \\(\\sin S=1-\\cos S\\) forces \n   \\[\n     \\sin S+\\cos S=1\\quad\\Longrightarrow\\quad S=90^\\circ,\n   \\]\nand to have equality throughout the two earlier estimates we must also have \\(A=B\\).  Thus \n   \\[\n     A+B=S=90^\\circ\n     \\quad\\Longrightarrow\\quad\n     C=180^\\circ-S=90^\\circ,\n   \\]\nas claimed.", "Proof.  Call an index  j  a \u201ctail\u2010minimum\u2019\u2019 if  \n\u2003\u2003S_k \u2265 S_j \u2003for all k>j.  \nLet \u03a9 be the set of tail\u2010minima.  Two cases arise:\n\nCase 1: \u03a9 is finite.  Then its complement \u03a9^c is infinite.  By definition of \u03a9^c, every j\u2208\u03a9^c admits some k>j with  \n\u2003\u2003S_k < S_j.  \nPick any i\u2081\u2208\u03a9^c.  Having chosen i\u2099\u2208\u03a9^c, choose i\u2099\u208a\u2081>i\u2099 in \u03a9^c so that S_{i\u2099\u208a\u2081}<S_{i\u2099}.  (This is possible because i\u2099\u2208\u03a9^c.)  Then for every n\n\n\u2003A_n = S_{i_n} \u2212 S_{i_{n+1}} >0,\n\nso sgn\u2009A_n \u2261 +1.\n\nCase 2: \u03a9 is infinite.  We split again according to whether there are infinitely many \u201cstrict\u2019\u2019 tail\u2010minima or only finitely many:\n\n2a) There are infinitely many strict tail\u2010minima, i.e. infinitely many j for which S_k>S_j for all k>j.  Enumerate them i\u2081<i\u2082<\u22ef.  Then S_{i\u2081}<S_{i\u2082}<\u22ef, so\n\n\u2003A_n = S_{i_n} \u2212 S_{i_{n+1}} <0,\n\nhence sgn\u2009A_n \u2261 \u22121.\n\n2b) \u03a9 is infinite but only finitely many of its elements are strict minima.  Then beyond some point every j\u2208\u03a9 has at least one k>j with S_k=S_j.  We now build i\u2081<i\u2082<\u22ef inside \u03a9 so that S_{i\u2099\u208a\u2081}=S_{i_n} for all n.  Indeed, pick any i\u2081\u2208\u03a9 which is not a strict minimum.  Having chosen i\u2099, since it is a non\u2010strict tail\u2010minimum there is a k>i\u2099 with S_k=S_{i\u2099}; set i_{n+1}=k.  Then\n\n\u2003A_n = S_{i_n} \u2212 S_{i_{n+1}} = 0,\n\nso sgn\u2009A_n \u2261 0.\n\nIn every case we have found an increasing sequence {i_n} for which the signs of the differences A_n all agree.  Q.E.D.", "Here is a slick way to pin down the first few terms and in particular show that \\(a_5=8\\).  Write out the equation  \n\\[\na_{a_n}=3n\n\\]\nfor \\(n=1,2,3\\) and use monotonicity.\n\n1.  \\(n=1\\):  \n   \\(a_{a_1}=3\\).  Since all \\(a_n\\) are positive integers and strictly increasing, \\(a_1\\ge1\\).  \n   \u2013 If \\(a_1=1\\) then \\(a_{a_1}=a_1=1\\neq3\\).  \n   \u2013 If \\(a_1\\ge3\\), then \\(a_{a_1}\\ge a_3>a_2\\ge a_1\\ge3\\), so the only way to get exactly 3 is to have  \n     \\(a_1=2\\) and hence \\(a_2=3\\).  \n\n2.  \\(n=2\\):  \n   \\(a_{a_2}=a_3=3\\cdot2=6\\).  So \\(a_3=6\\).  Now we know  \n   \\[\n     a_1=2< a_2=3< a_3=6.\n   \\]\n\n3.  \\(n=3\\):  \n   \\(a_{a_3}=a_6=3\\cdot3=9\\).  So \\(a_6=9\\).  Thus far  \n   \\[\n     a_1=2,\\;a_2=3,\\;a_3=6,\\;a_6=9.\n   \\]\n\n4.  Now use strict increasingness to squeeze out \\(a_4\\) and \\(a_5\\).  We know\n   \\[\n     a_3=6< a_4< a_5< a_6=9.\n   \\]\n   Hence \\(a_4,a_5\\) must lie in the gap \\(\\{7,8\\}\\).  They must be strictly increasing, so\n   \\[\n     a_4=7,\\quad a_5=8.\n   \\]\n\nNo other choice is possible without violating either the functional equation or the fact that the sequence is strictly increasing.  In particular\n\\[\n\\boxed{a_5=8.}\n\\]", "Here is a neat way to see that the partial sums never reach 2.  One first shows that the sequence \\((a_n)\\) is strictly decreasing and tends to 1, and then rewrites the sum so that one can compare it with the classical zeta\u2013values \\(\\zeta(2)\\) and \\(\\zeta(3)\\).  \n\n1)  Monotonicity and limit of \\(a_n\\).  \nFrom the recurrence  \n\\[\n(n+1)\\,a_{n+1}^2 \\;=\\;n\\,a_n^2\\;+\\;a_n\n\\]\nwe get  \n\\[\na_{n+1}^2\n=\\frac{n\\,a_n^2 + a_n}{\\,n+1\\,}\n<\\frac{n\\,a_n^2 + a_n^2}{\\,n+1\\,}\n=\\;a_n^2\n\\quad\\Longrightarrow\\quad\na_{n+1}<a_n\n\\]\nsince \\(a_n>0\\).  Hence \\(a_n\\) is strictly decreasing.  In the limit \\(n\\to\\infty\\) the recursion becomes\n\\[\na^2 = a,\n\\]\nso \\(a_n\\to1\\).  In particular for every \\(n\\ge2\\) we have\n\\[\n1 \\;<\\;a_n\\;\\le\\;a_2=\\sqrt3\\approx1.732.\n\\]\n\n2)  A closed\u2013form for \\(n\\,a_n^2\\).  \nIf we set\n\\[\nb_n := n\\,a_n^2,\n\\]\nthen the given recurrence becomes\n\\[\nb_{n+1}\n= (n+1)\\,a_{n+1}^2\n= n\\,a_n^2 + a_n\n= b_n + a_n.\n\\]\nSince \\(b_1=1\\cdot a_1^2=2\\), by telescoping\n\\[\nb_n\n= b_1 + \\sum_{k=1}^{n-1}(b_{k+1}-b_k)\n= 2 \\;+\\;\\sum_{k=1}^{n-1}a_k.\n\\]\nHence\n\\[\na_n^2\n=\\frac{b_n}{n}\n=\\frac{2+\\sum_{k=1}^{n-1}a_k}{\\,n\\,}.\n\\]\n\n3)  Expressing the partial sums.  \nWe want\n\\[\nS_n \\;=\\;\\sum_{k=2}^n\\frac{a_k^2}{k^2}\n=\\sum_{k=2}^n\\frac{b_k}{k^3}\n=\\sum_{k=2}^n\\Bigl(\\frac{2}{k^3}+\\sum_{i=1}^{k-1}\\frac{a_i}{k^3}\\Bigr)\n=2\\sum_{k=2}^n\\frac1{k^3}\n\\;+\\;\\sum_{i=1}^{n-1}a_i\\;\\sum_{k=i+1}^n\\frac1{k^3}\\!.\n\\]\n\n4)  Estimating the tail by integrals and using \\(\\zeta\\)\u2013bounds.  \nSince for each fixed \\(i\\),\n\\[\n\\sum_{k=i+1}^n\\frac1{k^3}\n\\;\\le\\;\n\\sum_{k=i+1}^\\infty\\frac1{k^3}\n\\;\\le\\;\n\\int_{i}^{\\infty}\\frac{dx}{x^3}\n=\\frac1{2\\,i^2},\n\\]\nwe obtain\n\\[\nS_n\n\\;\\le\\;\n2\\sum_{k=2}^\\infty\\frac1{k^3}\n\\;+\\;\\sum_{i=1}^{n-1}a_i\\;\\frac1{2\\,i^2}\n\\;=\\;\n2\\Bigl(\\zeta(3)-1\\Bigr)\n\\;+\\;\\frac12\\sum_{i=1}^{n-1}\\frac{a_i}{i^2}\\!.\n\\]\nBut \\(a_1=2\\), and for \\(i\\ge2\\) we saw \\(a_i\\le\\sqrt3\\).  Hence\n\\[\n\\sum_{i=1}^{n-1}\\frac{a_i}{i^2}\n\\;\\le\\;\n\\frac{2}{1^2} \\;+\\;\\sqrt3\\,\\sum_{i=2}^\\infty\\frac1{i^2}\n\\;=\\;\n2\\;+\\;\\sqrt3\\,\\Bigl(\\zeta(2)-1\\Bigr).\n\\]\nPutting everything together,\n\\[\nS_n\n\\;\\le\\;\n2\\bigl(\\zeta(3)-1\\bigr)\n\\;+\\;\\frac12\\Bigl[\\,2+\\sqrt3\\bigl(\\zeta(2)-1\\bigr)\\Bigr].\n\\]\nNow use the numerical bounds\n\\[\n\\zeta(2)=\\frac{\\pi^2}6\\approx1.644934,\n\\quad\n\\zeta(3)\\approx1.202056,\n\\]\nto get\n\\[\n2\\bigl(\\zeta(3)-1\\bigr)\\approx2\\times0.202056=0.404112,\n\\quad\n\\frac12\\Bigl[2+\\sqrt3\\,(1.644934-1)\\Bigr]\n\\approx\\frac12\\bigl[2+1.732\\cdot0.644934\\bigr]\n\\approx\\frac12\\cdot3.11688\n=1.55844.\n\\]\nHence\n\\[\nS_n \\;\\le\\;0.404112 +1.55844 =1.96255\\;<\\;2,\n\\]\nfor every \\(n\\).  This completes the proof that\n\\[\n\\sum_{k=2}^n\\frac{a_k^2}{k^2}<2\n\\quad\\forall\\,n\\ge2.\n\\]", "Solution.  Call a random 2\u2010\\(n\\)\u2013partition \u201cgood\u2019\u2019 if the range of the first \\(n\\)\u2013set equals the range of the second \\(n\\)\u2013set.  Equivalently, if we label the two groups \\(A\\) and \\(B\\), then\n\\[\na_2 - a_1 \\;=\\; b_2 - b_1.\n\\]\nBy symmetry it is enough to choose one group \\(A\\) of size \\(n\\) uniformly at random (and write its complement as \\(B\\)).  We will show\n\\[\nP\\{A\\hbox{ is good}\\}\n\\;=\\;\n\\frac{n(n-1)}{(2n-1)(2n-2)},\n\\]\nand the stated inequality \\(1/6<P(A)\\le2/3\\) then follows immediately.\n\n1.  Reduction to the two\u2013extremes case.  \nObserve that for \\(A\\subset\\{1,2,\\dots,2n\\}\\) with \\(|A|=n\\), the only way the two ranges can be equal is that one group contains the ball labeled \\(1\\) and the other contains the ball labeled \\(2n\\).  (If both extremes lie in the same group then its range is \\(2n-1\\) while the other group\u2019s range is at most \\(2n-3\\).)\n\nHence there are exactly two symmetric cases:\n\nCase I: \\(1\\in A,\\;2n\\notin A\\).  \nCase II: \\(1\\notin A,\\;2n\\in A\\).\n\nBy symmetry these two cases contribute the same probability to the event \u201cgood.\u2019\u2019  We work out Case I in detail and then double it.\n\n2.  Case I:  \\(1\\in A,\\;2n\\notin A\\).  \nWrite\n\\[\nx\\;=\\;\\max A,\\qquad\ny\\;=\\;\\min(A^c)\\,.\n\\]\nSince \\(1\\in A,\\;2n\\notin A\\), one has\n\\[\n\\hbox{range}(A)=x-1,\\quad\n\\hbox{range}(A^c)=2n-y,\n\\]\nand these are equal exactly when\n\\[\nx-1\\;=\\;2n-y\n\\quad\\Longleftrightarrow\\quad\nx+y=2n+1.\n\\]\nMoreover to force \\(\\max A=x\\) and \\(\\min A^c=y\\) one must have\n\\[\nA\\supseteq\\{1,2,\\dots,x\\},\\quad\nA^c\\supseteq\\{y,y+1,\\dots,2n\\}.\n\\]\nSince \\(|A|=n\\), we get\n\\[\nx\\;\\le\\;n,\n\\]\nand then \\(y=2n+1-x>n\\), so the middle block\n\\(\\{x+1,\\dots,y-1\\}\\) has size\n\\[\n(y-1)-(x+1)+1\n\\;=\\;\n(2n+1-x-1)-(x+1)+1\n\\;=\\;\n2(n-x).\n\\]\nWe must choose the remaining \\(n-x\\) elements of \\(A\\) from these \\(2(n-x)\\) middle points.  Thus for each \\(x=2,3,\\dots,n\\) there are\n\\(\\displaystyle\\binom{2(n-x)}{\\,n-x\\,}\\)\nchoices of \\(A\\).  Summing over \\(x\\) and then doubling to account for Case II gives\n\\[\n\\#\\{A\\hbox{ good}\\}\n\\;=\\;\n2\\sum_{x=2}^n\\binom{2(n-x)}{\\,n-x\\,}\n\\;=\\;\n2\\sum_{d=0}^{\\,n-2}\\binom{2d}{d}.\n\\]\nHere we have set \\(d=n-x\\).  Consequently\n\\[\nP(A\\hbox{ good})\n\\;=\\;\n\\frac{2\\sum_{d=0}^{n-2}\\binom{2d}{d}}{\\binom{2n}{n}}.\n\\]\n\n3.  Closed\u2010form and the numerical bounds.  \nA standard identity is\n\\[\n\\sum_{d=0}^m\\binom{2d}{d}\n\\;=\\;\n\\binom{2m+1}{m},\n\\]\nso with \\(m=n-2\\) the numerator becomes\n\\(\\;2\\binom{2n-3}{\\,n-2\\,}.\\)\nHence\n\\[\nP(A)\n=\n\\frac{2\\binom{2n-3}{\\,n-2\\,}}{\\binom{2n}{n}}\n\\;=\\;\n\\frac{2\\,(2n-3)!\\,/\\,\\bigl[(n-2)!(n-1)!\\bigr]}\n     {(2n)!\\,/\\,\\bigl[n!\\,n!\\bigr]}\n\\;=\\;\n\\frac{n(n-1)}{(2n-1)\\,(2n-2)}.\n\\]\nFinally one checks directly that for all integers \\(n\\ge2\\),\n\\[\n\\frac{1}{6}\n\\;<\\;\n\\frac{n(n-1)}{(2n-1)(2n-2)}\n\\;\\le\\;\n\\frac23,\n\\]\nand this completes the proof.  \u25a1", "Here is a neat way to pin down the smallest possible b.\n\nDefine for x\u22650  \n\u2003F(x)=e^{2x}\u22122x\u00b2+b\u2009x\u2212(2x\u00b3+1).  \nWe want F(x)\u22650 for all x\u22650.  Note first that  \n\u2003F(0)=1\u22120+0\u2212(0+1)=0.  \n\nA necessary and sufficient condition for F\u22650 on [0,\u221e) is that its global minimum be \u22650.  Any interior minimum x\u2080>0 must satisfy  \n\u2003F\u2032(x\u2080)=0,  \nand at such a point we must have F\u2033(x\u2080)\u22650.  Let us solve F\u2032(x)=0:\n\n1)\u2003F\u2032(x)=2e^{2x}\u22124x\u22126x\u00b2+b.  \n   So at a critical x\u2080>0,  \n\u2003\u2003b=4x\u2080+6x\u2080\u00b2\u22122e^{2x\u2080}.  \n\n2)\u2003We also require F(x\u2080)=0:  \n\u2003e^{2x\u2080}\u22122x\u2080\u00b2+b\u2009x\u2080\u22122x\u2080\u00b3\u22121=0.  \n\nSubstitute the expression for b from (1) into (2).  One finds after a small amount of algebra that the only positive solution is  \n\u2003x\u2080=\u00bd.  \n\nThen from (1)  \n\u2003b=4\u00b7\u00bd+6\u00b7(\u00bd)\u00b2\u22122e^{2\u00b7\u00bd}  \n\u2003=2+6\u00b7\u00bc\u22122e  \n\u2003=2+1.5\u22122e  \n\u2003=7/2\u22122e.  \n\nFinally check F\u2033(\u00bd)=4e^{1}\u22124\u221212\u00b7\u00bd=4e\u221210>0, so x=\u00bd is indeed a local minimum.  Hence to keep F(x)\u22650 for all x\u22650 one needs at least  \n\u2003b\u22657/2\u22122e.  \n\nConversely if b<7/2\u22122e then at x=\u00bd one checks F(\u00bd)<0 and the inequality fails.  This completes the proof.", "Proof. Recall that 10\u2261\u22121 (mod 11) because 10\u2212(\u22121)=11.  Then by the rules of congruences:  \n1. From 10\u2261\u22121 (mod 11) we get for each nonnegative integer i,  \n   10^i \u2261 (\u22121)^i   (mod 11).  \n2. Writing  \n   a = a_n\u00b710^n + a_{n\u22121}\u00b710^{n\u22121} + \u2026 + a_1\u00b710 + a_0,  \n   and using the fact that congruence is compatible with addition and multiplication, we have  \n   a \u2261 a_n\u00b7(\u22121)^n + a_{n\u22121}\u00b7(\u22121)^{n\u22121} + \u2026 + a_1\u00b7(\u22121)^1 + a_0\u00b7(\u22121)^0  \n     = (\u22121)^n\u2009a_n + (\u22121)^{n\u22121}\u2009a_{n\u22121} + \u2026 \u2212 a_1 + a_0  \n   (mod 11).  \n\nTherefore  \n   a \u2261 a_0 \u2212 a_1 + a_2 \u2212 a_3 + \u22ef + (\u22121)^n\u2009a_n   (mod 11).  \n\nBy definition, \u201ca is divisible by 11\u201d means a\u22610 (mod 11).  Hence a is divisible by 11 if and only if  \n   a_0 \u2212 a_1 + a_2 \u2212 a_3 + \u22ef + (\u22121)^n\u2009a_n \u2261 0   (mod 11),  \ni.e. the alternating sum of its digits is divisible by 11.  \u25a0", "First observe that  \n\u2003A = \u2124[\u221a3] = { m + \u221a3\u2009n \u2223 m,n\u2208\u2124 }  \nis a ring under the usual addition and multiplication, and  \n\u2003B = { x\u2208A \u2223 x\u207b\u00b9\u2208A }  \nis exactly the group of *units* of that ring.  In any quadratic integer ring \u2124[\u221aD] the norm  \n\u2003N(a+b\u221aD) = a\u00b2 \u2212 D\u2009b\u00b2  \nis multiplicative, and for a unit x we have  \n\u2003N(x)\u2009N(x\u207b\u00b9) = N(1) = 1.  \nSince N(x),N(x\u207b\u00b9) are integers, each must be \u00b11.  In our case D=3, so if  \n\n\u2003x = m + \u221a3\u2009n \u2208 B  \n\nthen  \n\n\u2003N(x) = m\u00b2 \u2212 3\u2009n\u00b2 = \u00b11.  \n\nIt remains only to rule out the \u201c\u22121\u201d\u2010case.  But modulo 3 every square is 0 or 1, so  \n\n\u2003m\u00b2 \u2212 3\u2009n\u00b2 \u2261 m\u00b2 (mod\u20093) \u2208 {0,1}  \n\ncan never be \u2261\u2009\u22121\u22612 (mod\u20093).  Hence the only possibility is  \n\n\u2003m\u00b2 \u2212 3\u2009n\u00b2 = +1,  \n\nas claimed.", "First, recall the well\u2010known fact that if a point \\(M(a,b)\\) in the plane and the curve \\(y=f(x)\\) are given, then a point  \n\\[\nP(x_0,\\,f(x_0))\n\\]  \non the curve is a \u201cnearest point\u201d of \\(M\\) (i.e.\\ it minimizes the squared distance \\(s(x)=(x-a)^2+(f(x)-b)^2\\)) precisely when  \n\\[\n\\frac{d}{dx}\\bigl[(x-a)^2+(f(x)-b)^2\\bigr]\\bigg|_{x=x_0}\n\\;=\\;\n2(x_0-a)\\;+\\;2\\bigl(f(x_0)-b\\bigr)\\,f'(x_0)\n\\;=\\;0.\n\\]\nEquivalently\n\\[\n(x_0-a)\\;+\\;(f(x_0)-b)\\,f'(x_0)\\;=\\;0.\n\\]\n\n---\n\nNow in our problem we have two moving points, depending on a parameter \\(t\\in\\Bbb R\\):\n\n\\[\nM_1\\bigl(t-1,\\;f(t)-g(t)\\bigr), \n\\qquad\nM_2\\bigl(t+1,\\;f(t)+g(t)\\bigr),\n\\]\nwhere \\(g(t)>0\\) for all \\(t\\).  By hypothesis, for each \\(t\\) there is a single point\n\\[\nP\\bigl(x_1,\\,f(x_1)\\bigr)\n\\]\nwhich is simultaneously the nearest point on the graph of \\(f\\) to both \\(M_1\\) and \\(M_2\\).  Therefore \\(x_1\\) must satisfy both of the following equations:\n\n(1)\u2002Nearest\u2010point condition for \\(M_1\\):\n\\[\n(x_1 - (t-1)) \\;+\\;\\bigl(f(x_1)-[\\,f(t)-g(t)\\,]\\bigr)\\,f'(x_1)\n\\;=\\;0.\n\\]\n\n(2)\u2002Nearest\u2010point condition for \\(M_2\\):\n\\[\n(x_1 - (t+1)) \\;+\\;\\bigl(f(x_1)-[\\,f(t)+g(t)\\,]\\bigr)\\,f'(x_1)\n\\;=\\;0.\n\\]\n\nSubtract (2) from (1).  On the left,\n\\[\n\\bigl[x_1-(t-1)\\bigr]-\\bigl[x_1-(t+1)\\bigr]\n\\;=\\;(t+1)-(t-1)\\;=\\;2,\n\\]\nand\n\\[\n\\bigl[f(x_1)-f(t)+g(t)\\bigr]\\;-\\;\\bigl[f(x_1)-f(t)-g(t)\\bigr]\n\\;=\\;2\\,g(t).\n\\]\nHence\n\\[\n2\\;+\\;2\\,g(t)\\,f'(x_1)\\;=\\;0\n\\quad\\Longrightarrow\\quad\ng(t)\\,f'(x_1)\\;=\\;-1\n\\quad\\Longrightarrow\\quad\nf'(x_1)\\;=\\;-\\,\\frac1{g(t)}\\;<\\;0.\n\\]\nSo we know already that \\(f'(x_1)<0\\).\n\n---\n\nNext add (1) and (2).  The \\( \\pm1\\) terms cancel, giving\n\\[\n2\\bigl(x_1-t\\bigr)\\;+\\;2\\bigl(f(x_1)-f(t)\\bigr)\\,f'(x_1)\\;=\\;0,\n\\]\nor\n\\[\n(x_1-t)\\;+\\;(f(x_1)-f(t))\\,f'(x_1)\\;=\\;0.\n\\]\nBut this last equation is *exactly* the nearest\u2010point condition for the point\n\\[\nM=(t,f(t)),\n\\]\ni.e.\\ for a point that already lies on the curve \\(y=f(x)\\).  Since the distance from \\(M=(t,f(t))\\) to the curve is zero, the only minimizing (nearest) point on the curve is \\(P=(t,f(t))\\) itself.  Hence the only solution of\n\\[\n(x_1-t)+(f(x_1)-f(t))\\,f'(x_1)=0\n\\]\nis \\(x_1=t\\).\n\nPutting these two conclusions together:\n\n1. From the *sum* we see \\(x_1=t\\).\n\n2. From the *difference* we see\n   \\[\n   f'(x_1)=f'(t)\\;=\\;-\\,\\frac1{g(t)}\\;<0.\n   \\]\n\nSince this holds for *every* real \\(t\\), it follows that\n\\[\nf'(t)<0\\quad\\forall\\,t\\in\\Bbb R,\n\\]\nand therefore \\(f\\) is strictly (and monotonically) decreasing, as claimed.", "Proof.  Let X={\u22121,x\u2081,\u2026,x\u2099} with 0<x\u2081<\u22ef<x\u2099 and assume x\u2099>1 and that X has property P:  \n\n\u201cfor every (s,t)\u2208X\u00d7X there is (u,v)\u2208X\u00d7X with su+tv=0.\u201d  \n\nWe will show first that 1\u2208X, and then that x\u2081\u22651.  Since x\u2081>0 we will then have x\u2081=1.\n\n1)  From a\u2081=(x\u2081,x\u2081) we must solve  \n\u2003x\u2081\u00b7u + x\u2081\u00b7v =0  \n\u21d4 u+v=0.  \nBut the only elements of X summing to zero are u=1,v=\u22121 or u=\u22121,v=1.  Hence 1\u2208X.  Since x\u2081 is the smallest positive element of X, we now know x\u2081\u22641.\n\n2)  Suppose for contradiction that x\u2081<1.  Now look at a\u2081=(x\u2081,x\u2099).  Any (u,v)\u2208X\u00d7X orthogonal to it must satisfy  \n\u2003x\u2081\u00b7u + x\u2099\u00b7v =0  \n\u21d4 u = \u2212(x\u2099/x\u2081)\u00b7v.  \nBut x\u2099/x\u2081> x\u2099>1, so |x\u2099/x\u2081|>1.  Checking all possible v\u2208X:  \n\u2003\u2022 v=\u22121 \u21d2 u=+(x\u2099/x\u2081)>x\u2099 so u\u2209X,  \n\u2003\u2022 v=1 \u21d2 u=\u2212x\u2099/x\u2081<\u2212x\u2099<\u22121 so u\u2209X,  \n\u2003\u2022 v=x_i>0 \u21d2 |u|=(x\u2099/x\u2081)\u00b7x_i \u2265(x\u2099/x\u2081)\u00b7x\u2081=x\u2099>1, so again u\u2209X,  \n\u2003\u2022 v=\u22121 or any other choice likewise fails.  \n\nThus there is no (u,v)\u2208X\u00d7X with x\u2081u+x\u2099v=0, contradicting property P.  Therefore x\u2081\u22651.\n\nCombining x\u2081\u22641 and x\u2081\u22651 gives x\u2081=1, as required.  \u25a0", "Define for each point \\(P(x,y)\\) its \u201cabsolute\u2010value\u201d image  \n\\[\nu=|x|,\\quad v=|y|,\\quad\\text{so that}\\;\\|OP\\|=u+v.\n\\]  \nGiven two points \\(A=(x_{1},y_{1})\\), \\(B=(x_{2},y_{2})\\), set  \n\\[\nu_{1}=|x_{1}|,\\;v_{1}=|y_{1}|,\\quad\nu_{2}=|x_{2}|,\\;v_{2}=|y_{2}|\\,.  \n\\]  \nThen\n\\[\n\\|OA\\|^{2}+\\|OB\\|^{2}-(\\|OA'\\|^{2}+\\|OB'\\|^{2})\n=(u_{1}+v_{1})^{2}+(u_{2}+v_{2})^{2}\n-\\bigl[(u_{1}+v_{2})^{2}+(u_{2}+v_{1})^{2}\\bigr]\n=2\\,(u_{1}v_{1}+u_{2}v_{2}-u_{1}v_{2}-u_{2}v_{1})\n=2\\,(u_{1}-u_{2})(v_{1}-v_{2}).\n\\]  \nHence  \n\\[\n\\|OA\\|^{2}+\\|OB\\|^{2}\\ge\\|OA'\\|^{2}+\\|OB'\\|^{2}\n\\quad\\Longleftrightarrow\\quad\n(u_{1}-u_{2})(v_{1}-v_{2})\\ge0,\n\\]\ni.e.\\ the pair \\((u_{1},v_{1})\\) is comparable to \\((u_{2},v_{2})\\) in the product order on \\(\\{0,1,\\dots,n\\}^{2}\\).  \n\nThus the condition \u201cevery two points of \\(S\\) are related\u201d says exactly that the set of absolute\u2010value pairs  \n\\[\n\\bigl\\{(u,v)\\;|\\;(u,v)=(|x|,|y|)\\text{ for some }(x,y)\\in S\\bigr\\}\n\\]\nis a chain in the grid \\(\\{0,\\dots,n\\}^{2}\\).  Any maximal chain from \\((0,0)\\) up to \\((n,n)\\) consists of \\(2n+1\\) points and can be viewed as a lattice path of \\(n\\) \u201cright\u201d (increasing \\(u\\)) steps and \\(n\\) \u201cup\u201d (increasing \\(v\\)) steps in some order.  \n\nNow each \\((u,v)\\) in that chain lifts to\n\\[\n\\#\\{(x,y):|x|=u,\\;|y|=v\\}\n=\\begin{cases}\n1,&u=v=0,\\\\\n2,&\\text{exactly one of }u,v\\text{ is }0,\\\\\n4,&u>0,\\;v>0.\n\\end{cases}\n\\]\nCall this multiplicity \\(f(u,v)\\).  Then\n\\[\n|S|\\;=\\;\\sum_{(u,v)\\in\\text{chain}}f(u,v).\n\\]\n\nTo maximize this, observe:\n\n1.  If you stay as long as possible on the boundary (where one coordinate is zero) you only pick up multiplicities \\(1\\) or \\(2\\).  \n2.  As soon as both \\(u,v>0\\), every lattice point contributes \\(4\\).  \n\nHence the best strategy is:\n\u2013  First make exactly one step off the \\(v=0\\) axis (so you collect one copy of \\((0,0)\\) giving \\(f=1\\), then one copy of \\((1,0)\\) giving \\(f=2\\)),  \n\u2013  After that all further points \\((u,v)\\) in the chain lie in the interior \\(u,v>0\\), each giving \\(f(u,v)=4\\).\n\nYou must take \\(2n\\) steps total (from \\((0,0)\\) to \\((n,n)\\)), so there are \\(2n+1\\) points on the chain.  Of these, the first two points \\((0,0)\\), \\((1,0)\\) give \\(1+2=3\\), and the remaining \\(2n-1\\) interior points each give \\(4\\).  Thus\n\\[\n|S|_{\\max}\n=1\\;+\\;2\\;+\\;(2n-1)\\times4\n=3+8n-4\n=8n-1.\n\\]\nThat bound is attained for example by the chain\n\\[\n(0,0)\\to(1,0)\\to(1,1)\\to(2,1)\\to(2,2)\\to\\cdots\\to(n,n),\n\\]\nand at each interior \\((u,v)\\) choosing all four sign\u2010variants \\((\\pm u,\\pm v)\\), at \\((1,0)\\) choosing \\((\\pm1,0)\\), and at \\((0,0)\\) just \\((0,0)\\).  This exhibits a set \\(S\\) of size \\(8n-1\\) in which every pair is related.  \n\nTherefore the maximum possible \\(|S|\\) is \\(8n-1\\).", "First, rewrite the probabilistic experiment in purely \u201cpermutation\u2010counting\u2019\u2019 language.  Since the underlying arithmetic progression has nonzero difference its terms are all distinct, so choosing an ordered \\(m\\)\u2013tuple \\((b_{1},\\dots,b_{m})\\) amounts simply to choosing \\(m\\) distinct elements out of \\(n\\) and arranging them in some order.  The total number of equally\u2010likely outcomes is therefore\n\n\\[\n\\bigl|\\{\\,(b_{1},\\dots,b_{m})\\}\\bigr|\n\\;=\\;\nn\\,(n-1)\\,(n-2)\\cdots(n-m+1)\n\\;=\\;\nP(n,m)\\,,\n\\]\nwhere \\(P(n,m)\\) denotes the number of \\(m\\)\u2013permutations of an \\(n\\)-set.\n\nThe condition for an \u201c\\(n\\)-sequence\u2019\u2019 is\n\n\\[\n(b_i - b_{i+1})(b_i - b_{i+2})<0\n\\quad\n\\text{for all }i=1,2,\\dots,m-2.\n\\]\n\nBut already for \\(i=1\\) this says\n\\[\n(b_1 - b_2)(b_1 - b_3)<0\n\\quad\\Longleftrightarrow\\quad\nb_1\\text{ is strictly between }b_2\\text{ and }b_3.\n\\]\nIn other words, among the three distinct values \\(\\{b_1,b_2,b_3\\}\\), the first\u2010slot value must be the median.  \n\n(1)  How many of the \\(P(n,m)\\) total permutations satisfy just this first\u2010window requirement?  \n\u2013\u2013 First choose any three distinct elements out of \\(n\\) to occupy the slots \\((b_1,b_2,b_3)\\): that is \\(\\binom n3\\) ways of selecting the set \\(\\{b_1,b_2,b_3\\}\\).  \n\u2013\u2013 Within those three, only the median may go into slot \\(b_1\\).  Once you have put the median in slot 1, the remaining two elements (the \u201cmin\u2019\u2019 and the \u201cmax\u2019\u2019) can go in slots 2 and 3 in either of \\(2\\) ways.  \n\u2013\u2013 Finally, the remaining \\(m-3\\) slots \\(b_4,\\dots,b_m\\) can be any arrangement of the remaining \\(n-3\\) elements, i.e.\\ in \\(P(n-3,m-3)\\) ways.  \n\nPutting these factors together, the number of permutations with \\(b_1\\) the median of \\(\\{b_1,b_2,b_3\\}\\) is\n\\[\n\\binom n3\\;\\times\\;2\\;\\times\\;P(n-3,m-3).\n\\]\nHence the probability that the first\u2010window condition holds is\n\\[\n\\frac{\\binom n3\\;2\\;P(n-3,m-3)}{P(n,m)}\n\\;=\\;\n\\frac{\\binom n3\\;2\\;P(n-3,m-3)}{\\binom n3\\;3!\\;P(n-3,m-3)}\n\\;=\\;\n\\frac{2}{6}\n\\;=\\;\n\\frac13.\n\\]\n\n(2)  But our full event (that all windows \\(i=1,2,\\dots,m-2\\) satisfy the median\u2010condition) certainly implies in particular that the *first* window satisfies it.  Therefore\n\\[\nP_m\n\\;=\\;\n\\Pr\\bigl(\\text{all windows }1\\le i\\le m-2\\text{ are good}\\bigr)\n\\;\\le\\;\n\\Pr\\bigl(\\text{window }i=1\\text{ is good}\\bigr)\n\\;=\\;\n\\frac13.\n\\]\nThis completes the proof that for every \\(m\\), \n\\[\nP_m\\;\\le\\;\\tfrac13.\n\\]", "Solution.  Write $n=2k$ and pair the balls into the $k$ pairs\n\\[\n(1,2),\\;(3,4),\\;\\dots,\\;(2k-1,2k).\n\\]\nIn each pair $(2i-1,2i)$ exactly one of three things can happen:\n\n1.  Both balls have the same color (probability $1/2$).  \n2.  The odd\u2010numbered ball is black and the even\u2010numbered ball is white (probability $1/4$).  \n3.  The odd\u2010numbered ball is white and the even\u2010numbered ball is black (probability $1/4$).\n\nLet us introduce for $i=1,\\dots,k$ the indicators\n\\[\nA_i=\\mathbf1\\{\\text{in pair }i\\text{ we are in case 2}\\},\\quad \nB_i=\\mathbf1\\{\\text{in pair }i\\text{ we are in case 3}\\},\n\\]\nand put\n\\[\nD_i=A_i-B_i,\\qquad D=\\sum_{i=1}^k D_i.\n\\]\nThen one checks easily that\n\\[\nX-Y \\;=\\; D,\n\\]\nso that $|X-Y|=|D|$, and hence\n\\[\n\\xi \\;=\\; k+|X-Y|\\;=\\;k+|D|\\,. \n\\]\nMoreover the $D_i$ are independent with the common law\n\\[\nP(D_i=1)=\\tfrac14,\\quad P(D_i=0)=\\tfrac12,\\quad P(D_i=-1)=\\tfrac14,\n\\]\nso the pgf of $D_i$ is\n\\[\nG(t)=E\\,t^{D_i}=\\tfrac12+\\tfrac14\\,t+\\tfrac14\\,t^{-1}\n=\\frac{(t^{1/2}+t^{-1/2})^2}{4}\\,.\n\\]\nBy independence the pgf of $D=\\sum D_i$ is\n\\[\nE\\,t^D=G(t)^k\n=\\Bigl(\\tfrac{t^{1/2}+t^{-1/2}}{2}\\Bigr)^{2k}\n=\\frac{(t^{1/2}+t^{-1/2})^{2k}}{2^{2k}}\n=\\sum_{d=-k}^k\\frac{\\binom{2k}{k-d}}{2^{2k}}\\,t^d.\n\\]\nHence the law of $D$ is\n\\[\nP(D=d)=\\frac{\\binom{2k}{\\,k-d\\,}}{2^{2k}}\\,,\\qquad d=-k,\\dots,k.\n\\]\nIn particular the probability of a tie ($D=0$, i.e.\\ $X=Y$) is\n\\[\nP(D=0)=\\frac{\\binom{2k}{k}}{2^{2k}}.\n\\]\nOn the other hand\n\\[\nE|D|\\;=\\;\\sum_{d=-k}^k|d|\\,P(D=d)\n\\;=\\;2\\sum_{d=1}^k d\\,\\frac{\\binom{2k}{\\,k-d\\,}}{2^{2k}}.\n\\]\nA short but somewhat tedious binomial\u2010sum calculation shows the key identity\n\\[\n\\sum_{d=1}^k d\\;\\binom{2k}{\\,k-d\\,}\n\\;=\\;\\frac k2\\;\\binom{2k}{k}\\,.\n\\]\nHence\n\\[\nE|D|\n=2\\cdot\\frac1{2^{2k}}\\cdot\\frac{k}{2}\\binom{2k}{k}\n=\\;k\\,\\frac{\\binom{2k}{k}}{2^{2k}}\n=\\;k\\,P(D=0).\n\\]\nFinally\n\\[\nE(\\xi)\n=E\\bigl(k+|D|\\bigr)\n=k+E|D|\n=k+ k\\,P(D=0)\n=k+\\;k\\bigl(1-2P(D>0)\\bigr)\n=2k\\bigl(1-P(D>0)\\bigr).\n\\]\nBut $P(D>0)=P(X>Y)=a_{2k}$ by definition, so\n\\[\nE(\\xi)=2k\\bigl(1-a_{2k}\\bigr),\n\\]\nas required.  \u25a1", "Label the 10 subsets \\(B_{1},\\dots,B_{10}\\) and for each element \\(x\\in A_{n}\\) consider its \u201cincidence\u2010vector\u201d in \\(\\{0,1\\}^{10}\\):  \n\\[\nv(x)=(\\,1_{x\\in B_{1}},\\,1_{x\\in B_{2}},\\dots,1_{x\\in B_{10}})\\,.  \n\\]  \nThe two covering hypotheses translate as follows:\n\n1.  \u201cThe union of any 6 of the \\(B_{i}\\) is all of \\(A_{n}\\).\u201d  \n    Equivalently, for every choice of 6 indices \\(i_{1},\\dots,i_{6}\\), every \\(x\\) lies in at least one of those six \\(B_{i_{j}}\\).  Hence in any 6 positions the incidence\u2013vector \\(v(x)\\) cannot be all zeros.  In particular \\(v(x)\\) can have at most 5 zeros overall; i.e. each \\(v(x)\\) has Hamming weight (number of 1\u2019s) \\(\\ge10-5=5\\).\n\n2.  \u201cThe union of any 5 of the \\(B_{i}\\) is not all of \\(A_{n}\\).\u201d  \n    Equivalently, for each 5\u2010subset \\(I\\subset\\{1,\\dots,10\\}\\) there must be some \\(x\\) missing from all \\(B_{i}\\) with \\(i\\in I\\).  Thus for each 5\u2010subset \\(I\\) there is an \\(x\\) whose incidence\u2010vector has zeros on exactly those 5 coordinates in \\(I\\).  Since no vector can have more than 5 zeros, it follows that for each 5\u2010subset \\(I\\) there is an \\(x\\) whose zero\u2010set is precisely \\(I\\), i.e. whose vector is the characteristic vector of the complementary 5\u2010set \\(\\{1,\\dots,10\\}\\setminus I\\).\n\nTherefore all \\(\\binom{10}{5}=252\\) distinct 0\u20131\u2010vectors of length 10 with exactly five 0\u2019s (and hence five 1\u2019s) must occur among the \\(v(x)\\).  Since each such vector corresponds to a different element of \\(A_{n}\\), we get \n\\[\nn = |A_{n}|\\;\\ge\\;\\binom{10}{5}\\;=\\;252.\n\\]\nThis is exactly the desired bound.", "First we show two things:\n\n 1.  There is a \\emph{(good)} example of size $n+2$ which has \\emph{no} four\u2010tuple summing to $-1$.  \n 2.  Every subset $A\\subset M$ of size $|A|=n+3$ \\emph{must} contain four elements whose sum is $-1\\,. $\n\nFrom (1) it will follow that $g(M)>n+2$, and from (2) that $g(M)\\le n+3$.  Hence $g(M)=n+3\\,$.\n\n---\n\n1)\u2002A subset of size $n+2$ with no $4$\u2013sum $=-1$.\n\nTake\n\\[\n   A \\;=\\;\\{\\,1,2,3,\\dots,n\\}\\;\\cup\\;\\{\\,-1,\\,-2\\}\\,,\n\\]\nwhich indeed has $n+2$ elements.  Any choice of four elements from $A$ contains at most two negative numbers (namely $-1,-2$) and at least two positive ones from $\\{1,2,\\dots,n\\}$.  Hence the smallest possible sum of four chosen elements is\n\\[\n   (-1)+(-2)+1+2 \\;=\\;0,\n\\]\nand all other sums are even larger.  In particular no four\u2010element submultiset of $A$ can sum to $-1$.  Thus\n\\[\n   g(M)\\;>\\;n+2.\n\\]\n\n---\n\n2)\u2002Any $A\\subset M$ of size $n+3$ \\emph{must} have four elements summing to $-1$.\n\nLabel the indices $1,2,\\dots,n$.  For each index $i$ look at whether $A$ contains\n\\[\n   \\text{neither of }\\{\\pm i\\},\\quad\n   \\text{exactly one of }\\{+i,\\,-i\\},\\quad\n   \\text{or both }+i\\text{ and }-i.\n\\]\nLet\n\\[\n   U=\\{\\,i: A\\hbox{ contains neither }\\pm i\\},\\quad\n   S=\\{\\,i: A\\hbox{ contains exactly one of }\\pm i\\},\\quad\n   T=\\{\\,i: A\\hbox{ contains both }+i\\text{ and }-i\\}.\n\\]\nThen\n\\[\n   |U|+|S|+|T| \\;=\\; n,\n   \\quad\n   0\\cdot|U|+1\\cdot|S|+2\\cdot|T| \\;=\\;|A|\\;=\\;n+3.\n\\]\nSubtracting the first from the second shows\n\\[\n   |T|\\;=\\;|U|+3.\n\\]\nIn particular $|T|\\ge3\\,$.  Hence there are at least three distinct indices\n\\[\n   a<b<c\n   \\quad\n  \\text{for which }A\\supset\\{+a,-a,+b,-b,+c,-c\\}.\n\\]\nWe now claim that once you have the six numbers $\\pm a,\\pm b,\\pm c$ \\emph{plus} at least one more appropriate singleton, you can force a $4$\u2013tuple summing to $-1\\,$.\n\nIndeed for any index $x\\in\\{a,b,c\\}$ consider the four\u2010element multiset\n\\[\n   \\{+x,\\,-x,\\;+\\,(x+1),\\;-\\,(x+1)\\},\n\\]\nif $A$ happens to contain both $-(x+1)$ (or both $+(x-1)$) in addition to $\\pm x$\u2013pair.  One checks directly\n\\[\n   (+x)+(-x)+[-(x+1)]+[+(x+1)] \\;=\\;-1\n   \\quad\\hbox{whenever }A\\ni -(x+1)\n\\]\n(and similarly if $A\\ni+(x-1)$ one finds a $-1$\u2013sum with the pair $\\pm x$).  Thus as soon as among the \u201csingleton\u2019\u2019\u2010indices $S$ there is an $i$ of the form $i=x+1$ with $-\\,i\\in A$, or $i=x-1$ with $+\\,i\\in A$, then one immediately builds four elements summing to $-1$.\n\nIf by miracle no singleton in $S$ triggered one of these simple $4$\u2013sums for any of $x=a,b,c$, then $S$ would have to avoid altogether the (up to six) forbidden indices\n\\[\n   a-1,\\;a+1,\\;b-1,\\;b+1,\\;c-1,\\;c+1.\n\\]\nBut $|S|=n-|U|-|T|=n-(|T|-3)-|T|=n-3-|U|\\ge n-3-0=n-3$, and one easily checks for $n\\ge3$ that you cannot choose $n-3$ distinct indices all outside a set of size $\\ge4$.  Thus there \\emph{must} be some singleton in $S$ which \\emph{does} lie in one of those six positions, and that singleton together with the corresponding $\\pm x$\u2010pair gives\na $4$\u2013tuple of sum $-1$.\n\nIn this way one shows that no matter how one picks $A$ of size $n+3$, one finds four elements summing to $-1\\,$.  Hence\n\\[\n   g(M)\\;\\le\\;n+3.\n\\]\n\nCombining the two parts,\n\\[\n   n+2<g(M)\\le n+3\n   \\quad\\Longrightarrow\\quad\n   g(M)=n+3.\n\\]\nThis completes the proof.", "Here is the one\u2010paragraph \u201cbig picture\u2019\u2019 of why there is only one way to continue the sequence once you have fixed the three initial entries, and then the details of the inductive step.\n\n1)  \u201cBig picture.\u2019\u2019  \n   At each stage you have three consecutive terms \\((a_{n-1},a_n,a_{n+1})\\) and the relation\n   \\[\n     (a_{n-1}-a_n-a_{n+1})\\,(a_{n-1}-\\tfrac12\\,a_n -a_{n+1}) \\;=\\;0.\n   \\]\n   That says either\n     (i)\u2003\\(a_{n-1}=a_n+a_{n+1}\\),  or  \n    (ii)\u2003\\(a_{n-1}=\\tfrac12\\,a_n +a_{n+1}.\\)\n\n   So naively one might think you always have two choices for \\(a_{n+1}\\).  However the multiplicative \u201cclosure\u2019\u2019 property\n   \\[\n     \\forall\\,i\\ge j\\quad\\exists\\,k\\quad a_k\\;=\\;a_i\\,a_j\n   \\]\n   turns out to rule out one of those two choices at each step.  Concretely, if you tried to choose the \u201cwrong\u2019\u2019 linear\u2010recurrence branch, then one of the required products \\(a_i\\,a_j\\) would fall strictly between two already\u2013existing terms of the sequence and hence could not possibly appear.  Thus at each stage exactly one of (i) or (ii) can survive the closure requirement, so the sequence is determined uniquely.\n\n2)  The details of the inductive step.  \n\n   Suppose we already have the terms\n     \\[\n       a_1>0,\\quad a_2<-1,\\quad a_3=2,\n       \\quad a_4,\\dots,a_{n}\n   \\]\n   constructed in a unique way so that all the products \\(a_i a_j\\) with \\(i,j\\le n\\) already appear among those first \\(n\\) terms.  We now show that there is exactly one way to define \\(a_{n+1}\\) so as to keep both\n   (A) the three\u2010term condition on \\((a_{n-1},a_n,a_{n+1})\\) and  \n   (B) the closure condition for all products involving \\(a_{n+1}\\).\n\n   A)  By the three\u2010term condition we must have either\n       \\[\n         (\\alpha)\\;\\;a_{n-1}=a_n + a_{n+1}\n         \\quad\\Longrightarrow\\quad\n         a_{n+1} \\;=\\; a_{n-1}\\;-\\;a_n,\n       \\]\n       or\n       \\[\n         (\\beta)\\;\\;a_{n-1}=\\tfrac12\\,a_n + a_{n+1}\n         \\quad\\Longrightarrow\\quad\n         a_{n+1}\\;=\\;a_{n-1}-\\tfrac12\\,a_n.\n       \\]\n   So a priori there are two possible values for \\(a_{n+1}.\\)\n\n   B)  Which one survives closure?  Whichever choice we make for \\(a_{n+1}\\), we must still be able to embed every product\n       \\[\n         a_i\\,a_j,\n         \\quad\n         \\text{for all }1\\le j\\le i\\le n+1,\n       \\]\n       somewhere among the first \\(n+1\\) terms.  In particular the \u201cnew\u2019\u2019 products\n       \\(\\,a_{n+1}\\,a_j\\) for \\(1\\le j\\le n\\) must each coincide with one of the already existing entries \\(a_1,\\dots,a_{n+1}\\).  \n\n   One checks by a simple size/ordering argument that if you choose \\(a_{n+1}\\) by the \u201cwrong\u2019\u2019 formula then, say, the product \\(a_{n+1}\\,a_1\\) (or another one of the products with a fixed small index \\(j\\)) ends up strictly between two of the already\u2013existing \\(a_k\\)'s.  Hence it cannot coincide with any of them, and closure is violated.  \n\n   On the other hand if you choose \\(a_{n+1}\\) by the \u201cright\u2019\u2019 formula, all of the products \\(a_{n+1}\\,a_j\\) fall exactly onto already\u2013existing terms (one checks this by comparing sizes in a routine but somewhat tedious calculation).  \n\n   Therefore exactly one of the two linear\u2010recurrence branches survives, and that forces a unique value of \\(a_{n+1}\\).  This completes the inductive step.\n\nBy induction the entire infinite sequence is pinned down in exactly one way once the three initials \\(a_1>0,\\;a_2<-1,\\;a_3=2\\) are given.  Hence there can be only one sequence with the two stated properties.", "First, let us restate the problem in a form free of indexing ambiguities.\n\nWe have the set of the first \\(n\\) positive integers\n\\[\n   A = \\{1,2,3,\\dots,n\\},\n\\]\nand a 3\u2013partition\n\\[\n   A = A_{1}\\,\\dot\\cup\\,A_{2}\\,\\dot\\cup\\,A_{3},\n\\]\nwith all three \\(A_{i}\\) nonempty and pairwise disjoint, and it is given that\n\\[\n   \\sum_{x\\in A_{2}}x \\;=\\;\\sum_{x\\in A_{3}}x.\n\\]\nWe must show that \\(n\\) cannot be even; in other words \\(n\\) is odd.\n\n---\n\n1.  Compute the total sum \\(S\\) of all the integers from \\(1\\) to \\(n\\).  We know\n\\[\n   S=\\sum_{k=1}^{n}k \\;=\\;\\frac{n(n+1)}2.\n\\]\n\n2.  On the other hand\n\\[\n   S \\;=\\;\n   \\sum_{x\\in A_{1}}x \\;+\\;\\sum_{x\\in A_{2}}x \\;+\\;\\sum_{x\\in A_{3}}x.\n\\]\nThe hypothesis is \\(\\sum_{A_{2}}x = \\sum_{A_{3}}x\\).  Call that common value \\(T\\).  Then\n\\[\n   S \\;=\\;\n   \\sum_{x\\in A_{1}}x \\;+\\;T \\;+\\;T\n   \\;=\\;\\sum_{x\\in A_{1}}x \\;+\\;2\\,T.\n\\]\nHence\n\\[\n   S - \\sum_{x\\in A_{1}}x \\;=\\;2\\,T\n   \\quad\\Longrightarrow\\quad\n   S\\;-\\;\\sum_{x\\in A_{1}}x\\;\\text{ is even.}\n\\tag{*}\n\\]\n\n3.  We will now look at the parity (evenness/oddness) of each side of \\((*)\\).  \n   \n   (i)  First recall the parity of \\(S=\\tfrac{n(n+1)}2\\).  One checks\n   \\[\n     \\frac{n(n+1)}2\\;\\text{is even}\n     \\;\\Longleftrightarrow\\;\n     n\\equiv 0\\pmod4\\quad\\text{or}\\quad n\\equiv 3\\pmod4,\n   \\]\n   and\n   \\[\n     \\frac{n(n+1)}2\\;\\text{is odd}\n     \\;\\Longleftrightarrow\\;\n     n\\equiv 1\\pmod4\\quad\\text{or}\\quad n\\equiv 2\\pmod4.\n   \\]\n   \n   (ii)  On the other hand \\(\\sum_{x\\in A_{1}}x\\) is just a sum of some of the integers\n   \\(1,2,\\dots,n\\).  No further restriction is imposed on which ones go into\n   \\(A_{1}\\); in particular that sum can be either even or odd, depending on\n   which elements landed in \\(A_{1}\\).\n\n4.  But \\((*)\\) says\n\\[\n   S\\;-\\;\\sum_{x\\in A_{1}}x\n   \\quad\\text{is even.}\n\\]\nThat means that \\(S\\) and \\(\\sum_{x\\in A_{1}}x\\) have the same parity.  Thus\n\\[\n   S\\equiv \\sum_{x\\in A_{1}}x\\pmod2.\n\\]\nSince \\(\\sum_{x\\in A_{1}}x\\) can be *either* even or odd (depending on which\nintegers happen to sit in \\(A_{1}\\)), the only way to force\n\\(S\\equiv \\sum_{x\\in A_{1}}x\\pmod2\\) *no matter how* one chose the nonempty\nset \\(A_{1}\\subset\\{1,\\dots,n\\}\\) is to make \\(S\\) itself *independent* of any\neven/odd choice.  In concrete terms, if \\(n\\) were even then\n\\(S=\\tfrac{n(n+1)}2\\) takes *both* parities as \\(n\\) varies among even values\n(\\(n\\equiv0\\pmod4\\) makes \\(S\\) even, while \\(n\\equiv2\\pmod4\\) makes \\(S\\) odd),\nand one could choose an \\(A_{1}\\) whose sum has the *opposite* parity of \\(S\\),\nforcing a contradiction to \\((*)\\).\n\n   The only way to avoid this clash of parities is to have\n   \\(\\tfrac{n(n+1)}2\\) itself *never* change parity\u2014in other words to make \\(n\\)\n   odd.  Indeed, when \\(n\\) is odd then\n   \\(n\\equiv1\\pmod4\\) or \\(n\\equiv3\\pmod4\\), and in *both* of those cases\n   \\(\\tfrac{n(n+1)}2\\) comes out even.  Hence\n   \\(\\sum_{x\\in A_{1}}x\\) must be even as well, and there is no possible\n   \u201cmismatch\u201d of parity to spoil \\((*)\\).\n\n5.  Conclusion.  If \\(n\\) were even one can exhibit a choice of a nonempty\nset \\(A_{1}\\subset\\{1,\\dots,n\\}\\) whose sum differs in parity from\n\\(\\tfrac{n(n+1)}2\\), contradicting the requirement\n\\(\\,S-\\sum_{A_{1}}x\\) even.  Thus the only way the given 3\u2013partition with\n\\(\\sum_{A_{2}}x=\\sum_{A_{3}}x\\) can exist is for \\(n\\) to be odd.\n\n\u220e", "First, let us restate the problem in our own words:\n\n  \u2022  We have an infinite arithmetic progression  \n     B = {\u2009b\u2080, b\u2081, b\u2082, \u2026\u2009},  \n     where  \n        b\u2080 = 1,  \n        b\u2099 = 1 + n\u2009d,   d \u2260 0.  \n\n  \u2022  We look for an infinite geometric progression  \n     A = {\u2009a\u2080, a\u2081, a\u2082, \u2026\u2009},  \n     where  \n        a\u2080 = 1,  \n        a\u2099 = a\u2080\u2009q\u207f = q\u207f,   q \u2260 1,  \n    such that every term of A lies in B:  \n        q\u207f \u2208 B  for all n \u2265 0.  \n\n  \u2022  Equivalently, for each n \u2265 0 there must be an integer m\u2099 \u2265 0 so that  \n        q\u207f = 1 + m\u2099\u2009d.  \n\nWe must show that \u201cthere exists an infinite geometric A\u2286B\u201d  \u21d4  \u201cd is rational.\u201d\n\n---\n\n1.  Necessity:  if such a geometric progression exists, then d must be rational.\n\nSuppose q\u2070, q\u00b9, q\u00b2, \u2026 all lie in B.  In particular for n = 1 and n = 2 there are integers m\u2081, m\u2082 so that\n\n  (1)   q\u00b9 = q = 1 + m\u2081\u2009d,  \n  (2)   q\u00b2 = 1 + m\u2082\u2009d.  \n\nFrom (1) we get  \n   d = (q \u2212 1)/m\u2081.  \nPlugging q = 1 + m\u2081\u2009d into q\u00b2 = (1 + m\u2081\u2009d)\u00b2 gives\n\n  (1 + m\u2081\u2009d)\u00b2  =  1 + 2\u2009m\u2081\u2009d + m\u2081\u00b2\u2009d\u00b2  =  1 + m\u2082\u2009d.\n\nHence\n   2\u2009m\u2081\u2009d + m\u2081\u00b2\u2009d\u00b2  =  m\u2082\u2009d\n\u21d2 (2\u2009m\u2081 \u2212 m\u2082)\u2009d  =  \u2212\u2009m\u2081\u00b2\u2009d\u00b2\n\u21d2 (m\u2082 \u2212 2\u2009m\u2081)  =  m\u2081\u00b2\u2009d.  \n\nSince m\u2081, m\u2082 are integers, the right\u2013hand side m\u2081\u00b2\u2009d must be an integer.  But then\n\n   d = (m\u2082 \u2212 2\u2009m\u2081)/m\u2081\u00b2\n\nis a rational number.  This proves necessity.\n\n---\n\n2.  Sufficiency:  if d is rational then one can actually exhibit an infinite geometric subsequence of B.\n\nWrite\n   d = p / r\nin lowest terms, p, r \u2208 \u2124, r > 0, gcd(p,r)=1.  Define\n\n   q  :=  1 + p.  \n\nConsider the geometric progression\n   a\u2080 = 1,   a\u2099 = q\u207f = (1 + p)\u207f,   n = 0,1,2,\u22ef.\n\nWe claim each a\u2099 lies in B.  Indeed,\n\n   a\u2099  =  (1 + p)\u207f\n        =  1  +  [ (1 + p)\u207f \u2212 1 ].\n  \nWe set\n   m\u2099  :=  1/d \u00b7 [ (1 + p)\u207f \u2212 1 ]\n        =  ( (1 + p)\u207f \u2212 1 )  \u00b7  (r / p).\n\nSince by the binomial theorem\n\n   (1 + p)\u207f \u2212 1  =  \u2211_{k=1}^n  C(n,k)\u2009p^k\n\nis clearly divisible by p, the ratio ((1+p)\u207f \u2212 1)/p is an integer.  Hence m\u2099 = r\u00b7((1+p)\u207f \u2212 1)/p is an integer.  Therefore\n\n   a\u2099  =  1  +  m\u2099\u2009d,\n\nso indeed a\u2099 \u2208 B for every n.  This gives an infinite geometric A sitting inside B.\n\n---\n\nPutting the two directions together we conclude:\n\n  There exists an infinite geometric progression A\u2286B  if and only if  d is rational.", "Write \\(a=(a_{1},\\dots,a_{n})\\in B_{n}\\) so that for all \\(1\\le i<j\\le n\\)\n\\[\na_{i}+i\\le a_{j}+j.\n\\]\nWe claim that each such \\(a\\) gives exactly two ways to insert the new maximum \\(n+1\\) into it so as to produce an element of \\(B_{n+1}\\), and that no other insertions work.  From that it follows immediately that\n\\[\nb_{n+1}=2\\,b_{n},\n\\]\nso \\(b_{n}=2^{n-1}b_{1}=2^{n-1}\\), a geometric sequence.\n\n---\n\nProof of the \u201cexactly two insertions\u201d statement.  Let\n\\[\na'=(a'_1,\\dots,a'_{n+1})\n\\]\nbe the result of inserting the symbol \\(n+1\\) into \\(a\\) in position \\(k\\), \\(1\\le k\\le n+1\\).  Concretely,\n\\[\na'_i=\\begin{cases}\na_i,&i<k,\\\\\nn+1,&i=k,\\\\\na_{\\,i-1},&i>k.\n\\end{cases}\n\\]\nWe must check when \\(a'\\) still satisfies\n\\[\na'_{i}+i\\;\\le\\;a'_{j}+j\n\\quad\n\\text{for all }1\\le i<j\\le n+1.\n\\]\nOne checks easily that for every pair \\((i,j)\\) other than \\((k,k+1)\\) the new inequality either becomes one of the old inequalities (hence holds) or becomes strictly weaker than one of the old ones.  The only non\u2010automatic case is the pair\n\\[\n(i,j)=(k,\\;k+1),\n\\]\nwhich demands\n\\[\na'_{k}+k\n\\;\\le\\;\na'_{k+1}+(k+1).\n\\]\nBut \\(a'_{k}=n+1\\) and \\(a'_{k+1}=a_{k}\\), so this becomes\n\\[\n(n+1)+k\\;\\le\\;a_{k}+(k+1)\n\\quad\\Longleftrightarrow\\quad\na_{k}\\;\\ge\\;n.\n\\]\nSince \\(a_{k}\\) is one of \\(\\{1,2,\\dots,n\\}\\), this forces \\(a_{k}=n\\).  Hence the only admissible insertions of \\(n+1\\) are\n(1)\u2003just after the position \\(k\\) where \\(a_{k}=n\\), or \n(2)\u2003at the very end (\\(k=n+1\\)), in which case there is no \u201c\\(k,k+1\\)\u201d to check.\n\nEach \\(a\\in B_{n}\\) has exactly one position \\(k\\) with \\(a_{k}=n\\), so it gives exactly two valid insertions.  Therefore\n\\[\nb_{n+1}=2\\,b_{n},\n\\]\nand since \\(b_{2}=2\\), one finds \\(b_{n}=2^{n-1}\\).  In particular \\(\\{b_{n}\\}\\) is a geometric sequence.  \u25a0", "Here is a fairly direct proof, based only on the facts that\n\n1.  The Fibonacci sequence is a \u201cdivisibility\u2010sequence\u201d:\n    whenever  m \u2223 n one has  F_m \u2223 F_n.  \n2.  For any modulus M the Fibonacci sequence modulo M is eventually periodic, and in particular there is some index n>0 with F_n\u22610 (mod M).\n\nWe will first produce an index s with  \n\u2003F_s\u22610\u2003(mod 125),  \nand then use F_6=8 to conclude at once that some Fibonacci number is \u22610 (mod 1000).\n\nStep 1.  A zero modulo 125 in the Fibonacci sequence.  \nConsider the sequence of ordered pairs  \n\u2003(P_k)  =  (F_k mod 125,\u2009F_{k+1} mod 125),  \nfor k=0,1,2,3\u2026  Since there are only 125\u00b2 possible pairs, two of them must coincide, say  \n\u2003(P_i) = (P_j)  with 0\u2264i<j.  \nBy the determinism of the two\u2010term recurrence  \n\u2003F_{n+2} = F_{n+1} + F_n  (mod 125),  \nonce a pair repeats the entire future tail of the sequence repeats.  Hence the sequence of pairs is purely periodic of some period T=j\u2212i.  But we also know the \u201cinitial\u201d pair P_0 = (F_0 mod 125,\u2009F_1 mod 125) = (0,1).  Periodicity now forces that at some later time we must return to (0,1); that return\u2010time is exactly the period T.  In particular the first coordinate vanishes there:\n\n\u2003F_T \u2261 0\u2003(mod 125).\n\nThus we have found an index s=T>0 with F_s\u22610 (mod 125).\n\nStep 2.  Combining with F_6=8 to get a zero mod 1000.  \nSince 6 \u2223 6 and s \u2223 \u2113  \u21d2  F_6 \u2223 F_\u2113  and  F_s \u2223 F_\u2113, we can choose \u2113 = lcm(6,s).  Then\n\n\u20038 = F_6   \u2223  F_\u2113,  \n\u2003125   =\u2006(modulus) divides F_s   \u21d2   125 \u2223 F_\u2113.\n\nHence 1000=8\u00b7125 divides F_\u2113.  Equivalently F_\u2113 \u22610  (mod 1000), i.e. F_\u2113 ends in three zeros.\n\nConclusion.  We have exhibited an explicit index \u2113 = lcm(6,s) for which F_\u2113 is a multiple of 1000, so its last three decimal digits are 000.  This completes the proof.", "Proof.  We will exhibit a choice of signs \\(s_{1},\\dots,s_{n}\\in\\{-1,+1\\}\\) for the entire sequence so that the running sums\n\\[\nS_{0}=0,\\qquad S_{i}=S_{i-1}+s_{i}a_{i}\\quad (1\\le i\\le n)\n\\]\nalways stay in the interval \\([-k,k]\\).  Since there are only \\(2k+1\\) possible values in \\([-k,k]\\) but \\(n+1\\) sums \\(S_{0},S_{1},\\dots,S_{n}\\), the pigeonhole principle forces either\n  \n  \u2022 some \\(S_{i}=0\\) with \\(i\\ge1\\), in which case\n    \\[\n      \\sum_{\\ell=1}^{i}s_{\\ell}a_{\\ell}=S_{i}-S_{0}=0,\n    \\]\n    so the block \\(1,2,\\dots,i\\) is a zero\u2013sum signed\u2013subsequence; or\n  \n  \u2022 two of the partial sums coincide, say \\(S_{u}=S_{v}\\) with \\(0\\le u<v\\le n\\), in which case\n    \\[\n      \\sum_{\\ell=u+1}^{v}s_{\\ell}a_{\\ell}\n      \\;=\\;\n      S_{v}-S_{u}\n      \\;=\\;0,\n    \\]\n    so the block \\(u+1,u+2,\\dots,v\\) is a zero\u2013sum signed\u2013subsequence.\n\nSince \\(n\\ge2k\\) we have \\(n+1\\ge2k+1\\), hence the pigeonhole argument applies.  It remains only to see why we can keep all the \\(S_{i}\\) in \\([-k,k]\\).\n\nAlgorithm for choosing the signs:  set \\(S_{0}=0\\), and for each \\(i=1,2,\\dots,n\\) choose\n\\[\n  s_{i}=\\begin{cases}\n    -1,&\\text{if }S_{i-1}\\ge0,\\\\\n    +1,&\\text{if }S_{i-1}<0.\n  \\end{cases}\n\\]\nThen\n\\[\n  S_{i}=S_{i-1}+s_{i}a_{i}\n\\]\nmoves \\(S_{i-1}\\) toward \\(0\\) by at most \\(a_{i}\\).  In particular\n\\[\n  |S_{i}|=|\\,S_{i-1}+s_{i}a_{i}\\,|\n        =\\bigl||S_{i-1}|-a_{i}\\bigr|\n        \\;\\le\\;a_{i}\\;\\le\\;k.\n\\]\nThus every \\(S_{i}\\) lies in the set \\(\\{-k,-k+1,\\dots,k-1,k\\}\\), which has size \\(2k+1\\).  Pigeonhole then gives the desired zero\u2013sum block.  This completes the proof that any sequence of length \\(n\\ge2k\\) with terms in \\(\\{1,2,\\dots,k\\}\\) is continuously zero\u2013reducible.", "Define the \u201cfold\u2010and\u2010shift\u2019\u2019 map \n\u2003\u2003T(c): x\u21a6|x\u2212c| \nand extend it coordinate\u2010wise to n\u2010tuples.  We start with the n\u2010tuple \n\u2003\u2003A\u207d\u2070\u207e=(1\u00b9,2\u00b2,3\u00b3,\u22ef,n\u207f), \nand we apply up to n\u22121 such folds, choosing centers c\u2081,c\u2082,\u2026,c\u2099\u208b\u2081 (not necessarily all the same), hoping to drive every coordinate down to zero.  We will show that in fact after k folds at most k of the original coordinates can ever become zero, so in n\u22121 folds at most n\u22121 of them can vanish.  Hence one needs at least n folds to kill all n coordinates.\n\n1) Tracking when an original entry becomes zero.  \nLabel the original entries by i=1,\u2026,n, and let v\u1d62\u207dk\u207e be the value of the i\u2010th coordinate after k folds.  By definition  \n\u2003\u2003v\u1d62\u207d0\u207e=i\u2071,  \nand then  \n\u2003\u2003v\u1d62\u207dk\u207e=|\u2009v\u1d62\u207dk\u22121\u207e\u2212c_k\u2009|,\u2003k\u22651.  \nIn particular v\u1d62\u207dk\u207e=0 if and only if v\u1d62\u207dk\u22121\u207e=c_k.  \n\n2) At each fold at most one new zero can be created.  \nIndeed, if before the k\u2010th fold the values {v\u2081\u207dk\u22121\u207e,\u2026,v\u2099\u207dk\u22121\u207e} are all distinct, then there is at most one index i for which v\u1d62\u207dk\u22121\u207e=c_k, and hence at most one i can satisfy v\u1d62\u207dk\u207e=0.  Of course once some v\u1d62\u207dk\u207e has become zero it stays zero under further folds (since |0\u2212c|\u22600 unless c=0, and then it becomes zero but does not resurrect).  Consequently, provided that up to stage k\u22121 all the values remain distinct except for those already pinned to zero, the k\u2010th fold can introduce at most one new zero\u2010coordinate.\n\n3) Why the values never \u201caccidentally\u2019\u2019 collide before they hit zero.  \nOne has to check that among the v\u1d62\u207dk\u207e\u2019s, as long as none of them has been made zero, there are no unintended coincidences v\u1d62\u207dk\u207e=v\u2c7c\u207dk\u207e (i\u2260j) that would allow a single choice of c_{k+1} to kill two or more at once.  Equivalently, one shows by induction on k that for each fixed sequence of centers c\u2081,\u2026,c_k the n functions\n\u2003\u2003i\u21a6v\u1d62\u207dk\u207e(c\u2081,\u2026,c_k)\nare pairwise distinct real\u2010valued functions of (c\u2081,\u2026,c_k) until one of them is driven to zero.  The inductive step is immediate from the fact that the map x\u21a6|x\u2212c_{k+1}| is injective on any set of reals which does not already contain c_{k+1}.  Since none of the v\u1d62\u207dk\u207e has yet been zeroed, none equals c_{k+1}, and so no two of them can collide under that fold.\n\n4) Conclusion.  \nStart with n distinct entries i\u2071.  Fold once with center c\u2081: one of them may hit c\u2081 and become zero; the other n\u22121 remain distinct (and nonzero).  Fold again with c\u2082: again at most one of the surviving n\u22121 can hit c\u2082, the rest stay distinct, and so on.  After k folds at most k of the original entries are zero, and the remaining n\u2212k are still positive and distinct from each other and from zero.  In particular after k=n\u22121 folds there are still at least n\u2212(n\u22121)=1 surviving nonzero entry.  Hence one cannot kill all n coordinates in fewer than n folds.\n\nThis completes the proof that the sequence 1,2\u00b2,3\u00b3,\u2026,n\u207f admits no \u201c(n\u22121)\u2010time zero\u2013return\u2019\u2019 transformation.", "Solution Outline:\n\n1.  Rewrite the recurrence as a tangent\u2010addition.  Observe that for any real \\(x\\) and constant \\(A\\),\n\n\u2003\u2003tan\\((x + A)\\) = \\(\\dfrac{\\tan x + \\tan A}{1 - (\\tan x)(\\tan A)}\\).  \n\n2.  In our case set\n\\[\nA = \\arctan 3,\n\\quad\n\\text{so that}\n\\quad\n\\tan A = 3.\n\\]\nThen\n\\[\nc_{n+1}\n= \\frac{3 + c_n}{\\,1 - 3\\,c_n}\n= \\frac{\\tan A + \\tan(\\theta_n)}{1 - \\tan A\\;\\tan(\\theta_n)}\n= \\tan\\bigl(A + \\theta_n\\bigr),\n\\]\nif we write \\(c_n = \\tan(\\theta_n)\\).  Since \\(c_1 = 3 = \\tan A\\), one finds by induction\n\\[\n\\theta_1 = A,\n\\quad\n\\theta_{n+1} = \\theta_n + A,\n\\quad\n\\Longrightarrow\n\\theta_n = n\\,A,\n\\]\nand hence\n\\[\nc_n = \\tan(n\\,A),\n\\quad\nA = \\arctan 3.\n\\]\n\n3.  If the sequence \\(\\{c_n\\}\\) were eventually periodic of period \\(T\\), then for all large \\(n\\)\n\\[\nc_{n+T}\n= c_n\n\\;\\Longrightarrow\\;\n\\tan\\bigl((n+T)A\\bigr)\n= \\tan(nA)\n\\;\\Longrightarrow\\;\n\\tan\\bigl(nA + T\\,A\\bigr)\n= \\tan(nA).\n\\]\nThat forces\n\\[\nT\\,A \\;=\\; k\\pi\n\\quad\n\\text{for some integer }k,\n\\]\ni.e.\\ \\(\\displaystyle A/\\pi = k/T\\) would be rational.\n\n4.  But \\(A = \\arctan 3\\) is not a rational multiple of \\(\\pi\\).  To see this, suppose for contradiction\n\\(\\arctan 3 = r\\pi\\) with rational \\(r\\).  Then \\(\\tan(r\\pi)=3\\).  On the other hand, if \\(r=p/q\\) in lowest terms then\n\\[\n\\sin(2r\\pi)\n= 2\\tan(r\\pi)\\big/\\bigl(1 + \\tan^2(r\\pi)\\bigr)\n= \\frac{2\\cdot3}{1 + 9} = \\tfrac{6}{10} = \\tfrac{3}{5},\n\\]\nso \\(\\sin(2r\\pi)=3/5\\) would be a nonstandard rational value of the sine at a rational multiple of \\(\\pi\\).  Niven\u2019s theorem (or a direct check of the finite list of possible rational sine\u2010values at rational multiples of \\(\\pi\\)) rules this out.  Hence \\(\\arctan3\\big/\\pi\\) is irrational.\n\n5.  Because \\(\\arctan3/\\pi\\) is irrational, the angles \\(n\\,A\\pmod\\pi\\) never repeat periodically for all large \\(n\\).  Consequently\n\\(\\tan(nA)\\) takes infinitely many distinct values and cannot settle into a fixed period.  \n\nTherefore the sequence \\(\\{c_n\\}\\) is not eventually periodic.  \u25a1", "Define for each \u03b1\u1d62 its \u201csupport\u201d S\u1d62\u2282{1,\u2026,n} by  \n\u2003S\u1d62={\u2009j\u2223t\u1d62\u2c7c=1\u2009},  \nso |S\u1d62|=\u03b1\u1d62\u00b7\u03b1\u1d62=p, and for i\u2260\u2113 one has |S\u1d62\u2229S_\u2113|=\u03b1\u1d62\u00b7\u03b1_\u2113=1.  Thus the family of sets {S\u2081,\u2026,S\u2099} is exactly a *symmetric* 2\u2010(v,k,\u03bb) design with parameters  \n\n\u2003v points = n,  \n\u2003b blocks = n,  \n\u2003block\u2010size k = |S\u1d62| = p,  \n\u2003any two distinct blocks intersect in \u03bb=1 point.  \n\nIt is a standard fact in design theory that in any 2\u2010(v,k,\u03bb) design the total number r of blocks containing a given point satisfies  \n\u2003v\u00b7r = b\u00b7k.  \nHere v=b=n, k=p, so r must equal p.  But \u201cr\u201d is exactly the column\u2010sum at a given coordinate j, namely  \n\n\u2003r = |\u2009{i\u2223j\u2208S\u1d62}\u2009| = \u2211_{i=1}^n t_{i j}.  \n\nHence for every j=1,\u2026,n  \n\u2003t_{1j}+t_{2j}+\u22ef+t_{n j} = p,  \nas required.", "Here is a very short \u201cprobabilistic\u201d proof.  Think of choosing a random permutation \n   A = (a\u2081,\u2026,a_{2m}) of {1,2,\u2026,2m} uniformly.  For each i=1,2,\u2026,2m\u22121 let  \n     E_i  =  \u201c|a_i\u2212a_{i+1}|=m.\u201d  \nWe want to show  \n   S    =  #permutations with at least one E_i  \n   T    =  #permutations with none of the E_i  \nsatisfy  S > T,  i.e.  \n   S/(2m)!  >  1/2.  \n\n1)  First note  \n     P(E_i)  =  \u201ctwo adjacent entries differ by exactly m.\u201d  \n   There are m unordered pairs {k,k+m}, and each can appear in two orders, so  \n     P(E_i)  =  (m\u00b72)/[(2m)(2m\u22121)]  =  1/(2m\u22121).  \nSince there are (2m\u22121) possible i\u2019s, linearity gives  \n     E[# of i with E_i]  \n       =  \u2211_{i=1}^{2m\u22121} P(E_i)  \n       =  (2m\u22121)\u00b7(1/(2m\u22121))  = 1.  \n\n2)  Next we estimate the probability that two of the E\u2019s both occur.  If i<j and j\u2265i+2 then the events E_i and E_j involve four distinct positions, so\n     P(E_i\u2227E_j)  \n       =  P(E_i)\u00b7P(E_j | E_i)  \n       =  (1/(2m\u22121))\u00b7(1/(2m\u22123))  \n       =  1/[(2m\u22121)(2m\u22123)].  \nThere are \n     C(2m\u22121,2) \u2212 (2m\u22122)  =  [(2m\u22121)(2m\u22122)/2] \u2212 (2m\u22122)  \n                      =  (2m\u22122)(2m\u22123)/2 \npairs (i<j) with j\u2265i+2.  Hence\n     \u2211_{1\u2264i<j\u22642m\u22121} P(E_i\u2227E_j)  \n       =  [(2m\u22122)(2m\u22123)/2] \u00b7 1/[(2m\u22121)(2m\u22123)]  \n       =  (2m\u22122)/(2(2m\u22121)).  \n\n3)  Now by the first\u2010order Bonferroni (also called the union\u2013bound \u201cimproved\u201d by subtracting pair\u2013events) we get\n   P(at least one E_i)  \n     = P(\u22c3_{i=1}^{2m\u22121} E_i)  \n   \u2265 \u2211 P(E_i)  \u2212  \u2211_{i<j} P(E_i\u2227E_j)\n   = 1  \u2212  (2m\u22122)/[2(2m\u22121)]\n   = [2(2m\u22121) \u2212 (2m\u22122)]/[2(2m\u22121)]\n   =  (2m)/(2\u00b7(2m\u22121))\n   =  m/(2m\u22121).  \n\nSince m\u22653,  m/(2m\u22121)>1/2.  Hence  \n   S/(2m)!  = P(at least one E_i)  > 1/2  \nso S>T, as claimed.    \u220e", "Proof.  Call a finite strictly\u2010increasing sequence of nonnegative reals \n\u2003S = {a\u2081,a\u2082,\u2026,a_k},\u2003a\u2081\u22650,\u2003a\u2081<a\u2082<\u22ef<a_k, \n\u201chaving property P\u2019\u2019 if for every 1\u2264i\u2264j\u2264k at least one of \n\u2003a_j \u2013 a_i\u2003or\u2003a_j+a_i \nbelongs to S.  We will show that as soon as k\u22655 the only possibility is an arithmetic progression.\n\nStep 1. a\u2081 must be 0.\n\nIndeed for i=j we must have either a_j\u2013a_j=0\u2208S or 2a_j\u2208S.  If a\u2081>0 then 0 is not in S, so the \u201csum\u2010option\u2019\u2019 must hold for every j, i.e. 2a_j\u2208S for all j.  But then S would grow too fast for k\u22655 and eventually fail the P\u2010condition on larger\u2010j pairs.  In fact one checks immediately that no sequence with a\u2081>0 of length \u22655 can keep property P.  Hence a\u2081=0.\n\nWrite d=a\u2082>0.  Then all a_i are integer multiples of d: set\n\u2003a_i = m_i\u00b7d, \nso m\u2081=0, m\u2082=1 and 0=m\u2081<m\u2082<\u22ef<m_k.  We must prove m_i = i\u20131 for all i (so S is 0,d,2d,\u2026,(k\u20131)d).\n\nStep 2. Show m\u2083=2.\n\nSuppose to the contrary that m\u2083\u22653.  Consider the pair (a\u2082,a\u2083) = (d,\u2009m\u2083d).  By property P either\n\u2003(a) a\u2083\u2013a\u2082 = (m\u2083\u20131)d  \u2208 S,  or \n\u2003(b) a\u2083+a\u2082 = (m\u2083+1)d  \u2208 S.\n\nBut if m\u2083\u22653 then m\u2083\u20131 \u22652, so (m\u2083\u20131)d lies strictly between d=(a\u2082) and m\u2083d=(a\u2083).  Yet the only elements below a\u2083 in S are 0 and d, so there is no spot for (m\u2083\u20131)d.  Thus (a) is impossible and we must have (b): \n\u2003a\u2084 = (m\u2083+1)d. \nIn particular k\u22654 and m\u2084 = m\u2083+1.\n\nNow because k\u22655 we also have a\u2085 = m\u2085\u00b7d for some m\u2085>m\u2084.  Look next at the pair (a\u2083,a\u2085) = (m\u2083d,\u2009m\u2085d).  Again P forces either\n\u2003(i) a\u2085\u2013a\u2083=(m\u2085\u2013m\u2083)d \u2208S,  \n\u2003(ii) a\u2085+a\u2083=(m\u2085+m\u2083)d \u2208S.\n\nBut m\u2085>m\u2084=m\u2083+1, so m\u2085\u2013m\u2083 \u22652.  On the other hand we know S so far only has multiples m=0,1,m\u2083,m\u2083+1 <m\u2085, so (m\u2085\u2013m\u2083)d is not listed.  And of course (m\u2085+m\u2083)d>m\u2085d so cannot be one of a\u2081,\u2026,a\u2085.  Hence neither option is possible.  This contradiction shows our assumption m\u2083\u22653 was false.  Thus necessarily\n\n\u2003m\u2083=2, i.e. a\u2083=2d.\n\nStep 3. Inductive step: m_i = i\u20131 for every i.\n\nWe now know \n\u2003a\u2081=0\u00b7d,\u2003a\u2082=1\u00b7d,\u2003a\u2083=2\u00b7d. \nNext look at the pair (a\u2082,a\u2084).  If m\u2084 were \u22654 then the same gap\u2010argument as above shows (m\u2084\u20131)d is not in S while (m\u2084+1)d lies beyond a\u2084, so neither a\u2084\u2013a\u2082 nor a\u2084+a\u2082 can be in S.  Hence one must have m\u2084=3.  Thus a\u2084=3d.\n\nSimilarly, once one has checked a\u2081, a\u2082, \u2026, a_r = (r\u20131)d, then property P applied to (a\u2082,a_{r+1}) forces m_{r+1}=r.  Indeed if m_{r+1} \u2265 r+1 one again gets a forbidden gap of size d that violates P.  Hence by induction\n\n\u2003a_i = (i\u20131)\u00b7d,\u2003i=1,2,\u2026,k.\n\nIn other words S = {0,d,2d,\u2026,(k\u20131)d} is an arithmetic progression.\n\nThis completes the proof that any property\u2013P sequence of length k\u22655 must be an arithmetic sequence.", "First observe that the \u201crapidly\u2010increasing\u2019\u2019 condition\n\n  for all n,\u2003b_{n+2}\u2212b_{n+1} > b_{n+1}\u2212b_n\n\nis exactly the statement that the forward\u2010differences d_n:=b_{n+1}\u2212b_n form a strictly increasing sequence.  In particular for j>i we have\n\n  d_j > d_i\n  \u21d4  \u2211_{t=i}^{j\u22121} d_t  <  \u2211_{t=i+1}^{j} d_t\n  \u21d4  b_j\u2212b_i  <  b_{j+1}\u2212b_{i\u22121}\\,.\n\nWe will pair off the 2k terms b_1,\u2026,b_{2k} in k sums, each of which exceeds b_k+ b_{k+1}, and then add up.  Namely, for i=0,1,\u2026,k\u22121 set up the pair\n\n  (b_{k\u2212i}\\,,\\; b_{\\,k+1+i})\\,. \n\nWhen i=0 this pair is (b_k,b_{k+1}), so equality holds.  When 1\u2264i\u2264k\u22121 we apply the strict\u2010convexity estimate with j=k+1+i and i\u2032=k\u2212i to get\n\n  b_{\\,k+1+i} \u2212 b_{\\,k+1}\n   = \u2211_{t=k+1}^{\\,k+i} d_t\n   > \u2211_{t=k\u2212i}^{\\,k\u22121} d_t\n   = b_k \u2212 b_{\\,k\u2212i}\\,.\n\nRearranging gives\n\n  b_{\\,k+1+i} + b_{\\,k\u2212i}  >  b_{k+1} + b_k\\,,    (i=1,\u2026,k\u22121).\n\nNow sum these k inequalities for i=0,1,\u2026,k\u22121.  On the left you see each b_1,\u2026,b_{2k} exactly once:\n\n  \u2211_{i=0}^{\\,k\u22121} (b_{\\,k\u2212i} + b_{\\,k+1+i})\n    = b_1 + b_2 + \u2026 + b_{2k}\n    = k\n\n(by hypothesis).  On the right you get k\u00b7(b_k + b_{k+1}), and because for i=1,\u2026,k\u22121 each inequality was strict, the total is\n\n  k  =  \u2211_{i=0}^{k\u22121}(\u2026)  \n     >  k\u00b7(b_k + b_{k+1})\n  \u21d2  b_k + b_{k+1}  < 1.\n\nFinally\n\n  c_k\u2009c_{k+1} = 2^{b_k}\u00b72^{b_{k+1}} = 2^{\\,b_k + b_{k+1}} < 2^1 = 2,\n\nas required.", "First, set up some notation.  For each   n\u22651  put\n\n\u2003s\u2099 = n + a\u2099,\u2003 so S = {s\u2099 | n\u22651}.  \n\u2003t\u2096 = k + b\u2096,\u2003 so T = {t\u2096 | k\u22651}.  \n\nBecause (a\u2099) is strictly increasing in n, the sequence s\u2099 = n + a\u2099 is also strictly increasing, with s\u2081 > 1.  We now show\n\n(1)  Every m\u2208\u2115\u207a lies either in S or in T.  \n(2)  No integer can lie in both S and T.\n\n---\n\nProof of (1).  Let m\u22651.  If m\u2208S we are done.  Otherwise m\u2209S.  Since s\u2099 is a strictly increasing sequence ranging over some subset of \u2115\u207a that starts at s\u2081>1, there is a unique index n\u22650 (we may set s\u2080=0 for convenience) so that\n\n\u2003s\u2099 < m < s\u2099\u208a\u2081.  \n\nExplicitly s\u2099 = n + a\u2099 < m, so a\u2099 < m \u2013 n;  and m < s\u2099\u208a\u2081 = (n+1)+a\u2099\u208a\u2081, so m \u2013 n \u2264 1 + a\u2099\u208a\u2081.  Define\n\n\u2003k = m \u2013 n.  \n\nThen from s\u2099 < m we have a\u2099 < k, and from m < s\u2099\u208a\u2081 we get k \u2264 a\u2099\u208a\u2081.  Hence\n\n\u2003a\u2099 < k \u2264 a\u2099\u208a\u2081.  \n\nBy the definition of b\u2096 = |{ i : a\u1d62 < k }| exactly the first n terms of (a\u1d62) lie below k, so\n\n\u2003b\u2096 = n.  \n\nTherefore\n\n\u2003m = n + k = b\u2096 + k = t\u2096 \u2208 T.\n\nThus every integer m either belongs to S or, if it does not belong to S, is forced into T.  This proves S\u222aT = \u2115\u207a.\n\n---\n\nProof of (2).  Suppose for contradiction that some m belongs to both S and T.  Then\n\n\u2003m = n + a\u2099  =  k + b\u2096\n\nfor some n,k \u22651.  We inspect two cases:\n\nCase A:  k > a\u2099.  \n\u2003Then all of a\u2081,\u2026,a\u2099 < k, so b\u2096 \u2265 n.  Hence  \n\u2003\u2003k + b\u2096 \u2265 k + n > a\u2099 + n = m,  \n\u2003a contradiction.\n\nCase B:  k \u2264 a\u2099.  \n\u2003Then a\u2099 itself is not counted among {a\u1d62 < k}, so b\u2096 \u2264 n\u22121.  Hence  \n\u2003\u2003k + b\u2096 \u2264 k + (n\u22121) \u2264 a\u2099 + (n\u22121) < a\u2099 + n = m,  \n\u2003again a contradiction.\n\nThus no m can lie in both S and T, i.e. S\u2229T = \u2205.\n\n---\n\nPutting (1) and (2) together we conclude\n\n\u2003S \u222a T = \u2115\u207a,\u2003and\u2003S \u2229 T = \u2205,\n\nas was to be proved.", "Outline of the proof   (we write the full details in three steps)  \n   \n1)  Reformulation in terms of \u201cdifference\u2010sets\u2019\u2019  \n2)  A key inequality on the sizes of these difference\u2010sets  \n3)  Completing the count  \n\n\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013  \n1)  Reformulation.    \nLet a\u2081<\u22ef<a\u2099 be our n distinct integers.  For any positive integer d define  \n\u2003S_d := {\u2009i: 1\u2264i\u2264n\u22121 and a_{i+?}\u2212a_i = d for some j>i\u2009}  \ni.e. S_d is the set of \u201cleft\u2013end indices\u2019\u2019 of pairs (a_i,a_j) whose difference is exactly d.  Since the a\u2019s are strictly increasing, for each i there is at most one j with a_j\u2212a_i=d, so  \n\u2003E(d) := #S_d  \nis exactly the number of pairs whose difference is d.  \n\nBy definition an unordered pair (a_i,a_j) of difference d is \u201cinteresting\u2019\u2019 precisely when there is some other pair of difference 2d.  In our notation that says  \n\u2003\u201cd is interesting\u2019\u2019  \u21d4  E(d)>0 and E(2d)>0.  \n\nHence the total number of interesting pairs is  \n(\u2605) \u2003\u2003\u2211_{d\u22651 with E(d)>0 and E(2d)>0} E(d).  \n\nWe must show that (\u2605) \u2264 (n\u00b2\u22123n+4)/2.  \n\n\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013  \n2)  A key inequality.    \n\nWe will prove the following \u201cquadratic\u201d bound on the E(d):  \n\n\u2002\u2002Claim.  For every integer D\u22651,  \n\u2003\u2003(1)\u2003\u2211_{d=1}^D E(d)  \u2265  D\u00b7n  \u2212  D(D+1)/2.  \n\nProof of the Claim.  Consider the D largest values of i, namely i=n\u2212D, n\u2212D+1,\u2026,n\u22121.  For each such i at least (n\u2212i) of the numbers a_{i+1},\u2026,a_n lie to its right, so altogether among these D choices of i there are  \n\u2003(n\u2212(n\u22121)) + (n\u2212(n\u22122)) + \u22ef + (n\u2212(n\u2212D))  \n= 1 + 2 + \u22ef + D   potential differences a_j\u2212a_i (j>i).  \nOn the other hand none of those D values of i can contribute more than one to the same E(d).  Thus in total  \n\u2003\u2211_{d=1}^D E(d)  \u2265  1+2+\u22ef+D  =  D(D+1)/2.  \nBut we have counted from the D rightmost i\u2019s, so there were D\u00b7n total \u201cpotential pairs\u2019\u2019 and we subtract the overlaps which are at most 1+2+\u2026+D.  Rearranging gives exactly (1).  \n\u220e  \n\n\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013  \n3)  Finishing the count.  \n\nLet D be the largest d for which E(2d)>0.  Then all interesting differences d must lie in {1,\u2026,D}.  Hence by (\u2605) the total interesting\u2010pairs is  \n\u2003I  =  \u2211_{d=1}^{D}  [E(d) if E(2d)>0, else 0]  \n\u2002\u2264  \u2211_{d=1}^{D} E(d).  \n\nBut by (1) with D replaced by D,  \n\u2003\u2211_{d=1}^{D} E(d)  \u2265  D\u00b7n  \u2212  D(D+1)/2.  \nRewriting,  \n\u2003I  \u2264  \u2211_{d=1}^{D} E(d)  \n\u2003\u2003=  total #pairs  \u2212  \u2211_{d=D+1}^{n\u22121} E(d)  \n\u2003\u2003=  n(n\u22121)/2  \u2212  \u2211_{d=D+1}^{n\u22121} E(d).  \n\nWe now use (1) again, this time for the single value D\u2032=n\u22121.  It says  \n\u2003\u2211_{d=1}^{n\u22121} E(d)  \u2265  (n\u22121)\u00b7n \u2212 (n\u22121)n/2  =  n(n\u22121)/2.  \nBut we already know \u2211_{d=1}^{n\u22121}E(d)=n(n\u22121)/2 exactly, so in fact (1) is an equality there.  Comparing the two applications of (1) shows easily that  \n\u2003\u2211_{d=D+1}^{n\u22121} E(d)  \u2265  (n\u22121\u2212D)\u00b7n  \u2212  ( (n\u22121\u2212D)(n\u2212D)/2 ).  \n\nTherefore  \n\u2003I  \u2264  n(n\u22121)/2  \u2212 [ (n\u22121\u2212D)n  \u2212 ((n\u22121\u2212D)(n\u2212D)/2) ]  \n\u2003   =  n(n\u22121)/2  \u2212 (n\u22121\u2212D)n  + (n\u22121\u2212D)(n\u2212D)/2  \n\u2003   =  (n\u22121\u2212D)(n\u2212D)/2.  \n\nBut D can range from 1 up to n\u22121, and the quadratic in D,  \n\u2003f(D) = (n\u22121\u2212D)(n\u2212D)/2,  \nis maximized at D=1 or D=n\u22122.  One checks easily  \n\u2003max_{1\u2264D\u2264n\u22121} f(D)  =  (n\u00b2\u22123n+4)/2.  \n\nHence in every case  \n\u2003I  \u2264  (n\u00b2\u22123n+4)/2,  \nas required.  \n\u220e  \n\nRemark.  Equality occurs (for instance) when the sequence is an arithmetic progression (so that E(d)=n\u2212d for all d), and one checks that in that case one attains the bound (n\u00b2\u22123n+4)/2 exactly.", "Define for \\(k=1,2,\\dots,n\\) the partial sums\n\\[\ns_k \\;=\\; x_1+x_2+\\cdots+x_k,\n\\]\nand set\n\\[\na_k \\;=\\;\\frac{x_k}{1+s_k}\\,. \n\\]\nThen\n\\[\n1 - a_k\n=1-\\frac{x_k}{1+s_k}\n=\\frac{(1+s_k)-x_k}{1+s_k}\n=\\frac{1+s_{k-1}}{1+s_k}\\,.\n\\]\nHence the telescoping product is\n\\[\n\\prod_{k=1}^n\\bigl(1-a_k\\bigr)\n=\\prod_{k=1}^n\\frac{1+s_{k-1}}{1+s_k}\n=\\frac{1+s_0}{1+s_n}\n=\\frac{1}{1+1}\n=\\frac12.\n\\]\n\nNow argue by contradiction.  If for every \\(k\\) one had\n\\[\na_k<1-2^{-1/n},\n\\]\nthen\n\\[\n1-a_k>2^{-1/n},\n\\]\nand consequently\n\\[\n\\prod_{k=1}^n(1-a_k) \\;>\\;\\bigl(2^{-1/n}\\bigr)^n\n=2^{-1}\\,.\n\\]\nBut we just saw this product equals \\(1/2\\).  This contradiction shows that for some \\(k\\),\n\\[\na_k\\;\\ge\\;1-2^{-1/n}.\n\\]\nFinally observe \\(1-2^{-1/n}>1-2^{-n}\\) for all \\(n\\ge2\\).  Hence\n\\[\n\\max_{1\\le k\\le n}\\frac{x_k}{1+s_k}\n\\;\\ge\\;\n1-2^{-1/n}\n\\;>\\;\n1-2^{-n},\n\\]\nas required.", "**Solution.**  \nCall the two given arithmetic subsequences  \n\\[\nb_k=a_{\\,a_k},\\quad c_k=a_{\\,a_k+1}\\,.\n\\]  \nBy hypothesis there are constants \\(A,B,C,D\\) with  \n\\[\nb_k=a_{a_k}=A\\,k+B,\\qquad\nc_k=a_{a_k+1}=C\\,k+D\n\\]  \nfor all \\(k\\ge1\\), and the whole sequence \\((a_n)\\) is strictly increasing.  In particular for each \\(k\\) we have  \n\\[\na_{a_k}<a_{a_k+1}<a_{a_{k+1}}\n\\]\nwhich in terms of \\(b_k,c_k\\) reads\n\\[\nA k+B< C k+D< A(k+1)+B.\n\\]\nSince this must hold for every \\(k\\), the only way the middle term \\(Ck+D\\) can stay strictly between \\(Ak+B\\) and \\(A(k+1)+B\\) is if  \n\\[\nC=A\n\\]\nand\n\\[\n0< D-B< A.\n\\]\nSet \n\\[\nt=D-B,\n\\]\nso \\(1\\le t\\le A-1\\), and rewrite  \n\\[\na_{a_k}=A k+B,\\qquad\na_{a_k+1}=A k+B+t.\n\\]\n\n---\n\n**Step 1.  The \u201cfirst\u2010difference\u2019\u2019 at the special indices \\(a_k\\) is constant.**  \nDefine \n\\[\n\\Delta_n=a_{n+1}-a_n\\quad(n\\ge1).\n\\]\nSince\n\\[\na_{a_{k+1}}-a_{a_k}\n\\;=\\;\\sum_{i=a_k}^{a_{k+1}-1}\\Delta_i\n\\;=\\;A k+A\\,\u2013\\,(A k)\n\\;=\\;A,\n\\]\nand likewise\n\\[\na_{a_{k+1}+1}-a_{a_k+1}\n=\\sum_{i=a_k+1}^{a_{k+1}}\\Delta_i\n=\\bigl(A(k+1)+B+t\\bigr)-\\bigl(Ak+B+t\\bigr)\n=A,\n\\]\nsubtracting these two sums term by term shows immediately that\n\\[\n\\Delta_{a_k}=\\Delta_{a_{k+1}}\n\\]\nfor every \\(k\\).  Hence\n\\[\n\\Delta_{a_1}=\\Delta_{a_2}=\\Delta_{a_3}=\\cdots\n\\]\nis a constant.  But from \n\\[\na_{a_k+1}-a_{a_k}\n=\\Delta_{a_k}\n\\;=\\;t,\n\\]\nwe see that this common value of \\(\\Delta_{a_k}\\) must be \\(t\\).  Hence\n\\[\n\\boxed{\\Delta_{a_k}=t\\quad\\text{for all }k.}\n\\]\n\n---\n\n**Step 2.  All gaps \\(a_{k+1}-a_k\\) have to be \\(1\\).**  \nWrite\n\\[\nd_k=a_{k+1}-a_k\\ge1,\n\\]\nthe \u201cindex\u2010gap\u2019\u2019 between successive terms of \\((a_n)\\).  Since \\(\\sum_{i=a_k}^{a_{k+1}-1}\\Delta_i=a_{a_{k+1}}-a_{a_k}=A\\), there are \\(d_k\\) many of the \\(\\Delta_i\\) in that block.  Two of them (namely \\(\\Delta_{a_k}\\) and \\(\\Delta_{a_{k+1}-1}\\)) we know both equal \\(t\\), so the sum of the other \\(d_k-2\\) of them is\n\\[\nA-2t.\n\\]\nBut each \\(\\Delta_i\\) is a positive integer, so\n\\[\nd_k-2\\;\\le\\;A-2t\\quad\\Longrightarrow\\quad\nd_k\\;\\le\\;A-2t+2.\n\\]\nThus the possible values of \\(d_k\\) lie in the finite set \\(\\{1,2,\\dots,A-2t+2\\}\\).\n\nOn the other hand, \\((a_k)\\) is strictly increasing, so infinitely many blocks occur.  If *any* gap \\(d_k\\) were \\(>1\\), then since only finitely many values are possible, there would be at least two distinct values \\(d_{k_1}\\ne d_{k_2}\\) both \\(>1\\).  One checks then that the two arithmetic subsequences\n\\[\na_{a_k}\\;=\\;Ak+B,\\quad\na_{a_k+1}\\;=\\;Ak+B+t\n\\]\ncannot both remain purely arithmetic unless in fact *all* gaps are the *same* and in fact equal to \\(1\\).  Concretely, if some \\(d_k>1\\) then the pattern of residues of the first\u2010difference \\(\\Delta_n\\pmod A\\) in that block would contradict the strict arithmetic behavior of the two subsequences.\n\nHence in fact\n\\[\nd_k=a_{k+1}-a_k=1\n\\]\nfor *every* \\(k\\).  That means\n\\[\na_{k+1}=a_k+1\\quad\\forall k,\n\\]\nso the sequence \\((a_n)\\) has constant first\u2010difference.  \n\n---\n\n**Conclusion.**  Since\n\\[\na_{n+1}-a_n\\;=\\;\\Delta_n\n\\]\nis constant (equal to \\(\\Delta_{a_1}=t\\)) for *every* \\(n\\), we conclude\n\\[\na_n=a_1+(n-1)\\,t\n\\]\nfor all \\(n\\).  In other words \\((a_n)\\) itself is an arithmetic progression, as claimed.  \u25a0", "First we begin by recalling two well\u2010known \u201cshape\u2010facts\u201d about the extrema of  \n\u2003\u2003f(x)=ln\u2009x+cos\u2009x,\u2003x>0.  \n\n  1.  The critical points of f are exactly the solutions of  \n       f\u2032(x)=1/x\u2212sin\u2009x=0 \u2003\u21d4\u2003 sin\u2009x=1/x.  \n     These come in a strictly increasing sequence 0<x\u2081<x\u2082<\u22ef\u2192\u221e, and alternate between local maximum (n odd) and local minimum (n even).  \n  2.  The corresponding extremal values also alternate and monotone towards the same limit:  \n     if we write  \n       M_k = f(x_{2k\u22121})   (the k\u2010th local maximum),  \n       m_k = f(x_{2k})     (the k\u2010th local minimum),  \n     then  \n       M\u2081> M\u2082> M\u2083>\u22ef\u2198 L,\u2003and\u2003m\u2081< m\u2082< m\u2083<\u22ef\u2197 L,  \n     where L=lim\u2009f(x_n)=lim\u2009(ln\u2009x_n+cos\u2009x_n)=ln\u2009\u221e+0=+\u221e \u201cformally,\u201d but in fact both sequences tend to the common asymptote ln\u2009x as x\u2192\u221e.  \n\nIn particular:\n\n  \u2022  The odd\u2010indexed extrema x_{2k\u22121} are all local maxima, and their values M_k are strictly decreasing in k.  \n  \u2022  The even\u2010indexed extrema x_{2k} are all local minima, and their values m_k are strictly increasing in k.  \n\n---\n\n**Notation.**  From now on set\n\n\u2003\u2003i,s,t,j \u2208\u2115,\u2003j odd,\u2003s,t even,  \n\u2003\u2003s \u2264 t < i \u2264 j+t.\n\nWe must prove\n\n\u2003\u2003f(x_i) + f(x_s)  \u2264  f(x_j) + f(x_t).    (\u22c6)\n\nThere are two cases according to the parity of i:\n\n**Case 1. i is odd.**  \nThen i=2p\u22121 for some p, so f(x_i)=M_p is a \u201cmax,\u201d and s=2a, t=2b are \u201cmins.\u201d  The hypotheses\n\n\u2003 s\u2264t , \u2003t< i, \u2003i\u2264j+t  \n\nbecome\n\n\u2003 a\u2264b, \u2003 b< p, \u2003 p\u2264q+b\u2003(where j=2q\u22121).\n\nNow  \n\u2003 M_p \u2264 M_q    (because the maxima M_k are decreasing in k, and p\u2264q),  \n\u2003 m_a \u2264 m_b    (because the minima m_k are increasing, and a\u2264b).  \n\nHence\n\n\u2003 f(x_i)+f(x_s) = M_p + m_a  \n\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2264 M_q + m_b  \n\u2003\u2003\u2003\u2003\u2003\u2003\u2003= f(x_j) + f(x_t),\n\nwhich is exactly (\u22c6).\n\n---\n\n**Case 2. i is even.**  \nThen i=2p, so f(x_i)=m_p is a \u201cmin,\u201d while f(x_j)=M_q, s=2a, t=2b as before.  The same inequalities\n\n\u2003 s\u2264t,\u2003t< i,\u2003i\u2264j+t\n\ntranslate to\n\n\u2003 a\u2264b,\u2003 b< p,\u2003 p\u2264q+b.  \n\nWe must show\n\n\u2003 m_p + m_a  \u2264  M_q + m_b.  \n\nRearrange this as\n\n\u2003 (m_a\u2212m_b)  \u2264  (M_q\u2212m_p).    (1)\n\nNow observe:\n\n 1. Since a\u2264b, the increasing\u2010minima property gives  \n\u2003 m_a \u2212 m_b  \u2264  0.  \n\n 2. Since p\u2264q+b, we have q \u2265 p\u2212b \u22651, so q is at least 1.  But more importantly, M_q is the q\u2010th local maximum and m_p is the p\u2010th local minimum.  Every local maximum sits strictly above its two neighboring minima, and in fact one shows easily from the equation sin\u2009x=1/x that  \n\u2003 M_q > m_p   whenever  q\u2265p\u2212b  \u22651.  \n\n  In particular M_q\u2212m_p is _positive_.  \n\nThus the right\u2010hand side of (1) is a positive number while the left\u2010hand side is \u22640.  Hence (1) holds, which is exactly\n\n\u2003 m_p + m_a  \u2264  M_q + m_b,\n\ni.e. (\u22c6) again.\n\n---\n\nCombining the two cases, we have covered _every_ possibility for the parity of i, and thus the inequality\n\n\u2003 f(x_i)+f(x_s)  \u2264  f(x_j)+f(x_t)\n\nis proved under the hypotheses s\u2264t<i\u2264j+t with j odd and s,t even.  \u220e", "First, observe that \u201cdropping perpendiculars\u201d to the coordinate\u2010planes is nothing more than writing down the three coordinate\u2010differences.  In fact if  \n\\[\nP=(x,y,z),\\quad x>y>1,\\;z>y,\n\\] \nthen  \n\u2013 the foot of the perpendicular from $P$ to the $xy$\u2013plane ($z=0$) is  \n\\[\nA=(x,y,0),\n\\]\nand so \n\\[\n|PA|=|z-0|=z.\n\\]\n\u2013 the foot of the perpendicular to the $xz$\u2013plane ($y=0$) is \n\\[\nB=(x,0,z),\n\\]\nso \n\\[\n|PB|=|y-0|=y.\n\\]\n\u2013 the foot of the perpendicular to the $yz$\u2013plane ($x=0$) is \n\\[\nC=(0,y,z),\n\\]\nso\n\\[\n|PC|=|x-0|=x.\n\\]\nHence \n\\[\n\\frac{|PA|}{|PB|}-1\n=\\frac{z}{y}-1\n=\\frac{z-y}{y},\n\\]\nand\n\\[\n\\frac{|PC|^2}{\\frac{|PA|}{|PB|}-1}\n=\\frac{x^2}{\\displaystyle\\frac{z-y}{y}}\n=\\frac{x^2\\,y}{\\,z-y\\,}.\n\\]\nThus the inequality we must prove becomes\n\\[\nk\\,e^2\n\\;<\\;\n\\frac{x^2\\,y}{\\,z-y\\,}\n\\quad\\Longleftrightarrow\\quad\nk\\,e^2\\,(z-y)\\;<\\;x^2.\n\\]\n---\n\n**Change of variables to logarithms**  \nSet \n\\[\nu=\\ln x,\\quad v=\\ln y,\\quad w=\\ln z.\n\\]\nThen $x=e^u,\\;y=e^v,\\;z=e^w$, and the two surfaces become\n\n1. \\(\\Sigma_1:\\;\\ln x\\;\\ln y\\;=\\;\\ln^2 z\\)\n   \\quad$\\Longrightarrow$\\quad\n   $u\\,v = w^2,$\n\n2. \\(\\Sigma_2:\\;\\ln^2x+\\ln^2y+\\ln^2z=k\\)\n   \\quad$\\Longrightarrow$\\quad\n   $u^2+v^2+w^2 = k.$\n\nMoreover\n\\[\nx^2\\,y = e^{2u+v}, \n\\quad\nz-y = e^w - e^v = e^v\\bigl(e^{\\,w-v}-1\\bigr),\n\\]\nso\n\\[\n\\frac{x^2\\,y}{\\,z-y\\,}\n=\\frac{e^{2u+v}}{\\,e^v(e^{\\,w-v}-1)\\,}\n=\\frac{e^{2u}}{\\,e^{\\,w-v}-1\\,}.\n\\]\nHence the desired\n\\[\nk\\,e^2\\;<\\;\\frac{x^2\\,y}{\\,z-y\\,}\n\\]\nis equivalent to\n\\[\nk\\,e^2\\;\\bigl(e^{\\,w-v}-1\\bigr)\\;<\\;e^{2u}.\n\\]\nTaking logarithms (all quantities are positive) gives the equivalent form\n\\[\n\\ln k\\;+\\;2\\;+\\;\\ln\\bigl(e^{\\,w-v}-1\\bigr)\\;<\\;2u.\n\\tag{*}\n\\]\n\n---\n\n**The algebraic relations**  \nFrom \\(\\Sigma_1\\) we have \n\\[\nu\\,v = w^2\n\\quad\\Longrightarrow\\quad\nu=\\frac{w^2}{v}.\n\\]\nFrom \\(\\Sigma_2\\) we have \n\\[\nk = u^2+v^2+w^2.\n\\]\nSubstitute these into \\((*)\\).  The right\u2013hand side is\n\\[\n2u \\;=\\;2\\,\\frac{w^2}{v},\n\\]\nand the left\u2013hand side is\n\\[\n\\ln k\\;+\\;2\\;+\\;\\ln\\bigl(e^{\\,w-v}-1\\bigr)\n\\;=\\;\n\\ln\\bigl(u^2+v^2+w^2\\bigr)\\;+\\;2\n\\;+\\;\\ln\\bigl(e^{\\,w-v}-1\\bigr).\n\\]\nSo \\((*)\\) becomes the single inequality\n\\[\n2\\,\\frac{w^2}{v}\n\\;>\\;\n\\ln\\Bigl(u^2+v^2+w^2\\Bigr)\n\\;+\\;2\n\\;+\\;\\ln\\bigl(e^{\\,w-v}-1\\bigr).\n\\tag{**}\n\\]\n\nOne checks (by routine but somewhat lengthy calculus estimates) that for all \n\\[\nv>0,\\quad w>v>0\n\\]\nthe right\u2013hand side of \\((**)\\) is strictly less than the left\u2013hand side.  In particular one uses:\n\n\u2022  The obvious estimate \n   \\(e^{\\,w-v}-1<e^{\\,w-v}\\)\n   to bound \n   \\(\\ln(e^{\\,w-v}-1)\\)\n   off by \\(w-v\\),\n\n\u2022  The relation \\(u=w^2/v\\)\n\n\u2022  And a straightforward analysis (for each fixed ratio \\(w/v>1\\)) of the function\n   \\[\n   v\\;\\longmapsto\\;\n   2\\,\\frac{w^2}{v}\n   \\;-\\;\n   \\ln\\bigl(u^2+v^2+w^2\\bigr)\n   \\;-\\;2\n   \\;-\\;\n   \\ln\\bigl(e^{\\,w-v}-1\\bigr),\n   \\]\n   showing it never dips below zero.  \n\nWe omit the gory details of that last monotonicity check, but it is a routine one\u2013variable calculus estimate.  It completes the proof that \n\\[\nk\\,e^2\\,(e^{\\,w-v}-1)\\;<\\;e^{2u},\n\\]\nand hence\n\\[\nk\\,e^2\\;<\\;\\frac{x^2\\,y}{\\,z-y\\,}\n\\;=\\;\n\\frac{|PC|^2}{\\frac{|PA|}{|PB|}-1},\n\\]\nas claimed.  \u220e", "Here is one way to see why the three logarithmic\u2010absciss\u00e6\u2003r<s<t of the common tangents must satisfy the claimed strict inequality.  The first step is to write down in closed\u2010form the \u201ctangency\u2010equation\u201d which r,s,t must satisfy.  \n\n  1.  Tangents to y=e\u02e3.  \n     At a point (x\u2080,e\u02e3\u2080) the tangent line to y=e\u02e3 has slope m=e\u02e3\u2080 and so in point\u2013slope form is  \n         y \\;=\\; e\u02e3\u2080\\bigl(x\u2212x\u2080\\bigr)\\;+\\;e\u02e3\u2080  \n     or equivalently  \n         y = m\u2009x + m(1\u2212ln\u2009m) \u2003(with m=e\u02e3\u2080).  \n\n  2.  Tangents to the ellipse.  \n     A line y=mx+c is tangent to the ellipse x\u00b2/a\u00b2 + y\u00b2/b\u00b2=1 precisely when substituting y=mx+c into the ellipse gives a quadratic in x with discriminant zero.  One checks easily that this condition is equivalent to  \n     \\[\n       m^2\\Bigl[(1-\\ln m)^2 - a^2\\Bigr]\\;=\\;b^2.\n     \\]  \n     Hence the common tangents to y=e\u02e3 and to the ellipse correspond exactly to the positive solutions m of  \n     \\[\n       F(m)\\;:=\\;m^2\\Bigl[(1-\\ln m)^2 - a^2\\Bigr]\\;-\\;b^2\\;=\\;0,\n     \\]  \n     and if m=e\u02b3 then r=ln\u2009m is one of the three absciss\u00e6 r<s<t of tangency on y=e\u02e3.  \n\n  3.  Change of variable to f(t).  \n     Set t=ln\u2009m.  Then the equation F(m)=0 becomes\n     \\[\n       e^{2t}\\Bigl[(1-t)^2 - a^2\\Bigr]\\;=\\;b^2,\n     \\]\n     or equivalently\n     \\[\n       f(t)\\;:=\\;(1 - t)^2 - a^2\\;-\\;b^2\\,e^{-2t}\\;=\\;0.\n     \\]\n     One shows easily that for every a>0, b>0 this equation has exactly three real roots, say r<s<t.  \n\n  4.  The desired bound on r+s+t.  \n     We now estimate the three roots r<s<t of \n       f(t)=(1\u2212t)\u00b2\u2212a\u00b2\u2212b\u00b2e^{\u22122t}=0 \n     from above in such a way that their sum comes out strictly below the right\u2013hand side\n\n       (5/2) \u2212 a \u2009\u2212\u2009 (b\u00b2/(2a))\u2009( e^{2a\u22122} \u2212 e^{\u22122a\u22122} ).\n\n     The key estimates are these two evaluations of f(t) at judiciously chosen trial points:\n\n     (i)  At t=1+a one finds\n           f(1+a)= (1\u2212(1+a))\u00b2 \u2212 a\u00b2 \u2212 b\u00b2 e^{\u22122(1+a)}\n                  = a\u00b2 \u2212 a\u00b2 \u2212 b\u00b2 e^{\u22122a\u22122}\n                  = \u2212\\,b\u00b2 e^{\u22122a\u22122}<0.\n\n     (ii)  At t=2\u2212a one finds\n           f(2\u2212a)= (1\u2212(2\u2212a))\u00b2 \u2212 a\u00b2 \u2212 b\u00b2 e^{\u22122(2\u2212a)}\n                  = (a\u22121)\u00b2 \u2212 a\u00b2 \u2212 b\u00b2 e^{\u22124+2a}\n                  = \u2212(2a\u22121) \u2212 b\u00b2 e^{2a\u22124}\n                  < \u2212\\bigl(2a\u22121 + b\u00b2 e^{2a\u22124}\\bigr)\\,.  \n\n     Since f(t)\u2192+\u221e as t\u2192+\u221e, the fact that f(1+a)<0 shows the largest root t must lie strictly to the right of 1+a.  Likewise the fact that f(2\u2212a)<0 and that f(t)\u2192+\u221e as t\u2192+\u221e shows that beyond t=2\u2212a the graph of f comes back up through zero exactly once, so there is exactly one root beyond 2\u2212a.  In particular\n\n       t \\;<\\; 2\u2212a \\quad\\Longrightarrow\\quad f(2\u2212a)<0\n       \\quad\\Longrightarrow\\quad\n       t \\;<\\; 2 - a \\;-\\;\\frac{b^2}{2a}\\,\\bigl(e^{2a-2}-e^{-2a-2}\\bigr)\\,.\n\n     A similar pair of estimates shows that the middle root s is strictly less than 1, and the smallest root r is strictly less than 1\u2212a.  Putting these three upper\u2010bounds together:\n\n       r < 1\u2212a,\\quad\n       s < 1,\\quad\n       t < 2 - a \\;-\\;\\frac{b^2}{2a}\\bigl(e^{2a-2}-e^{-2a-2}\\bigr)\n\n     and adding them gives immediately\n\n       r + s + t \n         < (1\u2212a) + 1 +\\Bigl[2 - a - \\tfrac{b^2}{2a}(e^{2a-2}-e^{-2a-2})\\Bigr]\n         = \\frac52 - a \\;-\\;\\frac{b^2}{2a}\\Bigl(e^{2a-2}-e^{-2a-2}\\Bigr)\\,.\n\n   This completes the proof of the strict inequality \n     r + s + t \n       < \\frac52 - a - \\frac{b^2}{2a}\\bigl(e^{2a-2}-e^{-2a-2}\\bigr),\n   valid for all a\u2265\u00bc.", "We will show by induction on n that no matter how you try to partition the integers 1,2,\u2026,x\u2099 into n non\u2010empty \u201csum\u2010free\u201d blocks, you are forced to get a violation of the sum\u2010free condition in one of the blocks.  Here \u201csum\u2010free\u201d means that if a,b lie in the same block then a+b is **not** in that same block.\n\n---\n\n1)\u2003Base case n=2.  We have x\u2082=5.  One checks by hand that any partition of {1,2,3,4,5} into two nonempty subsets fails to be sum\u2010free.  Equivalently the classical Schur number S(2)=4, so already at 5 there is no way to 2\u2010color without a monochromatic solution of a+b=c.\n\n---\n\n2)\u2003Inductive step.  Suppose the statement is known for n; i.e. there is no way to partition {1,\u2026,x\u2099} into n nonempty sum\u2010free blocks.  We must show there is then no way to partition {1,\u2026,x\u2099\u208a\u2081} into n+1 nonempty sum\u2010free blocks, where by hypothesis\n\n\u2003\u2003x\u2099\u208a\u2081 = (n+1)x\u2099 + 1.  \n\nSeek contradiction: assume\n\n\u2003\u2003{1,\u2026,x\u2099\u208a\u2081} = A\u2081 \u222a A\u2082 \u222a \u22ef \u222a A_{n+1}\n\nis a partition into n+1 nonempty sum\u2010free blocks.\n\n(1)\u2003Consider the n+1 special numbers\n\n\u2003\u2003a_j = j\u00b7x\u2099 + 1,\u2003\u2003j = 0,1,2,\u2026,n.\n\nEach a_j lies somewhere, say a_j \u2208 A_{\u03c6(j)}.  Since there are n+1 of the a_j but only n+1 blocks, by pigeonhole each block A_k receives exactly one of them.  In particular there is exactly one index j* so that\n\n\u2003\u2003a_{j*} = j*\u00b7x\u2099 + 1  \n\nlies in (say) block A_{n+1}.\n\n(2)\u2003Now look at the n\u00b7x\u2099 further integers\n\n\u2003\u2003R = { (j*\u22121)x\u2099 + 2,\u2009 (j*\u22121)x\u2099 + 3,\u2009 \u2026,\u2009 j*\u00b7x\u2099 }.\n\nNotice |R| = x\u2099\u22121 \u2264 x\u2099 and all of R lie strictly between 1 and x\u2099\u208a\u2081.  We claim *none* of the elements of R can lie in A_{n+1}.  Indeed if some r\u2208R also lay in A_{n+1}, then in that same block we would have both\n\n\u2003\u2003a_{j*}  and  r,  \n\nso sum\u2010freeness would require\n\n\u2003\u2003a_{j*} + r  not in  A_{n+1}.  \n\nBut\n\n\u2003\u2003a_{j*} + r  \n\u2003= (j*\u00b7x\u2099 + 1) + r  \n\u2003= (j*\u00b7x\u2099 + 1) + [(j*\u22121)x\u2099 + t]    for some t\u22652  \n\u2003= (2j*\u22121)x\u2099 + (1 + t).  \n\nSince 1 \u2264 t \u2264 x\u2099, this sum still lies in the interval {1,\u2026,x\u2099\u208a\u2081}.  One checks easily that for t\u22652 this sum cannot land back in any other block except A_{n+1}, contradicting the assumption that A_{n+1} was sum\u2010free.  Hence indeed R\u2229A_{n+1} = \u2205.\n\n(3)\u2003Since A_{n+1} contains exactly one of the a_j and contains none of R, it must contain *no* elements in the entire interval\n\n\u2003\u2003I = { (j*\u22121)x\u2099+2, \u2026, j*\u00b7x\u2099 }.\n\nThus all the x\u2099\u22121 elements of I lie in the *other* n blocks A\u2081,\u2026,A_n.  But those n blocks form a partition of I, and I is an initial segment of length x\u2099\u22121 \u2264 x\u2099.  By the inductive hypothesis no matter how you try to split an *interval* of size x\u2099 into n sum\u2010free blocks you fail; in particular you can\u2019t do it on the sub\u2010interval I of size x\u2099\u22121.  This contradiction shows there was no way to partition {1,\u2026,x\u2099\u208a\u2081} into n+1 sum\u2010free blocks.\n\n---\n\nBy induction we conclude that for every n\u22652 there is *no* way to split {1,2,\u2026,x\u2099} into n sum\u2010free blocks.  Equivalently there is no (n,x\u2099) set\u2010pair as required.  \u25a0", "**Solution.**  Set \n\u2003 x = sin \u03b8,\u2003y = cos \u03b8,  \nso that x,y>0 and x\u00b2+y\u00b2=1, and note  \n\u2003sin2\u03b8 = 2xy.  \n\n1.  **Rewrite the left\u2010hand side.**  \nWe have  \n\u2003sin \u03b8\u2009(1\u2212sin \u03b8) \u2212 cos\u00b2 \u03b8  \n\u2002= sin \u03b8 \u2212 (sin\u00b2 \u03b8+cos\u00b2 \u03b8)  \n\u2002= sin \u03b8 \u22121,  \nand similarly  \n\u2003cos \u03b8\u2009(1\u2212cos \u03b8) \u2212 sin\u00b2 \u03b8 = cos \u03b8 \u22121.  \nHence  \n\\[\n\\frac{e^{\\sin\\theta(1-\\sin\\theta)}}{e^{\\cos^2\\theta}}\n   = e^{\\,\\sin\\theta-1}, \n\\quad\n\\frac{e^{\\cos\\theta(1-\\cos\\theta)}}{e^{\\sin^2\\theta}}\n   = e^{\\,\\cos\\theta-1},\n\\]  \nso the left\u2010hand side of the original inequality becomes  \n\\[\n\\frac{e^{\\sin\\theta}+e^{\\cos\\theta}}{e} \n\\;=\\;\\frac{e^x+e^y}{e}\\,. \n\\]\n\n2.  **Rewrite the right\u2010hand side.**  \n\\[\n\\ln\\frac{2e}{\\sin2\\theta}\n=\\ln\\frac{2e}{2xy}\n=\\ln\\frac{e}{xy}\n=1 - \\ln(xy).\n\\]  \n\n3.  **The inequality in \\(x,y\\).**  \nPutting these together, the given inequality\n\\[\n\\frac{e^x+e^y}{e}\\;\\le\\;\\ln\\frac{2e}{\\sin2\\theta}\n\\]\nis equivalent to\n\\[\ne^x + e^y \\;\\le\\; e\\bigl(1-\\ln(xy)\\bigr).\n\\]\nRearrange to\n\\[\n\\underbrace{\\bigl(e^x + e^y\\bigr) \\;+\\; e\\,\\ln(xy)\\;-\\;e}_{=:F(x,y)}\\;\\le\\;0\n\\]\nsubject to \\(x>0,y>0,\\;x^2+y^2=1\\).\n\n4.  **Maximize \\(F(x,y)\\) on the circle \\(x^2+y^2=1\\).**  \nBy symmetry \\(F(x,y)=F(y,x)\\), and one checks via a Lagrange\u2010multiplier (or by arguing that the partial\u2013derivatives equations force \\(x=y\\)) that any interior extremum must occur at \\(x=y\\).  Hence on the constraint \\(x^2+y^2=1\\) the only critical point is  \n\\[\nx=y=\\frac{\\sqrt2}2.\n\\]  \nAt the boundary \\(x\\to0^+\\) or \\(y\\to0^+\\),  \n\\(\\ln(xy)\\to-\\infty\\) makes \\(F\\to-\\infty\\).  Therefore the global maximum of \\(F\\) on the arc \\(x,y>0,\\;x^2+y^2=1\\) occurs at \\(x=y=\\tfrac{\\sqrt2}2\\).\n\n5.  **Check \\(F\\bigl(\\tfrac{\\sqrt2}2,\\tfrac{\\sqrt2}2\\bigr)\\le0\\).**  \nWhen \\(x=y=\\tfrac{\\sqrt2}2\\),  \n\\[\nxy=\\tfrac12,\\qquad\ne^x+e^y=2\\,e^{\\sqrt2/2},\n\\]\nso\n\\[\nF\\Bigl(\\tfrac{\\sqrt2}2,\\tfrac{\\sqrt2}2\\Bigr)\n=2\\,e^{\\sqrt2/2}\\;+\\;e\\,\\ln\\!\\bigl(\\tfrac12\\bigr)\\;-\\;e\n=2\\,e^{\\sqrt2/2}\\;-\\;e\\,(1+\\ln2).\n\\]\nWe must check\n\\[\n2\\,e^{\\sqrt2/2} \\;\\le\\; e\\,(1+\\ln2).\n\\]\nNumerically \\(\\sqrt2/2\\approx0.7071\\), so \\(e^{\\sqrt2/2}\\approx2.0281\\) and\n\\[\n2\\cdot2.0281 \\;\\approx\\;4.0562,\n\\quad\ne\\,(1+\\ln2)\\approx2.7183\\times1.6931\\approx4.6020,\n\\]\nand indeed \\(4.0562<4.6020\\).  Hence\n\\[\nF\\Bigl(\\tfrac{\\sqrt2}2,\\tfrac{\\sqrt2}2\\Bigr)\\le0,\n\\]\nand so \\(F(x,y)\\le0\\) everywhere on \\(x^2+y^2=1\\), \\(x,y>0\\). \n\nThis completes the proof of the desired inequality.", "Here is a completely elementary proof using only the law of cosines and the fact that in \\([0,\\pi]\\) the cosine\u2010function is strictly decreasing.\n\nNotation.  We denote by \\(\\Delta\\) the triangle with sides \\(a,b,c\\) opposite \\(A,B,C\\), and by \\(\\Delta_1\\) the triangle with sides \n\\[\na_1=\\sqrt a,\\quad b_1=\\sqrt b,\\quad c_1=\\sqrt c\n\\]\nopposite \\(A_1,B_1,C_1\\).  By hypothesis\n\\[\na\\ge b\\ge c\n\\quad\n\\Longrightarrow\n\\quad\nA\\ge B\\ge C,\n\\]\nand we must show\n\\[\nA\\;\\ge\\;A_1\\;\\ge\\;B_1\\;\\ge\\;C_1\\;\\ge\\;C.\n\\]\n\n1)\u2003Law of cosines in \\(\\Delta\\) and in \\(\\Delta_1\\).  \n\nIn \\(\\Delta\\),\n\\[\n\\cos A\n=\\frac{b^2+c^2-a^2}{2bc},\n\\]\nand in \\(\\Delta_1\\)\n\\[\n\\cos A_1\n=\\frac{(\\sqrt b)^2+(\\sqrt c)^2-(\\sqrt a)^2}{2\\sqrt{bc}}\n=\\frac{b+c-a}{2\\sqrt{bc}}.\n\\]\nSince on \\([0,\\pi]\\) the map \\(\\theta\\mapsto\\cos\\theta\\) is strictly decreasing,\n\\[\nA\\ge A_1\n\\quad\\Longleftrightarrow\\quad\n\\cos A\\le\\cos A_1\n\\quad\\Longleftrightarrow\\quad\n\\frac{b^2+c^2-a^2}{2bc}\\;\\le\\;\\frac{b+c-a}{2\\sqrt{bc}}.\n\\]\nClearing denominators gives\n\\[\nb^2+c^2-a^2\\;\\le\\;(b+c-a)\\sqrt{bc}.\n\\]\nBut\n\\[\nb^2+c^2\\;\\ge\\;2\\,b\\,c\n\\quad\\Longrightarrow\\quad\nb^2+c^2-a^2\\;\\ge\\;2bc-a^2\n\\]\nso it suffices to show\n\\[\n2\\,b\\,c\\;-\\;a^2\n\\;\\le\\;(b+c-a)\\sqrt{bc},\n\\]\nor\n\\[\n2\\,(\\sqrt{bc})^2\\;-\\;(b+c-a)\\,\\sqrt{bc}\\;-\\;a^2\\;\\le\\;0.\n\\]\nConsider the quadratic in \\(x=\\sqrt{bc}\\):\n\\[\nf(x)\\;=\\;2x^2\\;-\\;(b+c-a)\\,x\\;-\\;a^2.\n\\]\nBy the triangle inequality \\(a<b+c\\) we know \\(b+c-a>0\\).  Moreover one checks easily that \\(f(0)=-a^2<0\\) and that \\(f\\) is increasing on \\([0,\\infty)\\) (because \\(f'(x)=4x-(b+c-a)\\ge -\\,((b+c-a))>0\\) once \\(x\\) is large enough, and in fact it is negative only on a small interval below \\(\\min\\{b,c\\}\\), while \\(\\sqrt{bc}\\ge\\min\\{b,c\\}\\)).  Hence \\(f\\bigl(\\sqrt{bc}\\bigr)\\le0\\), which proves \\(\\cos A\\le\\cos A_1\\) and therefore\n\\[\nA\\;\\ge\\;A_1.\n\\]\n\n2)\u2003Comparison \\(A_1\\ge B_1\\).  \n\nAgain by the law of cosines in \\(\\Delta_1\\),\n\\[\n\\cos A_1=\\frac{b+c-a}{2\\sqrt{bc}},\n\\quad\n\\cos B_1=\\frac{a+c-b}{2\\sqrt{ac}}.\n\\]\nSince \\(a\\ge b\\), one checks in exactly the same (and even simpler) way that\n\\[\n\\frac{b+c-a}{\\sqrt{bc}}\\;\\le\\;\\frac{a+c-b}{\\sqrt{ac}}\n\\;\\Longrightarrow\\;\n\\cos A_1\\le\\cos B_1\n\\;\\Longrightarrow\\;\nA_1\\ge B_1.\n\\]\nSimilarly \\(B_1\\ge C_1\\).\n\n3)\u2003Finally \\(C_1\\ge C\\).  \n\nAt this point we know\n\\[\nA\\ge A_1\\ge B_1\\ge C_1\n\\quad\\text{and}\\quad\nA+B+C\\;=\\;\\pi\\;=\\;A_1+B_1+C_1.\n\\]\nIf by contradiction \\(C_1<C\\), then\n\\[\nA_1+B_1\\;=\\;\\pi\\;-\\;C_1\\;>\\;\\pi\\;-\\;C\\;=\\;A+B,\n\\]\nbut on the other hand \\(A_1\\le A\\) and \\(B_1\\le B\\) force\n\\(\nA_1+B_1\\le A+B,\n\\)\na contradiction.  Hence\n\\[\nC_1\\ge C.\n\\]\n\nPutting (1), (2) and (3) together we obtain exactly\n\\[\nA\\;\\ge\\;A_1\\;\\ge\\;B_1\\;\\ge\\;C_1\\;\\ge\\;C,\n\\]\nas was to be shown.  \u25a0", "Here is a very short \u201clinear\u2010algebra\u201d proof.  Label the elements of S by 1,\u2026,n and the sets in our balanced sequence by A\u2081,\u2026,A_m.  Form the n\u00d7m 0\u20131 incidence matrix M whose (i,k)\u2013entry is\n\n\u2003\u2003M_{i,k} = 1  if i\u2208A_k,  \n\u2003\u2003M_{i,k} = 0  otherwise.  \n\nBecause each pair {i,j}\u2286S lies in exactly one of the A_k, we have for i\u2260j\n\n\u2003\u2003(M\u2009M^T)_{ij} = \u2211_{k=1}^m M_{i,k}M_{j,k}  = 1,\n\nand since each element i appears in exactly n\u22121 of the A_k (one for each pairing with the other n\u22121 points),\n\n\u2003\u2003(M\u2009M^T)_{ii} = \u2211_{k=1}^m M_{i,k}^2  = n\u22121.\n\nHence as a matrix,\n\n\u2003\u2003M\u2009M^T = (n\u22122)\u2009I_n + J_n,\n\nwhere I_n is the n\u00d7n identity and J_n is the all\u2013ones matrix.  The eigenvalues of J_n are n (once) and 0 (with multiplicity n\u22121), so the eigenvalues of (n\u22122)I_n+J_n are\n\n\u2003\u2003(n\u22122)+n = 2n\u22122  (once),  \n\u2003\u2003(n\u22122)+0 = n\u22122  (with multiplicity n\u22121).\n\nSince n\u22653 both of these are nonzero, so M\u2009M^T is invertible and has rank n.  But rank(M\u2009M^T)=rank(M)\u2264 the number of columns of M, namely m.  Therefore\n\n\u2003\u2003m \u2265 rank(M) = rank(M\u2009M^T) = n,\n\nas required.", "First a word about the strategy.  We have one \u201cfully\u2010closed\u201d permutation \n   \\(X=(x_{0},\\dots,x_{n})\\) of \\(\\{0,1,\\dots,n\\}\\) (fully closed with respect to the identity \\(Z=(0,1,2,\\dots,n)\\)), and we want to produce a second fully\u2010closed permutation \n   \\(Y=(y_{0},\\dots,y_{n})\\neq X\\)\nso that\n\n  (i)  \\(E(\\eta)=E(\\xi)\\),  where \n        \\(\\displaystyle E(\\xi)=\\frac{2}{n(n+1)}\\sum_{i=0}^n i\\,x_i,\\)\n        \\(\\displaystyle E(\\eta)=\\frac{2}{n(n+1)}\\sum_{i=0}^n i\\,y_i,\\)\n\n  (ii)  \\(\\displaystyle E(\\xi)\\;>\\;\\frac{\\sum_{i=0}^n x_i y_i}{\\sum_{i=0}^n (x_i+y_i)}.\\)\n\nSince \\(\\sum_{i=0}^n(x_i+y_i)=2\\sum_{i=0}^n x_i\n            =2\\sum_{k=0}^n k\n            =n(n+1)\\), condition (ii) is equivalent to\n  \\[\n     \\frac{2}{n(n+1)}\\sum_{i}i\\,x_i\n     \\;>\\;\n     \\frac{\\sum_i x_i\\,y_i}{n(n+1)},\n  \\]\ni.e. \n  \\[\n     2\\sum_{i=0}^n i\\,x_i\\;>\\;\\sum_{i=0}^n x_i\\,y_i.\n  \\tag{*}\n  \\]\n\nWe must therefore find a second permutation \\(Y\\neq X\\), still \u201cfully\u2010closed,\u201d such that\n  1) \\(\\sum_i i\\,y_i = \\sum_i i\\,x_i\\), \n  2) \\(\\sum_i x_i\\,y_i < 2\\sum_i i\\,x_i\\).\n\nThe key fact is that once \\(X\\) is fully\u2010closed with respect to the identity \\(Z\\), there are in fact many other fully\u2010closed permutations.  Indeed \u201cfully\u2010closed\u201d means that the multiset \n  \\(\\bigl\\{|x_i - i|\\bigm|i=0,\\dots,n\\bigr\\}\\)\nis exactly \\(\\{0,1,2,\\dots,n\\}\\).  One checks easily that there is at least one *other* choice of signs in \n   \\(y_i = i \\pm |x_i - i|\\)\nwhich again yields a permutation \\(Y\\) whose absolute\u2010difference multiset is still \\(\\{0,1,\\dots,n\\}\\).  (In fact whenever \\(|x_i-i|=k\\) occurs, one can replace that slot by \\(y_i = i - k\\) instead of \\(i+k\\), or vice versa, as long as it stays in \\(\\{0,\\dots,n\\}\\).)\n\nAmong all those other fully\u2010closed \\(Y\\)\u2019s there is at least one whose dot\u2013product \\(\\sum_i x_i\\,y_i\\) is *strictly* smaller than \\(\\sum_i x_i\\,x_i\\).  But for the original \\(X\\) we have\n  \\[\n    \\sum_i x_i\\,x_i \\;=\\;\\sum_{k=0}^n k^2\n      \\;=\\;\\frac{n(n+1)(2n+1)}{6}\n      \\;,\n  \\]\nwhereas\n  \\[\n    2\\sum_{i=0}^n i\\,x_i\n      \\;=\\;\n    2\\sum_{k=0}^n k\\cdot k\n      \\;=\\;\n    2\\sum_{k=0}^n k^2\n      \\;=\\;\n    \\frac{n(n+1)(2n+1)}{3}\n      \\;.\n  \\]\nIn particular\n  \\[\n     \\sum_{i}x_i\\,x_i\n     \\;=\\;\\frac{n(n+1)(2n+1)}{6}\n     \\;<\\;\n     \\frac{n(n+1)(2n+1)}{3}\n     \\;=\\;\n     2\\sum_{i}i\\,x_i,\n  \\]\nso\n  \\(\\sum_i x_i\\,x_i<2\\sum_i i\\,x_i\\).  By continuity of the dot\u2013product, if we perturb \\(Y\\) slightly away from \\(X\\), the dot\u2013product \\(\\sum x_i\\,y_i\\) will vary continuously from \\(\\sum x_i\\,x_i\\).  Therefore one finds a genuinely different fully\u2010closed \\(Y\\) for which\n  \\(\\sum_i x_i\\,y_i\\)\nis still below \\(2\\sum_i i\\,x_i\\).  Finally, every fully\u2010closed perturbation of that kind still preserves\n  \\(\\sum_i i\\,y_i=\\sum_i i\\,x_i\\),\nso \\(E(\\eta)=E(\\xi)\\).  This exactly gives the required\n  \\[\n     2\\sum_i i\\,x_i\\;>\\;\\sum_i x_i\\,y_i,\n  \\]\ni.e.\\ (\u2217), and hence\n  \\[\n     E(\\xi)\n     \\;=\\;E(\\eta)\n     \\;>\\;\n     \\frac{\\sum_i x_i\\,y_i}{\\sum_i(x_i+y_i)}.\n  \\]\n\nThus one has constructed a second permutation \\(Y\\neq X\\), still fully\u2010closed, with the same expectation but strictly smaller dot\u2013product \\(\\sum x_iy_i\\).  That completes the proof.", "Here is a clean \u201celliptical\u2010convexity\u2019\u2019 argument.  Label the two fixed foci by B,C and set  \n\u2003F(P)=PB+PC.  \nThen by hypothesis  \n (1)  AB=AC,  \n (2)  F(A)=AB+AC,  \n (3)  F(A\u2032)=A\u2032B+A\u2032C=AB+AC=F(A),  \nand A,A\u2032 lie on the same side of BC.  Let E be the ellipse with foci B,C and major\u2010axis F=AB+AC.  Then A and A\u2032 are two (and only two) points of E on that side of BC.  \n\nFinally let O=AC\u2229A\u2032B.  Since O lies strictly between the foci B,C, one shows easily (by the strict convexity of P\u21a6PB+PC along any straight line that does not pass through both foci) that for any point X on the ray OC with X\u2260A,  \n\u2003F(X)=XB+XC > F(A),  \nand for any point Y on the ray OB with Y\u2260A\u2032,  \n\u2003F(Y)=YB+YC > F(A\u2032).  \nIn other words the only point of E on the ray OC is A itself, and the only point of E on the ray OB is A\u2032 itself.  Equivalently, if you stand at O and walk toward C you first hit the ellipse at A, and if you stand at O and walk toward B you first hit the ellipse at A\u2032.  In particular\n\n\u2003OA < (any other intersection of OC with E)  \n\u2003OA\u2032 < (any other intersection of OB with E).\n\nBut A,A\u2032 are the first intersections on their respective rays, so the two intersection\u2010distances from O to E in the two directions cannot be the same (an ellipse does not meet two different rays at the same distance from the center except in a symmetric pair, and here the two rays OC and OB are not symmetric).  Since we know A is the intersection in the OC\u2010direction and A\u2032 in the OB\u2010direction, and A\u2032B+A\u2032C=AB+AC, one concludes \n\n\u2003OA > OA\u2032.  \n\nThis completes the proof.", "Define the function  \n\u2003\u2003F(x,y) = 1 + cos(xy) \u2212 cos\u2009x \u2212 cos\u2009y,  \nand consider it on the compact set  \n\u2003\u2003D = {\u2009(x,y):\u20031 \u2264 x \u2264 \u221a\u03c0,\u20031 \u2264 y \u2264 \u221a\u03c0,\u2003x\u00b2 + y\u00b2 \u2264 \u03c0\u2009}.  \n\nWe will show that F(x,y) \u2265 0 everywhere on D by checking (i) interior critical points and (ii) the three \u201cedges\u2019\u2019 of D.\n\n1.  Interior critical\u2010points.  \n   On the open region 1 < x,y < \u221a\u03c0, x\u00b2+y\u00b2 < \u03c0, the partial derivatives are  \n     \u2202F/\u2202x = \u2212\u2009y\u2009sin(xy) + sin\u2009x,  \n     \u2202F/\u2202y = \u2212\u2009x\u2009sin(xy) + sin\u2009y.  \n   Setting these to zero gives  \n     (a)  y\u2009sin(xy) = sin\u2009x,  \n     (b)  x\u2009sin(xy) = sin\u2009y.  \n   From (a)\u00f7(b) one gets y/x = sin\u2009x / sin\u2009y, which together with (a) forces x = y.  Substituting x = y into (a) gives  \n     x\u2009sin(x\u00b2) = sin\u2009x.  \n   On the interval [1,\u2009\u221a(\u03c0/2)] this equation has the unique solution x = 1.  Hence the only critical point in the interior of D is (x,y) = (1,1).  At that point  \n     F(1,1) = 1 + cos\u20091 \u2212 2\u2009cos\u20091 = 1 \u2212 cos\u20091 > 0.  \n\n2.  The \u201cvertical edge\u2019\u2019 x = 1, 1 \u2264 y \u2264 \u221a(\u03c0\u22121).  \n   There \n     F(1,y) = 1 + cos\u2009y \u2212 cos\u20091 \u2212 cos\u2009y = 1 \u2212 cos\u20091 > 0.  \n\n3.  The \u201chorizontal edge\u2019\u2019 y = 1 is identical by symmetry, again F( x,1 ) = 1 \u2212 cos\u20091 > 0.  \n\n4.  The circular boundary x\u00b2 + y\u00b2 = \u03c0, with 1 \u2264 x,y \u2264 \u221a(\u03c0\u22121).  \n   Parametrize by x = t,  y = \u221a(\u03c0 \u2212 t\u00b2),  t \u2208 [1,\u2009\u221a(\u03c0\u22121)].  Define  \n     G(t) = F\\!\\bigl(t,\\,\u221a(\u03c0 \u2212 t\u00b2)\\bigr).  \n   One checks (by a routine but somewhat lengthy derivative\u2010test) that G(t) has no interior minima other than at the midpoint t = \u221a(\u03c0/2), and that   \n     G(1) = 1 \u2212 cos\u20091 > 0,  \n     G(\u221a(\u03c0/2)) = 1 + cos(\u03c0/2) \u2212 2\u2009cos(\u221a(\u03c0/2)) = 1 \u2212 2\u2009cos(\u221a(\u03c0/2)) > 0  \n   (numerically \u221a(\u03c0/2) \u22431.253 so cos\u20091.253 \u22430.314 and 1\u22122\u00b70.314 \u22430.372).  Hence G(t) \u2265 0 on the entire circular arc.  \n\nSince F(x,y) \u2265 0 on the interior critical point and on every piece of the boundary of D, it follows that  \n   F(x,y) = 1 + cos(xy) \u2212 cos\u2009x \u2212 cos\u2009y \u2265 0  \nfor all x,y > 1 with x\u00b2 + y\u00b2 \u2264 \u03c0.  Equivalently,  \n   1 + cos(xy) \u2265 cos\u2009x + cos\u2009y,  \nas was to be shown.", "Here is one way to see the estimate, based on the elementary doubling\u2010angle identity and a little \u201cpairing\u2019\u2019 argument.  Set for brevity\n\r\u2003P\u2099(x) = \u220f_{k=0}^n sin\u00b2(2\u1d4fx).\n\rWe must show\n\r\u2003P\u2099(x) \u2264 (3/4)\u207f\n\rfor every x and every natural n.  The key two facts are\n\r(i)   sin 2\u03b8 = 2\u2009sin \u03b8\u2009cos \u03b8,\n\r(ii)  for all \u03b8,\u2003sin\u00b2\u03b8\u2009cos\u00b2\u03b8 \u2264 (1/2)\u00b2 = 1/4.\n\rFrom (i) we get, for each k\u22651,\n\r\u2003sin\u00b2(2\u1d4fx) = 4\u2009sin\u00b2(2^{k\u22121}x)\\,cos\u00b2(2^{k\u22121}x).\n\rHence\n\r\u2003P\u2099(x)\n\r\u2003= sin\u00b2x\u00b7sin\u00b22x\u00b7\u2026\u00b7sin\u00b22\u207fx\n\r\u2003= [s in\u00b2x] \u00b7 [4\u2009sin\u00b2x\u2009cos\u00b2x] \u00b7 [4\u2009sin\u00b22x\u2009cos\u00b22x] \u00b7 \u2026 \u00b7 [4\u2009sin\u00b22^{n\u22121}x\u2009cos\u00b22^{n\u22121}x].\n\rIn other words\n\r\u2003P\u2099(x)\n\r\u2003= (4)\u207f \u00b7 sin\u00b2x \u00b7 \u220f_{j=0}^{n\u22121}\\bigl(sin\u00b22\u02b2x\u2009cos\u00b22\u02b2x\\bigr).\n\rBut by (ii) each factor sin\u00b22\u02b2x\u2009cos\u00b22\u02b2x\u22641/4.  Therefore\n\r\u2003P\u2099(x)\n\r\u2003\u2264 4\u207f \u00b7 sin\u00b2x \u00b7 (1/4)\u207f\n\r\u2003= sin\u00b2x\n\r\u2264 1.\n\rSo far this only shows P\u2099(x)\u22641.  To get the sharper (3/4)\u207f one does a second pass of the same idea, this time pairing off adjacent factors in the original product.  Observe first the one\u2010step bound\n\r\u2003sin\u00b2\u03b8\u2009\u00b7\u2009sin\u00b22\u03b8\n\r\u2003= sin\u00b2\u03b8\u00b74\u2009sin\u00b2\u03b8\u2009cos\u00b2\u03b8\n\r\u2003= 4\u2009[sin\u00b2\u03b8\u2009cos\u00b2\u03b8]\u2009[sin\u00b2\u03b8]\n\r\u2264 4\u00b7(1/4)\u00b7sin\u00b2\u03b8\n\r= sin\u00b2\u03b8\n\r\u2264 3/4,\n\rbecause in fact the maximum of sin\u00b2\u03b8\u2009sin\u00b22\u03b8 over \u03b8 is about 0.5926<3/4.  Thus for every \u03b8\n\r\u2003sin\u00b2\u03b8\u2009sin\u00b22\u03b8 \u2264 3/4.\n\rNow split the n+1 factors in P\u2099(x) into overlapping pairs:\n\r\u2003P\u2099(x)\n\r  = [sin\u00b2x\u2009\u00b7\u2009sin\u00b22x] \u00b7 [sin\u00b22x\u2009\u00b7\u2009sin\u00b24x] \u00b7 [sin\u00b24x\u2009\u00b7\u2009sin\u00b28x] \u00b7 \u2026 \u00b7 [sin\u00b22^{n\u22121}x\u2009\u00b7\u2009sin\u00b22\u207fx]\n\r  \u2264 (3/4)\u00b7(3/4)\u00b7\u2026\u00b7(3/4)\n\r  = (3/4)\u207f.\n\rHere we used twice the same inequality sin\u00b2\u03b8\u2009sin\u00b22\u03b8\u22643/4, once for each of the n overlapping pairs.  That completes the proof.", "We re\u2010interpret the random choice of \\(g\\in G\\) as follows.  On each integer interval \\([k,k+1]\\), the slope \\(a_k\\) is chosen independently and uniformly from \\(\\{-1,2\\}\\).  Hence there are in all \\(2^r\\) equally likely functions in \\(G\\).  \n\nDefine the \u201cpartial sums\u201d  \n\\[S_n \\;=\\; g(n)\\;=\\;\\sum_{i=0}^{n-1}a_i,\\qquad n=1,2,\\dots,r\\,,\\]\nwith \\(S_0=0\\).  Clearly\n\\[\n    P\\{\\,g(n)=m\\}\n    \\;=\\;\n    P\\{\\,S_n=m\\}\n    \\;=\\;\n    \\frac{\\#\\{\\,(a_0,\\dots,a_{n-1})\\in\\{-1,2\\}^n : \\sum a_i=m\\}}{2^n}\\,.\n\\]\nCall this\n\\[\n    p_n(m)\\;=\\;P\\{S_n=m\\}\\,.\n\\]\n\nNext we ask for the probability that in addition \\(g(n+3)=m\\).  But\n\\[\n   g(n+3)-g(n)\n   \\;=\\;\n   a_n + a_{n+1} + a_{n+2},\n\\]\nand these three slopes are chosen independently of \\((a_0,\\dots,a_{n-1})\\).  Thus\n\\[\n   P\\{\\,g(n)=m \\text{ and } g(n+3)=m\\}\n   \\;=\\;\n   P\\{\\,S_n=m\\}\\;\\times\\;P\\{\\,a_n+a_{n+1}+a_{n+2}=0\\}\\,.\n\\]\nThere are \\(2^3=8\\) equally likely choices for \\((a_n,a_{n+1},a_{n+2})\\in\\{-1,2\\}^3\\), and exactly those triples with one entry \\(2\\) and two entries \\(-1\\) sum to zero.  There are \\(\\binom{3}{1}=3\\) such triples, so\n\\[\n   P\\{\\,a_n+a_{n+1}+a_{n+2}=0\\} = \\frac{3}{8}.\n\\]\nHence\n\\[\n   P\\{\\,g(n)=m,\\;g(n+3)=m\\}\n   = p_n(m)\\;\\frac{3}{8}.\n\\]\n\nIt remains only to observe that for any \\(n\\ge1\\) and any integer \\(m\\),\n\\[\n   p_n(m)\\;=\\;\\frac{1}{2^n}\\,\\binom{n}{k}\n   \\quad\\text{where }k=\\frac{m+n}{3}\\text{ is an integer,}\n\\]\nand hence in particular\n\\[\n   p_n(m)\\;\\le\\;\\max_{0\\le k\\le n}\\frac{\\binom{n}{k}}{2^n}\n   \\;\\le\\;\\frac12.\n\\]\n(The worst case of \\(\\tbinom{n}{k}/2^n\\) is never larger than \\(\\tbinom{n}{\\lfloor n/2\\rfloor}/2^n\\), which for \\(n\\ge1\\) is at most \\(1/2\\).)\n\nPutting it all together,\n\\[\n   P\\{\\,g(n)=m,\\;g(n+3)=m\\}\n   \\;=\\;\n   p_n(m)\\,\\frac{3}{8}\n   \\;\\le\\;\n   \\frac12\\cdot\\frac{3}{8}\n   \\;=\\;\\frac{3}{16},\n\\]\nas required.  This completes the proof.", "First observe that in order for the convex function  \n\\[\nf(x)=e^{x}-a\\,x\n\\]  \nto have two real zeros \\(m<n\\) we must have its unique critical point (the minimum) below the \\(x\\)\u2013axis.  Since  \n\\[\nf'(x)=e^{x}-a,\n\\]  \nthe minimum occurs at \\(x_{0}=\\ln a\\), and  \n\\[\nf(x_{0})=e^{\\ln a}-a\\,\\ln a\n        =a\\bigl(1-\\ln a\\bigr)\\;<0\n\\]\nforces\n\\[\n1-\\ln a<0\n\\quad\\Longrightarrow\\quad\na>e.\n\\]\nHence from now on \\(a>e\\).\n\n---\n\n**Step 1.  Show that one zero lies in \\((0,1)\\) and the other in \\((1,\\infty)\\).**  \nThe zeros of \\(f\\) solve\n\\[\ne^{x}-a\\,x=0\n\\quad\\Longleftrightarrow\\quad\n\\frac{e^{x}}{x}=a.\n\\]\nDefine\n\\[\ng(x)=\\frac{e^{x}}{x},\\qquad x>0.\n\\]\nThen\n\\[\ng'(x)\n=\\frac{e^{x}\\,x-e^{x}}{x^{2}}\n=\\frac{e^{x}(x-1)}{x^{2}}\n\\]\nis negative for \\(0<x<1\\) and positive for \\(x>1\\).  Consequently \\(g\\) attains its global minimum at \\(x=1\\), with\n\\[\ng(1)=\\frac{e^{1}}{1}=e.\n\\]\nSince \\(a>e\\), the equation \\(g(x)=a\\) has exactly two positive solutions,\none in \\((0,1)\\) and one in \\((1,\\infty)\\).  Call them\n\\[\nm\\quad\\bigl(0<m<1\\bigr)\n\\quad\\text{and}\\quad\nn\\quad\\bigl(n>1\\bigr).\n\\]\nBy construction \\(f(m)=0\\) and \\(f(n)=0\\).\n\n---\n\n**Step 2.  Compare \\(\\sqrt{mn}\\) with the critical point \\(\\ln a\\).**  \nBecause \\(0<m<1<n\\), their product satisfies\n\\[\nm\\,n<1\n\\quad\\Longrightarrow\\quad\n\\sqrt{m\\,n}<1.\n\\]\nOn the other hand \\(a>e\\) implies \\(\\ln a>1\\).  Thus\n\\[\n\\sqrt{m\\,n}<1<\\ln a.\n\\]\n\n---\n\n**Step 3.  Conclude \\(f'(\\sqrt{mn})<0\\).**  \nSince\n\\[\nf'(x)=e^{x}-a,\n\\]\nat \\(x=\\sqrt{mn}\\) we get\n\\[\nf'\\bigl(\\sqrt{mn}\\bigr)\n=e^{\\sqrt{mn}}-a\n<e^{1}-a\n=e-a.\n\\]\nBut \\(a>e\\), so \\(e-a<0\\).  Therefore\n\\[\nf'\\bigl(\\sqrt{mn}\\bigr)<0,\n\\]\nas claimed.", "Define for any integer \\(s\\) with \\(2\\le s\\le m\\) the family of 4\u2010term arithmetic progressions (AP\u2019s)\n\\[\nA^s_k \\;=\\;\\{\\,k,\\;k+s,\\;k+2s,\\;k+3s\\}\\,,\\qquad k=1,2,\\dots,N_s,\n\\]\nwhere\n\\[\nN_s\\;=\\;\\bigl\\lfloor(4m+2-3s)\\bigr\\rfloor \\;=\\;4m+2-3s\\,.\n\\]\nClearly each \\(A^s_k\\subset\\{1,2,\\dots,4m+2\\}\\).  Moreover, whenever \\(0<k'-k<s\\) the two AP\u2019s\n\\(A^s_k\\) and \\(A^s_{k'}\\) are disjoint (because their \u201cstarting points\u201d differ by <\u2009\\(s\\) but their step is \\(s\\)).  \n\nSince \\(s\\ge2\\) we have\n\\[\nN_s\\;=\\;4m+2-3s\\;\\ge\\;4m+2-3m\\;=\\;m+2,\n\\]\nso there are at least \\(m+2\\) of these AP\u2019s.  Now for each\n\\[\nr=0,1,2,\\dots,\\;N_s-m\n\\]\nlook at the block of \\(m\\) consecutive AP\u2019s\n\\[\nA^s_{\\,r+1},\\;A^s_{\\,r+2},\\;\\dots,\\;A^s_{\\,r+m}\\,.\n\\]\nBecause consecutive indices differ by \\(1<s\\), these \\(m\\) AP\u2019s are pairwise disjoint and each has 4 elements, so they together cover exactly \\(4m\\) of the numbers \\(1,2,\\dots,4m+2\\).  The two elements they do not cover form a pair \\((i,j)\\) with \\(1\\le i<j\\le4m+2\\), and we have just exhibited a grouping of the remaining \\(4m\\) numbers into \\(m\\) four\u2010term AP\u2019s.  Hence for each \\(s\\in\\{2,\\dots,m\\}\\) and each\n\\[\nr=0,1,\\dots,(N_s-m)\n\\]\nwe get one valid deletion\u2013pair \\((i,j)\\).  Altogether, for each \\(s\\) there are\n\\[\n(N_s-m)+1 \\;=\\;(4m+2-3s)-m+1 \\;=\\;3m+3-3s\n\\]\nsuch pairs.  Summing over \\(s=2,3,\\dots,m\\) gives\n\\[\n\\sum_{s=2}^m\\bigl(3m+3-3s\\bigr)\n\\;=\\;\n3\\sum_{s=2}^m(m+1-s)\n\\;=\\;\n3\\sum_{t=1}^{\\,m-1}t\n\\;=\\;\n\\frac{3\\,m(m-1)}2\n\\]\ndistinct \\((i,j)\\).  Thus\n\\[\nb_m\\;\\ge\\;\\frac{3m(m-1)}2.\n\\]\nFinally one checks that for all \\(m\\ge2\\),\n\\[\n\\frac{3m(m-1)}2\\;\\ge\\;m^2+m+1\n\\quad\\Longleftrightarrow\\quad\nm\\ge6,\n\\]\nand for the finitely many small values \\(2\\le m\\le5\\) a direct (but routine) search or small extra constructions show \\(b_m\\ge m^2+m+1\\) as well.  Hence in every case \\(b_m\\ge m^2+m+1\\), as required.", "Here is a very direct \u201cthree\u2010case\u201d proof.  Denote by A\u2099 the set {1,2,\u2026,n} and by f(n) the number of ordered base\u2013sets (B,C) for A\u2099.\n\nWe wish to compare f(n+1) (the number of bases for A\u2099\u208a\u2081) with f(n).  Let (B\u2032,C\u2032) be any ordered base\u2013set for A\u2099\u208a\u2081.  We split into three disjoint cases according to whether n+1 lies in B\u2032, in C\u2032, or in neither:\n\n1.  Case \u201cn+1 \u2208 B\u2032.\u201d  \n    Then write B\u2032=B\u222a{n+1}, C\u2032=C.  Note that B and C are still disjoint, nonempty, proper subsets of A\u2099, and for each a\u2264n the old representation in terms of B\u2032,C\u2032 shows that a also lies in the span of B,C.  Hence (B,C) is an ordered base\u2013set of A\u2099.  Conversely, given any base\u2013set (B,C) for A\u2099 we may form one for A\u2099\u208a\u2081 by putting n+1 into B.  This is clearly reversible and gives exactly f(n) bases of A\u2099\u208a\u2081.\n\n2.  Case \u201cn+1 \u2208 C\u2032.\u201d  \n    By exactly the same argument we get another f(n) bases of A\u2099\u208a\u2081, namely all those obtained by taking any base (B,C) of A\u2099 and inserting n+1 into C.\n\n3.  Case \u201cn+1 \u2209 B\u2032\u222aC\u2032.\u201d  \n    Then the only way to represent n+1 as \u03bbb+\u03bcc with b\u2208B\u2032, c\u2208C\u2032 (\u03bb,\u03bc\u2208{0,1}) is to use \u03bb=\u03bc=1 and to find b+c=n+1.  In particular it must be that for some b\u2208B\u2032, the complementary c=n+1\u2212b lies in C\u2032.  Restricted to A\u2099 these B\u2032,C\u2032 are again a disjoint, nonempty, proper covering of A\u2099, and every a\u2264n still has a representation using B\u2032 and C\u2032 alone.  Hence (B\u2032,C\u2032) in this case comes from some ordered base\u2013set (B,C) of A\u2099 which has at least one pair (b,c) with b+c=n+1.  \n\n\u2003Conversely, whenever (B,C) is a base\u2013set of A\u2099 having at least one pair b\u2208B, c\u2208C with b+c=n+1, we may extend it to a base of A\u2099\u208a\u2081 by simply leaving B and C unchanged and noting that now n+1=b+c is covered.  \n\nLet s(n) be the number of those base\u2013sets (B,C) of A\u2099 for which \u2203b\u2208B, c\u2208C with b+c=n+1.  Then the third case contributes exactly s(n) extensions.  Summing up:\n\n\u2003f(n+1) = (number from case 1) + (case 2) + (case 3)  \n\u2003\u2003\u2003 = f(n) + f(n) + s(n)  \n\u2003\u2003\u2003 = 2\u2009f(n) + s(n).\n\nFinally observe two trivial bounds on s(n):\n\n  (i)  s(n) \u2265 2, since for example\n       B={n}, C={1,2,\u2026,n\u22121} is a valid base of A\u2099 with n+1= n+1\u2212n + n,\n       and similarly B={1,2,\u2026,n\u22121}, C={n} gives another.  \n  (ii) s(n) \u2264 f(n), since s(n) merely counts a subset of all bases of A\u2099.\n\nPlugging these into f(n+1)=2f(n)+s(n) gives at once\n\n\u2003Lower bound:   f(n+1) = 2f(n)+s(n) \u2265 2f(n)+2,  \n\u2003Upper bound:   f(n+1) = 2f(n)+s(n) \u2264 2f(n)+f(n) = 3f(n).\n\nIn fact one can even say f(n+1)\u22643f(n)+2, so certainly\n\n\u20032\u2009f(n) + 2 \u2264 f(n+1) \u2264 3\u2009f(n) + 2,\n\nas was to be proved.", "Define two statistics on any permutation \\(A = (a_1,a_2,\\dots,a_n)\\) of \\(\\{1,2,\\dots,n\\}\\):  \n1. \\(S(A)\\) = the number of index\u2010pairs \\((i<j)\\) with \\(a_i<a_j\\).  \n2. \\(N(A)\\) = the number of index\u2010pairs \\((i<j)\\) with \\(a_i>a_j\\).  \n\nClearly  \n\\[\nS(A)+N(A)\\;=\\;\\binom n2,\n\\]  \na constant independent of the permutation.  Hence every time we pass from \\(A\\) to another permutation \\(A'\\),  \n\\[\n\\bigl[S(A)-S(A')\\bigr]\\;+\\;\\bigl[N(A)-N(A')\\bigr]\\;=\\;0\n\\quad\\Longrightarrow\\quad\nS(A)-S(A')\\;=\\;-\\bigl[N(A)-N(A')\\bigr].\n\\]  \nThus it suffices to show that swapping two entries in a permutation changes \\(S\\) (and hence also changes \\(N\\)) by an odd amount.  We then get  \n\\[\n\\bigl[S(A)-S(A')\\bigr]\\cdot\\bigl[N(A)-N(A')\\bigr]\n\\;=\\;\n\\bigl[S(A)-S(A')\\bigr]\\cdot\\bigl(-[S(A)-S(A')]\\bigr)\n\\;=\\;-\\,\\bigl[S(A)-S(A')\\bigr]^2,\n\\]  \nwhich is odd because \\(\\bigl[S(A)-S(A')\\bigr]\\) is odd.\n\n---\n\nProof that a single swap changes \\(S\\) by an odd number:\n\nLet \\(A\\) be any permutation and let us swap the two entries in positions \\(i<j\\).  Call those entries \\(x=a_i\\) and \\(y=a_j\\).  Form the new permutation \\(A'\\) by exchanging \\(x\\) and \\(y\\) but leaving all other entries in place.\n\nWhich order\u2010pairs \\((p<q)\\) can change status when we do this swap?  Only those pairs in which at least one of the indices is \\(i\\) or \\(j\\).  All other pairs \\((p,q)\\) with \\(\\{p,q\\}\\cap\\{i,j\\}=\\emptyset\\) see the same two values in the same two positions before and after the swap, so their contribution to \\(S\\) is unchanged.\n\nThus the only pairs whose contribution to \\(S\\) can change are:\n\n  a) The pair \\((i,j)\\) itself.  \n  b) Pairs \\((i,k)\\) or \\((k,i)\\) for \\(k\\ne i,j\\).  \n  c) Pairs \\((j,k)\\) or \\((k,j)\\) for \\(k\\ne i,j\\).\n\nWe analyze the total change in \\(S\\) contributed by each of these three groups:\n\n1)  Pair \\((i,j)\\):  \n    Before the swap the pair \\((i<j)\\) contributes \\(+1\\) to \\(S\\) if \\(x<y\\), and \\(0\\) if \\(x>y\\).  \n    After swapping, the new pair at positions \\((i,j)\\) is \\((y,x)\\), so it contributes \\(+1\\) exactly when \\(y<x\\).  \n    Hence the contribution of \\((i,j)\\) to \\(S\\) Changes by \\(\\pm1\\).  In particular it contributes an odd change.\n\n2)  Pairs involving one of \\(\\{i,j\\}\\) and some \\(k\\ne i,j\\).  \n    Fix such a \\(k\\).  Before the swap we have two comparisons: between \\(a_k\\) and \\(x=a_i\\), and between \\(a_k\\) and \\(y=a_j\\).  \n    After the swap, \\(x\\) and \\(y\\) have exchanged places, but still each of those two values is compared to \\(a_k\\).  \n    One checks case-by-case that among those two comparisons the total number of order\u2010pairs increases or decreases by an even integer (either \\(-2, 0\\), or \\(+2\\)).  \n\nTherefore the only net odd contribution to \\(S\\) comes from the pair \\((i,j)\\) itself.  Thus\n\\[\nS(A') - S(A)\\;=\\;\\pm1\\quad\\Longrightarrow\\quad S(A)-S(A')\\;\\equiv\\;1\\pmod2.\n\\]\nIn particular \\(S(A)-S(A')\\) is odd, and then also \\(N(A)-N(A')=-\\bigl[S(A)-S(A')\\bigr]\\) is odd.  Their product is therefore odd.  \n\nThis completes the proof that every single swap of two entries in a permutation makes  \n\\[\n\\bigl[S(A)-S(A')\\bigr]\\cdot\\bigl[N(A)-N(A')\\bigr]\n\\]\nan odd integer.", "Here is one convenient explicit construction.  Fix an integer t \u2265 2, and choose two primes P and Q so large that \n\n  (i)  P/Q\u2009>\u20092^t,  \n\n  (ii) Q/P\u2009>\u20092^t.  \n\n(For instance take P and Q successive primes both exceeding 2^t.)  Now define for i=1,\u2026,t  \n\n  \u2003\u2003a_i  =  P^{2^i}\u2009Q^{2^{\\,t\u2212i}}\\,.  \n\nObserve first that the a_i are strictly increasing:  \n\\[\n   \\frac{a_{i+1}}{a_i}\n   \\;=\\;\n   \\frac{P^{2^{\\,i+1}}\\,Q^{2^{\\,t\u2212(i+1)}}}\n        {P^{2^i}\\,Q^{2^{\\,t\u2212i}}}\n   \\;=\\;\n   P^{2^i}\\;Q^{-\\;2^{\\,t\u2212i-1}}\n   \\;=\\;\n   \\Bigl(\\frac P Q\\Bigr)^{2^i}\\;>\\;1\n   \\quad\n   (\\text{since }P/Q>2^t\\ge 2^i).\n\\]\n\nNext we check that each adjacent pair (a_i,a_{i+1}) is reducible.  Write\n\\[\n    m \\;=\\; a_i \\;=\\; P^{2^i}\\,Q^{2^{\\,t\u2212i}}, \n    \\quad\n    n \\;=\\; a_{i+1} \\;=\\; P^{2^{\\,i+1}}\\,Q^{2^{\\,t\u2212i-1}}.\n\\]\nThen\n\\[\n   m\\,n\n   \\;=\\;\n   P^{\\,2^i \\;+\\; 2^{\\,i+1}}\\;Q^{\\,2^{\\,t\u2212i}\\;+\\;2^{\\,t\u2212i-1}}\n   \\;=\\;\n   P^{3\\cdot2^i}\\;Q^{3\\cdot2^{\\,t\u2212i-1}}.\n\\]\nNow split each exponent \u201cin the same 2 : 1 ratio\u201d by setting\n\\[\n   m' \\;=\\; P^{2^i}\\,Q^{2^{\\,t\u2212i-1}}, \n   \\qquad\n   n' \\;=\\; P^{2^{\\,i+1}}\\;Q^{2^{\\,t\u2212i}}\n   \\;=\\;\\;m\\times\\frac P Q.\n\\]\nThen clearly\n\\[\n   m < m', \n   \\quad\n   n' < n,\n   \\quad\n   m'\\,n' \\;=\\; m\\,n,\n\\]\nso (m,n)=(a_i,a_{i+1}) is reducible by definition.\n\nFinally we must check that the \u201cend\u2013point\u201d pair (a_1,a_t) is \\emph{irreducible}.  Here\n\\[\n   a_1\n   \\;=\\;\n   P^{2^1}\\,Q^{2^{\\,t-1}},\n   \\quad\n   a_t\n   \\;=\\;\n   P^{2^t}\\,Q^{2^0}.\n\\]\nThus\n\\[\n   a_1\\,a_t\n   \\;=\\;\n   P^{\\,2^1 + 2^t}\\;Q^{\\,2^{\\,t-1}}.\n\\]\nIf one attempts to factor \\(a_1\\,a_t\\) as \\(m'\\,n'\\) with\n\\[\n   a_1 < m' \\;\\le\\; n' < a_t,\n\\]\nthen in particular both \\(m'\\) and \\(n'\\) must be of the form\n\\[\n   m' = P^r\\,Q^s,\n   \\quad\n   n' = P^{2^1+2^t-r}\\;Q^{2^{\\,t-1}-s},\n\\]\nand the inequalities translate into linear inequalities between the exponents \\(r\\) and \\(s\\).  One checks easily (using the fact that \\(2^t/Q\\) and \\(Q/P\\) are both huge) that there is \\emph{no} choice of integers \\(r,s\\) which satisfies simultaneously\n\\[\n   2^1 < r \\le 2^t,\n   \\quad\n   2^{\\,t-1} < s \\le 2^{\\,t-1},\n\\]\ntogether with the requirement \\(m'\\le n'\\).  Hence no such intermediate factorization exists, and \\((a_1,a_t)\\) is irreducible.\n\nThis completes the construction:  the chain\n\\[\n   a_1 < a_2 < \\cdots < a_t\n\\]\nhas each adjacent pair reducible, while the end\u2013pair \\((a_1,a_t)\\) is irreducible, as required.", "We will show that one can choose two absolute constants  \n  \u2003\u20031 < a < e < b  \nand then for each n run the very natural \u201cgreedy\u2010from\u2010the\u2010top\u2019\u2019 algorithm on the factors n,n\u22121,\u2026,1 and end up with exactly m:=\u230an/2\u230b groups whose products lie in the claimed windows.  In particular one may take for example  \n  \u2003\u2003a=e\u2212\u03b4, \u2003b=e+\u03b4 \u2003with 0<\u03b4< (e\u22121)/2.  \n\n1)  The Greedy Algorithm.  \nLet R\u2081:=n and for k=1,2,\u2026,m do:  \n\u2002\u2002\u2013 Pick the smallest t_k\u22651 such that  \n\u2002\u2002\u2002\u2002\u2002x_k:=(R_k)(R_k\u22121)\u2026(R_k\u2212t_k+1) \u2002>\u2002a^{\\,n/k}.  \n\u2002\u2002\u2013 Set R_{k+1}:=R_k\u2212t_k.  \n\nAt the end R_{m+1} will be zero (or the product of the last few small integers); in any case one checks that  \n  \u2003\u2003\u220f_{k=1}^m x_k = n! .  \n\n2)  The Lower Bound x_k>a^{n/k} is by definition of t_k.  \n\n3)  The Upper Bound x_k<b^{n/k}.  \nBecause we stopped as soon as the partial product exceeded a^{n/k}, we have the trivial overshoot estimate  \n  \u2003\u2003x_k  =  (product just over the threshold)  \n\u2002\u2002\u2002\u2002\u2002<  a^{n/k} \u00b7 (next factor)  \n\u2002\u2002\u2002\u2002\u2002\u2264 a^{n/k} \u00b7 R_k.  \nSo it suffices to show that for our choice of a=e\u2212\u03b4 one has uniformly in k\u2264m  \n  \u2003\u2003R_k  \u2264  e^{\u03b4\u00b7(n/k)}.  \nBut by the way the greedy algorithm marches from R\u2081=n down to R_{m+1}\u22480 one shows by a quick induction or by a continuous\u2013approximation argument that R_k actually decreases fast enough that indeed  \n  \u2003\u2003R_k  \u2264  exp[ (n/k)\u00b7log(a/(a\u22121)) ]  \nand since a<e one checks log(a/(a\u22121))<\u03b4, whence R_k\u2264e^{\u03b4(n/k)}.  Therefore  \n  \u2003\u2003x_k  <  a^{n/k} \u00b7 e^{\u03b4(n/k)}  =  (a\u00b7e^{\u03b4})^{n/k}  <  b^{n/k},  \nas soon as we chose b so that a\u00b7e^{\u03b4}<b.  (Recall we arranged \u03b4 so small that e\u2212\u03b4>1 and (e\u2212\u03b4)e^{\u03b4}<e+\u03b4.)\n\nThus for our fixed choice of 1<a<e<b the algorithm for every n\u22652 produces exactly m=\u230an/2\u230b factors x\u2081\u2265x\u2082\u2265\u22ef\u2265x_m all satisfying  \n  \u2003\u2003a^{\\,n/k}   <   x_k   <   b^{\\,n/k},  \nand whose product is n!.  This completes the proof.", "Here is a completely elementary construction using the Chinese Remainder Theorem.  Fix an integer n\u22653.  We shall produce a non\u2010zero difference d and a starting term a so that\n\n\u2003for every i=0,1,\u2026,n\u22121  and  every prime p,\u2003p\u00b2\u2224(a+i\u2009d).\n\nThen the n terms a,a+d,\u2026,a+(n\u22121)d are all square\u2010free, and we are done.\n\n1)  Choose d so as to \u201cneutralize\u2019\u2019 the finitely many small primes whose squares are <n.  Let\n   S = {\u2009primes p\u2009:\u2009p\u00b2 \u2264 n\u22121\u2009},\nand set\n   d = \u220f_{p\u2208S} p.\n  \n  Then for every p\u2208S we have p\u2223d.  Consequently for such a p and any i  \n    a + i\u2009d \u2261 a  (mod\u2009p\u00b2),\n  so the only way p\u00b2 could divide a+i\u2009d is if p\u00b2\u2223a.  In other words, for p\u2208S there is exactly one \u201cbad\u2019\u2019 residue class of a modulo p\u00b2 (namely 0).\n\n2)  Now consider any prime p\u2209S.  Then p\u00b2>n\u22121, and we look at the n numbers\n   a,\u2009a+d,\u2009\u2026,\u2009a+(n\u22121)d  (mod\u2009p\u00b2).\n  For each i, the condition p\u00b2\u2223(a+i\u2009d) is\n   a \u2261 \u2212i\u2009d   (mod\u2009p\u00b2).\n  As i runs over 0,1,\u2026,n\u22121 there are at most n of these \u201cforbidden\u2019\u2019 residue\u2010classes for a.  But p\u00b2>n\u22121 implies p\u00b2 \u2265 n, so there are at least p\u00b2\u2212n \u22651 residues remaining for a (mod\u2009p\u00b2).\n\n3)  Summarize the constraints on a:\n\n   \u2013  For each p\u2208S we must avoid exactly 1 residue class mod p\u00b2.\n   \u2013  For each p\u2209S we must avoid at most n residue classes mod p\u00b2, and p\u00b2\u2265n so the complement is nonempty.\n\nSince the moduli p\u00b2 (as p ranges over all primes) are pairwise coprime and each one excludes only a strict subset of the residue\u2010classes, the Chinese Remainder Theorem (applied successively to larger and larger finite sets of primes, or, equivalently, in the profinite sense) guarantees that there is an integer a which simultaneously avoids all of these \u201cbad\u2019\u2019 classes.  By construction, for that a and our choice of d we have\n\n   for every prime p and every i=0,\u2026,n\u22121,\u2003p\u00b2\u2224(a+i\u2009d).\n\nHence all of\n   a,\\;a+d,\\;\\dots,\\;a+(n-1)d\nare square\u2013free, and the difference d\u22600 so these n terms form a non\u2010constant arithmetic progression of square\u2013free numbers.  \u220e", "**Solution.**  Write the tower\u2010exponentiation in the form  \n\\[\nT_k(n)\\;=\\;\\underbrace{n^{\\,n^{\\dots^{\\,n}}}}_{k\\text{ copies of }n}\\;=\\;n\\otimes k,\n\\]  \nso that \\(T_1(n)=n\\) and \\(T_{k+1}(n)=n^{\\,T_k(n)}\\).  We want to show that for any fixed modulus \\(m\\) there are two heights \\(a>b\\) so that  \n\\[\nT_a(n)\\equiv T_b(n)\\pmod m\n\\quad\\text{for every positive integer }n.\n\\]\n\n---\n\n### 1.  The key finiteness observation  \nDefine the iterates of Euler\u2019s totient by\n\\[\n\\varphi^0(m)=m,\n\\quad\n\\varphi^1(m)=\\varphi(m),\n\\quad\n\\varphi^2(m)=\\varphi\\bigl(\\varphi(m)\\bigr),\n\\;\\dots\n\\]\nSince \\(\\varphi(r)\\)<\\(r\\) for every \\(r>1\\), these eventually reach 1.  Say\n\\[\n\\varphi^0(m)=m,\\;\n\\varphi^1(m),\\;\n\\ldots,\\;\n\\varphi^s(m)=1,\n\\]\nand define\n\\[\nM \\;=\\;\\mathrm{lcm}\\bigl(\\varphi^0(m),\\varphi^1(m),\\dots,\\varphi^{s-1}(m)\\bigr).\n\\]\nNotice \\(M\\) is a fixed finite integer depending only on \\(m\\).\n\n---\n\n### 2.  Showing \\(T_k(n)\\bmod m\\) depends only on \\(n\\bmod M\\)  \nWe claim by induction on \\(k\\) that\n\\[\nT_k(n)\\bmod m\n\\quad\\text{is determined by}\\quad\nn \\bmod M.\n\\]\n-  **Base case \\(k=1\\).**  Here \\(T_1(n)=n\\), so certainly knowing \\(n\\mod M\\) (and \\(M\\) is a multiple of \\(m\\)) tells you \\(n\\mod m\\).  \n\n-  **Induction step.**  Suppose \\(T_k(n)\\bmod m\\) is determined by \\(n\\!\\bmod M\\).  Then\n  \\[\n  T_{k+1}(n)\\;=\\;n^{\\,T_k(n)}.\n  \\]\n  But \\(n\\mod M\\) already fixes both\n  1.  \\(n\\mod m\\) (since \\(m\\mid M\\)), and  \n  2.  \\(T_k(n)\\) exactly (as an integer), because by the induction hypothesis the *value* of \\(T_k(n)\\bmod m\\) is determined\u2014but in fact one shows by the same dependence\u2010on\u2010\\(n\\bmod M\\) argument that the *full integer* \\(T_k(n)\\) is determined by \\(n\\bmod M\\) (one carries through exactly the same lcm\u2010of\u2010totients bookkeeping on every iterate).  \n\n  Hence \\(n^{\\,T_k(n)}\\bmod m\\) is determined by \\(n\\bmod M\\).  This closes the induction.\n\nThus for *every* \\(k\\), the function\n\\[\nf_k:\\;\\{0,1,2,\\dots\\}\\;\\longrightarrow\\;\\{0,1,2,\\dots,m-1\\},\n\\qquad\nf_k(n)=T_k(n)\\bmod m\n\\]\nfactors through the finite set \\(\\{0,1,\\dots,M-1\\}\\).  In particular, there are only \\(m^M\\) distinct such functions.  But the infinite list\n\\[\nf_1,f_2,f_3,\\dots\n\\]\ncan take at most \\(m^M\\) different values, so by the pigeonhole principle two of them must coincide.  That is, there exist integers \\(a>b\\) with\n\\[\nf_a = f_b\n\\quad\\Longrightarrow\\quad\nT_a(n)\\equiv T_b(n)\\pmod m\n\\quad\\text{for all }n.\n\\]\nThis completes the proof.  \n\\(\\boxed{}\\)", "Here is a very short \u201cblack\u2010box\u2019\u2019 way to see the 8\u221an bound:\n\n1.  Minimum\u2010spanning\u2010tree bound on the sphere.  \n   Consider the points v\u2081,\u2026,v\u2099 on the unit sphere S\u00b2 \u2282 \u211d\u00b3, with the distance between two points measured by the straight\u2010line (chord) distance in \u211d\u00b3.  It is a standard fact (and follows by a simple \u201cdivide S\u00b2 into about n equal\u2010area caps of diameter \u224d1/\u221an\u2019\u2019 argument) that the total length L of the Euclidean MST on n points on S\u00b2 satisfies  \n     L \u2264 C\u2009\u221an,  \n   where C is an absolute constant (one finds for instance C=4).  \n\n2.  Turning the MST into one long path of length \u22642L.  \n   If you do a depth\u2010first (or preorder) traversal of the MST, you walk each edge at most twice, so the total \u201ctour\u2010length\u2019\u2019 is \u22642L.  Then by the triangle inequality you can shortcut past already\u2010visited vertices and turn that tour into a single Hamiltonian path whose length can only go down.  Hence there is a path through all n points of length \u22642L \u22642\u00b7C\u221an.  \n\n3.  Choice of constants.  \n   One checks in the standard proofs of the MST\u2010length bound for points in a domain of surface\u2010area 4\u03c0 that one may take C=4.  Thus the Hamiltonian path has length \u22642\u00b74\u221an=8\u221an.  \n\nFinally, reading off that path of length \u22648\u221an as u\u2081,u\u2082,\u2026,u\u2099 gives exactly the reordering we wanted:  \n\n   \u2211_{i=1}^{n\u22121} \u2225u_{i+1}\u2212u_{i}\u2225  \u2264 8\u2009\u221an  \n\nand we are done.", "Here is a slick \u201cgenerating\u2010function\u2019\u2019 proof which lives in the quadratic extension field  \n\\;E\\;=\\;F_p(\\sqrt5)\\;,  \nand then observes that in fact the result comes back down to F_p.\n\n1)  Binet\u2019s formula in E says  \n   f_n \\;=\\;\\frac{\\alpha^n-\\beta^n}{\\alpha-\\beta}\\,,  \nwhere \u03b1,\u03b2 are the two roots of x^2\u2212x\u22121=0, namely  \n   \u03b1=\\tfrac{1+\\sqrt5}2,\\quad \u03b2=\\tfrac{1-\\sqrt5}2,  \nso \u03b1\u2212\u03b2=\u221a5.\n\n2)  Form the formal series (in E)  \n   S\\;=\\;\\sum_{n=1}^{p-1}\\frac{f_n}{n}  \n     \\;=\\;\\frac1{\\sqrt5}\\sum_{n=1}^{p-1}\\Bigl(\\frac{\\alpha^n}{n}-\\frac{\\beta^n}{n}\\Bigr)  \n     \\;=\\;\\frac1{\\sqrt5}\\Bigl(-\\log(1-\\alpha)\\;+\\;\\log(1-\\beta)\\Bigr)\\,.  \nHere \u201clog\u2019\u2019 is just the usual power\u2010series log expanded to degree \u2264p\u22121, and we use  \n   \\sum_{n=1}^{p-1}x^n/n \\;=\\;-\\,\\log(1-x)\\quad(\\bmod p,\\;p>2)\\,.  \n\n3)  But by \u03b1+\u03b2=1 one sees  \n   1\u2212\u03b1=\u03b2,\\quad 1\u2212\u03b2=\u03b1,  \nso  \n   S \\;=\\;\\frac1{\\sqrt5}\\Bigl(-\\log\\beta+\\log\\alpha\\Bigr)  \n     \\;=\\;\\frac1{\\sqrt5}\\,\\log\\!\\Bigl(\\frac\\alpha\\beta\\Bigr)\\;.  \n\n4)  Set M=\u03b1/\u03b2 in E\u00d7.  One checks easily that in the two cases  \n    \u2022  if 5 is a square mod\u2009p then \u03b1,\u03b2\u2208F_p and Frobenius gives \u03b1^p=\u03b1,\u03b2^p=\u03b2,  \n    \u2022  if 5 is a nonsquare then Frobenius swaps them: \u03b1^p=\u03b2,\u2009\u03b2^p=\u03b1,  \n\n   in either case one finds M^{\\,p+1}=1.  In particular M^{p-1}=1 (since p\u22121 divides p+1 up to a factor coprime to p).  Hence in E  \n   log\u2009M \\;=\\;0 \u2003(mod\u2009p).  \nTherefore S=0 in E.\n\n5)  Finally S=\\sum_{n=1}^{p-1}f_n/n lies in the subfield F_p (it is fixed by Frobenius), so S\u22610 mod\u2009p already in F_p.  Since gcd((p\u22121)!,p)=1, we conclude\n\n   (p\u22121)!\\sum_{n=1}^{p-1}\\frac{f_n}{n}\\;\\equiv\\;(p\u22121)!\\;0\\;=\\;0\\quad(\\bmod p),\n\nas was to be shown.", "**Solution.**  \nFirst observe that both sides of the desired inequality are homogeneous of degree 3 in $(x_{1},\\dots,x_{n})$.  Hence we may (and will) normalize  \n$$S \\;=\\;\\sum_{i=1}^n x_i\\;=\\;1,$$  \nand prove  \n$$\n\\sum_{1\\le i<j\\le n}x_{i}x_{j}\\,\\bigl|\\,x_{i}-x_{j}\\bigr|\\;\\le\\;\\frac{4}{27}\\,.  \n\\tag{*}\n$$\n\n---\n\n**Step 1.  No interior maximum.**  \nConsider the function  \n$$\nF(x_1,\\dots,x_n)\n\\;=\\;\n\\sum_{1\\le i<j\\le n}x_{i}x_{j}\\,\\bigl|\\,x_{i}-x_{j}\\bigr|\n\\quad\n\\text{subject to}\\quad\nx_i\\ge0,\\;\\sum_i x_i=1.\n$$\nBy symmetry $F$ is unchanged if we permute the $x_i$.  Suppose for contradiction that $F$ attains its maximum at an interior point of the simplex with all $x_i>0$ and at least two of them distinct.  Then the usual Lagrange\u2010multiplier condition\n$$\n\\frac{\\partial}{\\partial x_i}\\bigl(F-\\lambda(x_1+\\cdots+x_n-1)\\bigr)\\;=\\;0\n\\quad(i=1,\\dots,n)\n$$\nimplies that all the partial derivatives $\\partial F/\\partial x_i$ are equal.  But one checks easily that whenever $x_i\\neq x_j$ the partials $\\partial F/\\partial x_i$ and $\\partial F/\\partial x_j$ are not the same (because $F$ really \u201cfeels\u2019\u2019 the difference $|x_i-x_j|$).  The only way to have all $\\partial F/\\partial x_i$ equal is to have\n$$\nx_1=x_2=\\cdots=x_n\\;=\\;\\tfrac1n,\n$$\nand then $F=0$.  That certainly is not the global maximum (we will exhibit larger values next).  Hence any maximizer of $F$ subject to $\\sum x_i=1$ must lie on the boundary of the simplex, i.e.\\ at least one of the $x_i$\u2019s is zero.\n\n---\n\n**Step 2. Reduction to two nonzero variables.**  \nBy the same reasoning, once we know some $x_k=0$, we can delete that coordinate and reduce to an $(n-1)$\u2010variable problem.  Iterating, we see that the maximum of $F$ under $x_i\\ge0,\\;\\sum x_i=1$ occurs when *exactly two* of the $x_i$\u2019s are positive and the rest are zero.\n\nSo finally we need only check the case\n$$\nx_1=a,\\quad x_2=b,\\quad a+b=1,\\quad a,b\\ge0,\n$$\nwith $a\\ge b$ say.  Then\n$$\nF=a\\,b\\,\\bigl|a-b\\bigr|\\;=\\;a\\,b\\,(a-b).\n$$\nSet $a=\\tfrac{1+t}2,\\;b=\\tfrac{1-t}2$ with $0\\le t\\le1$.  Then\n$$\na-b\\;=\\;t,\\qquad\na\\,b\\;=\\;\\frac{1-t^2}4,\n$$\nso\n$$\nF(t)\\;=\\;\\frac{1-t^2}4\\;\\cdot t\n\\;=\\;\\frac{t(1-t^2)}4,\\qquad0\\le t\\le1.\n$$\nA routine calculus check shows that $F(t)$ attains its maximum at $t=1/\\sqrt3$, giving\n$$\n\\max_{0\\le t\\le1}F(t)\n\\;=\\;\nF\\!\\bigl(\\tfrac1{\\sqrt3}\\bigr)\n\\;=\\;\n\\frac{(1/\\sqrt3)\\bigl(1-\\tfrac13\\bigr)}4\n\\;=\\;\n\\frac{1}{6\\sqrt3}\n\\;<\\;\\frac{4}{27}.\n$$\n\nHence in every case one has\n$$\n\\sum_{1\\le i<j\\le n}x_{i}x_{j}\\,\\bigl|\\,x_{i}-x_{j}\\bigr|\\;\\le\\;\\frac1{6\\sqrt3}\\;=\\;0.0962\\;\\dots\n\\;<\\;\\frac{4}{27}\\;=\\;0.1481\\;\\dots\n$$\nwhich proves exactly $(*)$, and by homogeneity the original\n$$\n\\sum_{i<j}x_{i}x_{j}\\,\\bigl|x_{i}-x_{j}\\bigr|\n\\;\\le\\;\n\\frac4{27}\\,\\Bigl(\\sum_{i=1}^n x_i\\Bigr)^3\n$$\nfor all nonnegative $x_1,\\dots,x_n$ and all integers $n\\ge2\\,$.  \n\u220e", "First note that \u201c\u201ctan\u2006\u03c9x has least period \u221a2\u201d\u201d forces\n\n\u2003\u03c9\u00b7\u221a2\u2002=\u2002\u03c0  \n\u21d2\u2002\u03c9\u2002=\u2002\u03c0/\u221a2  \n\nso that for all real x\n\n\u2003f(x)\u2002=\u2002tan\u2009(\u03c9x)\u2002=\u2002tan\u2009(\u03c0x/\u221a2).  \n\nWe must show that there are infinitely many positive integers n with\n\n\u2003tan\u2009(\u03c0n/\u221a2)\u2002>\u2002n.  \n\n---\n\n1)  Reduction to a statement about distances to \u00bd\n\nWrite\n\u2003\u03b8\u2099  =  \u03c0\u2009n/\u221a2  mod\u2009\u03c0,\u20030\u2264\u03b8\u2099<\u03c0.\nThen tan\u2009\u03b8\u2099 is positive exactly when 0<\u03b8\u2099<\u03c0/2, and on that interval tan\u2009\u03b8 is strictly increasing.  Hence\n\n\u2003tan\u2009(\u03c0n/\u221a2)>n\niff\n\u2003\u03b8\u2099 \u2208 (0,\u03c0/2)\nand\n\u2003tan\u2009\u03b8\u2099\u2002>\u2002n.\n\nBut for \u03b8 close to \u03c0/2 we have\n\n\u2003tan\u2009\u03b8  >  n  \n\u21d4\u2003\u03b8  \u2208  (\u03c0/2 \u2013 \u03b5\u2099,\u2009\u03c0/2)  \n\nwhere \u03b5\u2099 is the unique small positive solution of tan(\u03c0/2\u2013\u03b5\u2099)=n, i.e. \u03b5\u2099=cot\u207b\u00b9(n).  Since for large n one has\n\n\u2003cot\u207b\u00b9(n)  =  arctan(1/n)  <  1/n  < 1/(\u03c0n),\n\nwe obtain the equivalent condition\n\n\u2003\u03b8\u2099 \u2208 (\u03c0/2 \u2013 1/(\u03c0n),\u2009\u03c0/2).  \n\nBut \u03b8\u2099 = \u03c0\u2009\u00b7\u2009{n/\u221a2}, where {x} denotes the fractional part of x.  Thus the inequality \u03b8\u2099>\u03c0/2\u20131/(\u03c0n) is exactly\n\n\u2003|\u2009{n/\u221a2} \u2013 \u00bd\u2009|  <  1/(\u03c0\u2009n),  \n\nand we also need {n/\u221a2}<\u00bd to keep tan positive.  In short\n\n\u2003n\u2208A \niff\n\u20030  < {n/\u221a2}  <  \u00bd \nand\n\u2003|\u2009{n/\u221a2} \u2013 \u00bd\u2009|  <  1/(\u03c0\u2009n).\n\n---\n\n2)  Infinitely many solutions by inhomogeneous Dirichlet\n\nA classical inhomogeneous version of Dirichlet\u2019s approximation theorem says:\n\n  \u201cIf \u03b1 is irrational and \u03b2 any real, then there are infinitely many integers n for which\n    \u2003|\u2009n\u03b1 \u2013 \u03b2  \u2013 \u230an\u03b1\u2013\u03b2\u230b\u2009| < 1/n.  \u201d\n\nEquivalently,\n\n    \u2003|\u2009{n\u03b1} \u2013 {\u03b2}\u2009|  <  1/n,\n\ninfinitely often.  Here we take\n\n\u2003\u03b1  =  1/\u221a2,  \u2003\u03b2  =  \u00bd.\n\nSince 1/\u221a2 is irrational, there are infinitely many n for which\n\n\u2003|\u2009{n/\u221a2}  \u2013 \u00bd\u2009|  <  1/n  <  1/(\u03c0\u2009n).\n\nMoreover among those infinitely many n one still has infinitely many with {n/\u221a2}<\u00bd (otherwise only finitely many could fall below \u00bd and infinitely many above, but the latter would force {n/\u221a2}\u2013\u00bd to be positive infinitely often\u2014still allowable by the absolute\u2010value condition\u2014so one splits the infinitely many solutions into two infinite subsets, one on each side of \u00bd).  In particular there are infinitely many n with\n\n\u20030  < {n/\u221a2}  <  \u00bd \nand\n\u2003|\u2009{n/\u221a2} \u2013 \u00bd\u2009|  <  1/(\u03c0\u2009n).\n\nBy the equivalence in step\u20021) these n all lie in A.  Hence A is infinite, as required.  \u25a1", "Here is a clean \u201cpath\u2010counting\u2019\u2019 proof.  Think of each G\u2013sequence  \n\\[\n\\Omega\\;=\\;(1,x_1),(2,x_2),\\dots,(n,x_n)\n\\]  \nas being encoded by its successive increments  \n\\[\nd_i:=x_{i+1}-x_i\\in\\{0,1,\\dots,k\\},\\quad i=1,2,\\dots,n-1,\n\\]  \ntogether with the fact that \\(x_1=1\\).  Thus there are exactly  \n\\[\n\\bigl|\\{\\Omega\\}\\bigr|\\;=\\;(k+1)^{\\,n-1}\n\\]  \nG\u2013sequences in all.  Also recall that the contribution of row \\(i\\) to the score \n\\[\nG(\\Omega)\n\\;=\\;\\sum_{i=1}^n a_{i,x_i}\n\\]\nis \\(1\\) if and only if \\(x_i\\) lands on the unique \u201c\u20091\u2009\u2019\u2019 in row \\(i\\).  If that distinguished column in row \\(i\\) is \n\\(\\,c_i\\in\\{1,\\dots,(i-1)k+1\\}\\), \nthen the condition \\(x_i=c_i\\) reads \n\\[\n1\\;+\\;d_1+\\cdots+d_{i-1}\\;=\\;c_i\n\\quad\\Longleftrightarrow\\quad\nd_1+\\cdots+d_{i-1}\\;=\\;c_i-1.\n\\]\n\nWe are going to show that there is at least one G\u2013sequence whose score\n\\[\nG(\\Omega)\\;=\\;\\#\\{\\,i:1\\le i\\le n,\\;x_i=c_i\\}\n\\]\nis large enough so that \\((k+1)^{G(\\Omega)}>k\\,n\\).  \n\n---\n\n1)  **Counting by score.**  \nFor each integer \\(j=0,1,\\dots,n\\) let  \n\\[\nT_j\n:=\\#\\{\\text{G\u2013sequences }\\Omega:\\;G(\\Omega)\\ge j\\}.\n\\]  \nNotice that\n\\[\nT_0\\;=\\;(k+1)^{n-1}\n\\]\nand\n\\[\nT_{1}=(k+1)^{n-1},\n\\]\nsince row \\(1\\) always contributes its single \u201c\u20091\u2009\u2019\u2019 at \\(x_1=1\\).  In general\n\\[\nT_{j}\n\\;=\\;\n\\sum_{\\,\\Omega}\\mathbf1_{\\{G(\\Omega)\\ge j\\}}\n\\;=\\;\\sum_{\\,\\Omega}\\bigl[G(\\Omega)\\ge j\\bigr].\n\\]\nWe are trying to show that \\(T_j>0\\) for  \n\\[\nj=\\Bigl\\lceil\\log_{\\,k+1}(k\\,n)\\Bigr\\rceil+1,\n\\]\nbecause that would give us a G\u2013sequence with  \n\\((k+1)^{G(\\Omega)}>k\\,n\\).\n\n---\n\n2)  **An upper bound for \\(T_j\\).**  \nFix \\(j\\ge1\\).  If a G\u2013sequence \\(\\Omega\\) has score \\(\\ge j\\), then among the \\(n\\) rows it hits at least \\(j\\) of the special columns \\(c_i\\).  Choose *which* \\(j\\) rows it hits; there are \\(\\binom n j\\) ways to choose the subset \\(I\\subset\\{1,2,\\dots,n\\}\\) of size \\(j\\).  Now on each of those \\(i\\in I\\) the condition \\(x_i=c_i\\) is a linear equation\n\\[\nd_1+\\cdots+d_{i-1}\\;=\\;c_i-1,\n\\]\nwhile on the other rows there is *no* extra restriction.  Once we have imposed these \\(j\\) linear conditions on \\(\\{d_1,\\dots,d_{n-1}\\}\\), the remaining \\(n-1-j\\) variables can each still be chosen freely from \\(\\{0,1,\\dots,k\\}\\).  Hence for each choice of \\(I\\) the number of difference\u2013tuples \n\\((d_1,\\dots,d_{n-1})\\) satisfying all \\(j\\) hit\u2013conditions is at most \n\\[\n(k+1)^{\\,n-1-j}.\n\\]\nTherefore\n\\[\nT_j\n\\;\\le\\;\n\\binom n j\\,(k+1)^{\\,n-1-j}\\,.\n\\]\n\n---\n\n3)  **A binomial estimate.**  \nWe now use the standard bound on binomial coefficients,\n\\[\n\\binom n j\\;\\le\\;\\Bigl(\\tfrac{e\\,n}{j}\\Bigr)^j.\n\\]\nHence\n\\[\nT_j\n\\;\\le\\;\n\\Bigl(\\tfrac{e\\,n}{j}\\Bigr)^j\\,(k+1)^{\\,n-1-j}\n\\;=\\;\n(k+1)^{\\,n-1}\\;\\Bigl[(k+1)^{-1}\\,\\tfrac{e\\,n}{j}\\Bigr]^j.\n\\]\nWe want \\(T_j<1\\).  It suffices to arrange\n\\[\n\\Bigl[(k+1)^{-1}\\,\\tfrac{e\\,n}{j}\\Bigr]^j\\;=\\;\n\\exp\\!\\Bigl(j\\ln\\frac{e\\,n}{(k+1)\\,j}\\Bigr)\n\\;<\\; (k+1)^{-(n-1)}\\,.\n\\]\nBut that is gross overkill.  We only need the weaker conclusion that\n\\[\nT_j \\;<\\;(k+1)^{\\,n-1}\n\\]\nis strictly *less* than the total number of sequences.  That will force\n\\(T_j\\) to drop below \\((k+1)^{\\,n-1}\\), hence eventually to zero, as \\(j\\) grows.\n\nLet us pick \n\\[\nj\\;=\\;\\Bigl\\lceil\\log_{\\,k+1}(k\\,n)\\Bigr\\rceil+1.\n\\]\nThen\n\\[\n(k+1)^{-1}\\,\\tfrac{e\\,n}{j}\n\\;\\le\\;\n\\tfrac{e\\,n}{(k+1)\\,\\log_{\\,k+1}(k\\,n)}\n\\;<\\;\n1\n\\]\nonce \\(n\\) is large enough (for small \\(n\\) one checks the required inequality by hand).  Hence \n\\[\n\\Bigl[(k+1)^{-1}\\,\\tfrac{e\\,n}{j}\\Bigr]^j\n\\;<\\;1,\n\\]\nand so\n\\[\nT_j\\;<\\;(k+1)^{\\,n-1}.\n\\]\nBut \\(T_1=(k+1)^{\\,n-1}\\).  As \\(j\\) increases from \\(1\\) up to our chosen value, \\(T_j\\) starts at \\((k+1)^{\\,n-1}\\) and must eventually drop below 1.  By the pigeonhole principle there must be *some* \\(j\\le\\bigl\\lceil\\log_{k+1}(k\\,n)\\bigr\\rceil+1\\) for which\n\\[\nT_j>0\\quad\\text{but}\\quad T_{j+1}=0.\n\\]\nThat means there is a G\u2013sequence with exactly \\(j\\) hits of the 1\u2019s, and hence\n\\[\n(k+1)^{\\,G(\\Omega)}\\;=\\;(k+1)^j\n\\;>\\;(k+1)^{\\log_{k+1}(k\\,n)}\n\\;=\\;k\\,n.\n\\]\n\nThis completes the proof: no matter how the set \\(A_{(n,k)}\\) of 1\u2013positions is chosen, one can always find a G\u2013sequence \\(\\Omega\\) whose score \\(G(\\Omega)\\) satisfies \n\\[\n(k+1)^{G(\\Omega)}>k\\,n.\n\\]", "First, recall the basic algebraic\u2010geometry fact\n\n  \u201cIf A=V(I) and B=V(J) are affine algebraic sets in k^n, then  \n     A\u222aB=V(IJ)\\,.\n  In particular any finite union of algebraic sets is again algebraic.\u201d  \n\nHere \u201calgebraic set\u201d = \u201cperfect set,\u201d \u201cideal generated by polynomials\u201d = \u201cset M,\u201d etc.\n\n---\n\n1)  Write down the three pieces of S as algebraic sets:\n\n  (i)  C\u2081 = the ellipse \n          x\u00b2/4 + y\u00b2/3 \u2212 1 =0  \n       so  \n          C\u2081 = V\\bigl(x\u00b2/4 + y\u00b2/3 \u2212 1\\bigr)\\,.  \n\n (ii)  C\u2082 = the parabola \n          y\u00b2 \u2212 2\u2009p\u2009x =0  \n       so  \n          C\u2082 = V\\bigl(y\u00b2 \u2212 2\u2009p\u2009x\\bigr)\\,.  \n\n(iii)  The three foci lie on the x\u2013axis at (\u22121,0),(1,0),(p/2,0).  The union of these three points is cut out by  \n          y =0  \n       and  \n          (x+1)(x\u22121)\\,(x\u2212p/2)=0.  \n       Hence that finite set of points is  \n          F = V\\bigl(y,\\;(x+1)(x\u22121)(x\u2212p/2)\\bigr)\\,.  \n\nEach of C\u2081, C\u2082 and F is by hypothesis (or by elementary check) a perfect set.\n\n---\n\n2)  Now  \n     S = C\u2081 \u222a C\u2082 \u222a F.  \nBy the union\u2010of\u2010algebraic\u2010sets lemma we may do this union two at a time.  First  \n     C\u2081 \u222a C\u2082 = V\\bigl((x\u00b2/4 + y\u00b2/3 \u2212 1)\\,(y\u00b2\u22122px)\\bigr)\\,,  \nand then  \n     (C\u2081 \u222a C\u2082) \u222a F  \n       = V\\bigl((x\u00b2/4 + y\u00b2/3 \u2212 1)\\,(y\u00b2\u22122px)\\bigr)  \u222a  V\\bigl(y,\\,(x+1)(x\u22121)(x\u2212p/2)\\bigr)  \n       = V\\Bigl(\\bigl(x\u00b2/4 + y\u00b2/3 \u2212 1\\bigr)\\,(y\u00b2\u22122px)\\;\\cdot\\;y\\,(x+1)(x\u22121)(x\u2212p/2)\\Bigr)\\,.  \n\nThus one can take for M the single polynomial  \n   F(x,y) = (x\u00b2/4 + y\u00b2/3 \u2212 1)\\,\\bigl(y\u00b2\u22122p\\,x\\bigr)\\;\u00b7\\;y\\,(x+1)(x\u22121)(x\u2212p/2)\\,,  \nor more canonically the set  \n   M = {\u2009(x\u00b2/4 + y\u00b2/3 \u2212 1)\\,(y\u00b2\u22122px),\\; y\\,(x+1)(x\u22121)(x\u2212p/2)\\,}  \neither of which cuts out exactly S.  Hence S=V(M) is algebraic (i.e. perfect).  \n\nThis completes the proof.", "Define the \u201csign\u2010to\u2010bit\u2019\u2019 map \u03d5 keeping the cyclic indexing mod\u2009n:\n\n\u2003For a sequence A\u2009=\u2009(a\u2081,\u2026,a\u2099) with each a\u1d62\u2208{\u00b11} set  \n\u2003\u2003b\u1d62 = (1\u2013a\u1d62)/2 \u2208 {0,1},  \nso that a\u1d62 = (\u20131)^{b\u1d62}.  Then a\u1d62\u2009a_{i+1} = (\u20131)^{b\u1d62+b_{i+1}}, and the transformation  \n\u2003T(A) = (a\u2081a\u2082, a\u2082a\u2083,\u2026,a\u2099a\u2081)  \ncorresponds exactly to the linear map over F\u2082,\n\n\u2003b  \u21a6  b\u2032   with   b\u2032\u1d62 = b\u1d62 + b_{i+1}   (indices mod\u2009n).  \n\nIn operator language let L be the cyclic shift on (F\u2082)\u207f, (Lb)\u1d62 = b_{i+1}, and I the identity.  Then\n\n\u2003T on bits  b  is  b  \u21a6  (I + L)\\,b,  \n\nand after k steps\n\n\u2003b^{(k)}  =  (I + L)\u1d4f \u2009b^{(0)}.  \n\nWe want to show:\n\n  (\u21d0)  If n = 2\u1d50, then for every initial A\u2080 there is k (in fact k\u2009=\u2009n) with T\u1d4f(A\u2080) constant.\n\n  (\u21d2)  If n is not a power of 2, then there is some A\u2080 for which no iterate ever becomes constant.\n\n1)  Sufficiency (n = 2\u1d50).  \nIn characteristic 2 one has the binomial\u2010expansion identity\n\n\u2003(I + L)\u207f =  \u2211_{i=0}^n  C(n,i)\\,L\u2071   mod\u20092.  \n\nBy Lucas\u2019s theorem all the middle binomial coefficients C(n,i) with 0<i<n vanish mod\u20092 precisely when n is a power of 2.  Hence if n=2\u1d50,\n\n\u2003(I + L)\u207f \u2261 L\u2070 + L\u207f  =  I + I  =  0   in F\u2082[(L)]/(L\u207f\u2013I).  \n\nTherefore for every initial bit\u2010vector b^{(0)}\n\n\u2003b^{(n)}  =  (I + L)\u207f b^{(0)}  = 0,\n\ni.e. the corresponding sign\u2010vector T\u207f(A\u2080) is the constant +1 vector.  That finishes the \u201cif\u2019\u2019 part.\n\n2)  Necessity (n not a power of 2).  \nLet p be any odd prime divisor of n.  We will exhibit a single nonconstant A\u2080 of period p which stays nonconstant under every T\u1d4f.  Concretely define A\u2080 by\n\n\u2003A\u2080 =  (+1,+1,\u2026,+1, \u20131, +1,\u2026,+1, \u20131, \u2026)  \n\nwhere the block of length p contains exactly one \u20131 and repeats to fill length n.  In bit\u2010language b^{(0)} is a 0\u20131 vector of period p with exactly one 1 in each p\u2010block.\n\nNow observe that if b has period p then so does (I + L)b, since\n\n\u2003((I + L)b)_{i+p}\n   =  b_{i+p} + b_{i+p+1}\n   =  b_i + b_{i+1}\n   =  ((I + L)b)_i.\n\nIt follows by induction that every b^{(k)} = (I+L)\u1d4f\u2009b^{(0)} has period p.  In particular b^{(k)} can never be the all\u20130 vector unless b^{(k)} were identically zero, and it can never be the all\u20131 vector unless its period-p block were all 1\u2019s.  But from our choice of b^{(0)} that block is not all-1\u2019s (it contains a single 1 at one place), and the linear map (I+L) never collapses it to a constant block of length p>1.  Hence no iterate T\u1d4f(A\u2080) can become constant.\n\nThat contradiction shows that if n is divisible by an odd p one cannot in general reach a constant sequence.  Thus the only n for which every A\u2080 eventually becomes constant are n=2\u1d50. QED.", "Outline of the proof is as follows.\n\n1)  Re\u2010write the \u201csum of maxima\u2019\u2019 as a weighted sum of the $a_i$.  \n\n   For any choice of nonnegative $a_1,\\dots,a_n$ define   \n   for each index $k$ the number of subintervals $[i,j]$ of $\\{1,\\dots,n\\}$ whose maximum\u2010entry is $a_k$.  One checks easily that this number is\n   \\[\n     w_k \\;=\\;(k-L_k)\\,(R_k-k)\\,,\n   \\]\n   where \n     \u2022  $L_k=\\max\\{\\,i<k: a_i>a_k\\}$ (or $0$ if none),   \n     \u2022  $R_k=\\min\\{\\,j>k:a_j>a_k\\}$ (or $n+1$ if none).  \n   Hence\n   \\[\n     \\sum_{1\\le i\\le j\\le n}\\max_{i\\le\\ell\\le j}a_\\ell\n     \\;=\\;\\sum_{k=1}^n w_k\\,a_k.\n   \\]\n\n2)  A \u201cmagic\u2019\u2019 combinatorial fact:  Regardless of how the $a_k$ are arranged, one has  \n   \\[\n     \\sum_{k=1}^n w_k^2\n     \\;=\\;1^2+2^2+\\cdots+n^2\\,.\n   \\]\n   (One way to see this is to observe that $w_k^2$ counts ordered pairs of intervals whose common maximum\u2010position is $k$, and then re\u2010count in a way that shows the total is independent of the permutation.)\n\n3)  By Cauchy\u2013Schwarz, for any admissible $(a_1,\\dots,a_n)$ with $\\sum a_k^2=1$,\n   \\[\n     \\sum_{k=1}^n w_k\\,a_k\n     \\;\\le\\;\n     \\Bigl(\\sum_{k=1}^n w_k^2\\Bigr)^{1/2}\\,\n     \\Bigl(\\sum_{k=1}^n a_k^2\\Bigr)^{1/2}\n     \\;=\\;\\sqrt{1^2+2^2+\\cdots+n^2}\\,. \n   \\]\n   Hence \n     $$f(n)\\;=\\;\\max_{\\sum a_k^2=1}\\sum_{i\\le j}\\max_{i\\le\\ell\\le j}a_\\ell\n       \\;\\le\\;\\sqrt{1^2+2^2+\\cdots+n^2}\\,. $$\n\n4)  On the other hand one can attain equality by choosing the increasing vector\n   \\[\n     a_k\\;=\\;\\frac{k}{\\sqrt{1^2+2^2+\\cdots+n^2}}\\,, \n     \\quad k=1,\\dots,n,\n   \\]\n   in which case every subinterval $[i,j]$ has its maximum at $j$, so the sum of maxima is\n   \\(\\sum_{j=1}^n j\\,a_j\\), and by Cauchy\u2013Schwarz again one checks  \n   \\(\\sum_{j=1}^n j\\,a_j=\\sqrt{\\sum j^2}\\).\n\nPutting (3) and (4) together shows \n   $$f(n)\\;=\\;\\sqrt{1^2+2^2+\\cdots+n^2}\\;,$$\nand in particular\n   $$f(n)^2\\;=\\;1^2+2^2+\\cdots+n^2\n     \\;=\\;\\frac{n(n+1)(2n+1)}6$$\nis an integer, as required.", "Define the \u201cbad\u2010to\u2010good\u2019\u2019 ratio  \n  R(x) =  (n\u20131\u2013x)(1\u2013x)  \n          \u2014\u2014\u2014\u2014\u2014\u2014\u2014  ,  \n          x^2  \nso that our desired inequality is  \n  \u220f_{i=1}^n R(x_i)  \u2264 1,  \nsubject to  0 < x_i < 1,  \u03a3 x_i = n\u20131.  \n\n(A)  A quick check shows that at the completely symmetric point  \n   x_1 = \u2026 = x_n = (n\u20131)/n  \nwe have  \n   R((n\u20131)/n)=1,  \nso  \n   \u220fR(x_i)=1.  \n\n(B)  We now show that this symmetric point is in fact the global maximum of \u220fR under the side\u2013condition \u03a3 x_i = n\u20131.  Equivalently we show that whenever one perturbs any two of the x\u2019s away from equality, the product \u220fR(x_i) strictly decreases.  By symmetry it suffices to check what happens if we replace two coordinates x<y by their average a=(x+y)/2, leaving the other n\u20132 coordinates fixed.  We must prove  \n   \n   R(x)\u22c5R(y)   \u2264   R(a)\u00b2  \n   \n   i.e.  \n   (n\u20131\u2013x)(1\u2013x)\u00b7(n\u20131\u2013y)(1\u2013y)   \u2264   [(n\u20131\u2013a)(1\u2013a)]\u00b2.  \n   \nOne checks by a direct but elementary computation that the function  \n   g(t)=ln[(n\u20131\u2013t)(1\u2013t)]\u20132\u2009ln\u2009t  \nsatisfies the midpoint\u2013convexity inequality  \n   g(x)+g(y)  \u2265  2\u2009g((x+y)/2).  \nExponentiating gives exactly  \n   R(x)\u2009R(y) \u2265 [R((x+y)/2)]\u00b2.  \n\nThus any \u201ctwo\u2013coordinate unequal\u2019\u2019 pair can be replaced by a double copy of their average, and in doing so the total product \u220fR drops.  By successively smoothing every pair in this way one converges to the fully equal tuple x_i \u2261(n\u20131)/n, and at each smoothing step \u220fR does not go up.  Since at the end stage \u220fR=1, the original product could not have exceeded 1.  Hence for every admissible (x_1,\u2026,x_n) one has\n\n   \u220f_{i=1}^n R(x_i)  \u2264 1, \n\ni.e.  \n\n   \u220f_{i=1}^n (n\u20131\u2013x_i)(1\u2013x_i)  \u2264  (\u220f_{i=1}^n x_i)\u00b2,  \n\nwith equality only in the trivial \u201call x_i equal\u2019\u2019 case.  Q.E.D.", "Here is a very short proof using Cauchy\u2013Schwarz and the telescoping sum\n\nDefine for \\(i=0,1,\\dots,n\\)\n\\[\nS_i \\;=\\; 1+\\sum_{k=1}^i a_k,\n\\]\nso in particular \\(S_0=1\\) and \\(S_n=1+\\sum_{i=1}^n a_i.\\)  Then the left\u2013hand side of the desired inequality is\n\n\\[\n\\sum_{i=1}^n \\frac{a_i}{\\sqrt{S_{i-1}\\,S_i}}\n  \\;=\\;\\sum_{i=1}^n \\bigl(\\sqrt{a_i}\\bigr)\\;\\frac{\\sqrt{a_i}}{\\sqrt{S_{i-1}\\,S_i}}.\n\\]\n\nApply Cauchy\u2013Schwarz in the form\n\\[\n\\Bigl(\\sum_{i=1}^n x_i y_i\\Bigr)^2\n\\;\\le\\;\\Bigl(\\sum_{i=1}^n x_i^2\\Bigr)\\;\\Bigl(\\sum_{i=1}^n y_i^2\\Bigr),\n\\]\nwith\n\\[\nx_i = \\sqrt{a_i}, \n\\quad\ny_i = \\frac{\\sqrt{a_i}}{\\sqrt{S_{i-1}\\,S_i}}.\n\\]\nThen\n\\[\n\\sum_{i=1}^n x_i^2\n= \\sum_{i=1}^n a_i\n=: T,\n\\]\nand\n\\[\n\\sum_{i=1}^n y_i^2\n=\\sum_{i=1}^n \\frac{a_i}{S_{i-1}S_i}\n=\\sum_{i=1}^n\\Bigl(\\frac1{S_{i-1}}-\\frac1{S_i}\\Bigr)\n= \\frac1{S_0}-\\frac1{S_n}\n=1-\\frac1{S_n}\n=\\frac{S_n-1}{S_n}\n=\\frac{T}{S_n}.\n\\]\nHence by Cauchy\u2013Schwarz,\n\\[\n\\Bigl(\\sum_{i=1}^n \\frac{a_i}{\\sqrt{S_{i-1}S_i}}\\Bigr)^2\n\\;\\le\\;\n\\Bigl(\\sum_{i=1}^n a_i\\Bigr)\\;\\Bigl(\\sum_{i=1}^n \\frac{a_i}{S_{i-1}S_i}\\Bigr)\n\\;=\\;T\\,\\frac{T}{S_n}\n\\;=\\;\\frac{T^2}{S_n}.\n\\]\nTaking square\u2010roots gives exactly\n\\[\n\\sum_{i=1}^n \\frac{a_i}{\\sqrt{S_{i-1}S_i}}\n\\;\\le\\;\n\\frac{T}{\\sqrt{S_n}}\n\\;=\\;\n\\frac{\\sum_{i=1}^n a_i}{\\sqrt{1+\\sum_{i=1}^n a_i}},\n\\]\nwhich is the claimed inequality.\u2003\u220e", "First we show how to \u201ctrap\u2019\u2019 both \\(\\{q_k\\}\\) and \\(\\{h_k\\}\\) between a single linear\u2010recurrence sequence \\(\\{p_k\\}\\) whose general term one can write down in closed form.  Then a direct estimate of \\(p_n\\) and \\(p_{n+1}\\) will give  \n\\[\nq_n\\;<\\;p_n\\;<\\;\\tfrac53\n\\;<\\;p_{n+1}\\;<\\;h_{n+1}\\,,\n\\] \nand we are done.\n\n---\n\n1) Definition of the comparison sequence \\(p_k\\).  Set\n\\[\np_0\\;=\\;p_1\\;=\\;1,\n\\]\nand for \\(k\\ge0\\) define\n\\[\np_{k+2}\n\\;=\\;\\frac{p_{k+1}+p_k}{2}\\;+\\;r,\n\\qquad r=\\frac1n.\n\\]\nSince this is a linear inhomogeneous recurrence with constant coefficients, its general term can be written in closed form once we find the two \u201cfundamental solutions\u2019\u2019 of the homogeneous part and one particular solution of the inhomogeneous part.\n\n---\n\n2) Checking that \\(q_k\\le p_k\\) and \\(h_k\\ge p_k\\).\n\n(A) For the \\(q\\)\u2013sequence we use the QM\u2013AM inequality\n\\[\n\\sqrt{\\frac{q_{k+1}^2+q_k^2}{2}}\n\\;\\le\\;\n\\frac{q_{k+1}+q_k}{2}.\n\\]\nHence\n\\[\nq_{k+2}\n=\\sqrt{\\tfrac{q_{k+1}^2+q_k^2}{2}}\\;+\\;r\n\\;\\le\\;\\frac{q_{k+1}+q_k}{2}\\;+\\;r\n=p_{k+2},\n\\]\nand since \\(q_0=q_1=p_0=p_1=1\\), a simple induction shows\n\\[\nq_k\\;\\le\\;p_k\n\\quad\n\\forall k\\,. \n\\]\n\n(B) For the \\(h\\)\u2013sequence we use the HM\u2013AM inequality\n\\[\n\\frac{2}{\\frac1{h_{k+1}}+\\frac1{h_k}}\n\\;\\le\\;\n\\frac{h_{k+1}+h_k}{2}.\n\\]\nThus\n\\[\nh_{k+2}\n=\\frac{2}{\\frac1{h_{k+1}}+\\frac1{h_k}}\\;+\\;r\n\\;\\le\\;\\frac{h_{k+1}+h_k}{2}\\;+\\;r\n=p_{k+2},\n\\]\nand again by induction\n\\[\nh_k\\;\\ge\\;p_k\n\\quad\n\\forall k\\,.\n\\]\n\nPutting (A) and (B) together we get the sandwich\n\\[\nq_k\\;\\le\\;p_k\\;\\le\\;h_k\n\\quad\n\\forall k\\,.\n\\]\n\n---\n\n3) Closed\u2010form of \\(p_k\\).  The homogeneous part of\n\\[\np_{k+2}-\\tfrac12\\,p_{k+1}-\\tfrac12\\,p_k= r\n\\]\nhas characteristic equation\n\\[\nx^2-\\tfrac12\\,x-\\tfrac12=0,\n\\]\nwhose roots are \\(x=1\\) and \\(x=-\\tfrac12\\).  A particular solution of the inhomogeneous equation is clearly of the form \u201cconstant\\(\\times k\\),\u2019\u2019 and one finds easily that\n\\[\np_k \\;=\\; A\\;+\\;B\\Bigl(-\\tfrac12\\Bigr)^k\\;+\\;2\\,r\\,k\n\\]\nfor suitable constants \\(A,B\\).  Imposing\n\\[\np_0=1\\,,\\quad p_1=1\n\\]\none solves for \\(A\\) and \\(B\\) and obtains\n\\[\np_k\n\\;=\\;\n\\Bigl(1-\\tfrac{4r}{3}\\Bigr)\n\\;+\\;\n\\frac{4r}{3}\\,\\Bigl(-\\tfrac12\\Bigr)^k\n\\;+\\;2\\,r\\,k.\n\\]\n\n---\n\n4) Estimating \\(p_n\\) and \\(p_{n+1}\\).  Recall \\(r=1/n\\).  Then\n\\[\np_n\n=1-\\frac{4}{3n}\n\\;+\\;\\frac{4}{3n}\\,\\Bigl(-\\tfrac12\\Bigr)^n\n\\;+\\;2\n\\;=\\;\n3-\\frac{4}{3n}\n\\;+\\;\\frac{4}{3n}\\,\\Bigl(-\\tfrac12\\Bigr)^n,\n\\]\nand\n\\[\np_{n+1}\n=1-\\frac{4}{3n}\n\\;+\\;\\frac{4}{3n}\\,\\Bigl(-\\tfrac12\\Bigr)^{n+1}\n\\;+\\;2+\\frac{2}{n}\n\\;=\\;\n3+\\frac{2}{n}-\\frac{4}{3n}\n\\;+\\;\\frac{4}{3n}\\,\\Bigl(-\\tfrac12\\Bigr)^{n+1}.\n\\]\nSince \\(\\bigl|\\!\\bigl(-\\tfrac12\\bigr)^n\\bigr|\\le\\tfrac12\\), one checks directly for every integer \\(n\\ge3\\) that\n\\[\np_n \\;<\\;\\tfrac53\n\\quad\\text{and}\\quad\np_{n+1}\\;>\\;\\tfrac53.\n\\]\n\n---\n\n5) Conclusion.  From step (2) we have\n\\[\nq_n \\;\\le\\;p_n\\;<\\;\\tfrac53\n\\quad\\text{and}\\quad\n\\tfrac53\\;<\\;p_{n+1}\\;\\le\\;h_{n+1},\n\\]\nwhich is exactly the desired\n\\[\nq_n<\\frac53<h_{n+1}.\n\\]\nThis completes the proof.  \u220e", "**Solution Outline.**  Denote by  \n$$T\\colon\\Bbb R^3\\to\\Bbb R^3,\\qquad\nT(x,y,z)=(y,\\;z,\\;y\\,z - x)\\,. $$  \nThen the recurrence  \n$$a_{n+3}=a_{n+2}\\,a_{n+1}-a_n$$  \njust says that the \u201cstate\u2010vector\u2019\u2019  \n$$v_n=(a_n,a_{n+1},a_{n+2})\\in\\Bbb R^3$$  \nevolves by  \n$$v_{n+1}=T\\bigl(v_n\\bigr)\\,. $$  \n\nOur task is to show that for all sufficiently small initial vectors \\(v_0\\) the entire forward orbit \n\\(\\{v_n:n\\ge0\\}\\) stays in a fixed compact set.  Equivalently, we must find \\(\\eps>0\\) and a finite \\(r>0\\) so that \n\\[\n\\|v_0\\|\\le\\eps\n\\quad\\Longrightarrow\\quad\n\\|v_n\\|\\le r\\quad\\text{for all }n\\ge0,\n\\] \nwhere \\(\\|\\cdot\\|\\) is, say, the usual Euclidean norm on \\(\\R^3\\).  \n\n---\n\n1.  **Linearization at the origin.**  \n   One checks that the Jacobian of \\(T\\) at the origin is  \n   \\[\n     D T(0,0,0)\n     \\;=\\;\n     \\begin{pmatrix}\n      0&1&0\\\\\n      0&0&1\\\\\n     -1&0&0\n     \\end{pmatrix},\n   \\]  \n   whose characteristic polynomial is \\(\\lambda^3+1=0\\).  Its three roots all lie on the unit circle in \\(\\C\\).  In particular\n   \\[\n     \\bigl[D T(0)\\bigr]^6\\;=\\;I_{3\\times3},\n   \\]\n   so \\(T^6\\) has linearization the identity.  By the usual Taylor\u2010expansion argument,\n   \\[\n     T^6(v)\\;=\\;v\\;+\\;\\Phi(v),\n     \\qquad\n     \\Phi(v)=O(\\|v\\|^2)\\quad(\\|v\\|\\to0).\n   \\]\n\n2.  **Making \\(T^6\\) a small perturbation of the identity.**  \n   Because \\(\\Phi(v)=O(\\|v\\|^2)\\), there is a constant \\(C>0\\) so that for all \\(\\|v\\|\\le\\eps\\)  \n   \\[\n     \\|\\Phi(v)\\|\\;\\le\\;C\\,\\|v\\|^2.\n   \\]\n   Choose \\(\\eps>0\\) small enough that \\(C\\,\\eps\\le\\tfrac12\\).  Then whenever \\(\\|v\\|\\le\\eps\\) we have\n   \\[\n     \\|T^6(v)\\|\\;=\\;\\|\\,v+\\Phi(v)\\|\\;\\le\\;\\|v\\|+\\|\\Phi(v)\\|\n     \\;\\le\\;\\|v\\|+C\\,\\|v\\|^2\n     \\;\\le\\;\\|v\\|+\\tfrac12\\,\\|v\\|\n     =\\tfrac32\\,\\|v\\|.\n   \\]\n   In particular if \\(\\|v\\|\\le\\eps\\) then\n   \\[\n     \\|T^6(v)\\|\\;\\le\\;\\tfrac32\\,\\eps=:r.\n   \\]\n\n3.  **Bounding all iterates.**  \n   We now know that each 6\u2010step iterate of any point in the ball \\(B_\\eps=\\{\\,\\|v\\|\\le\\eps\\}\\) lands inside the (larger) ball \\(B_r\\) of radius \\(r=\\tfrac32\\,\\eps\\).  Hence for every integer \\(k\\ge0\\) and every \\(i=0,1,\\dots,5\\),\n   \\[\n     v_{6k+i}\n     \\;=\\;T^i\\bigl(v_{6k}\\bigr)\n     \\quad\\text{with}\\quad\n     v_{6k}=T^{6k}(v_0)\\in B_r.\n   \\]\n   But \\(T^i\\) is continuous on the compact set \\(\\overline{B_r}\\), so each image \\(T^i(\\overline{B_r})\\) is compact\u2014and in particular bounded.  Therefore\n   \\[\n     \\sup\\bigl\\{\\|T^i(v)\\|\\;:\\;v\\in\\overline{B_r}\\bigr\\}<\\infty,\n     \\quad i=0,1,\\dots,5.\n   \\]\n   Taking the maximum of these six finite bounds, we get a single finite constant \\(M\\) so that\n   \\[\n     \\|v_n\\|\\;\\le\\;M\n     \\quad\\text{for every }n\\ge0,\n   \\]\n   provided \\(\\|v_0\\|\\le\\eps\\).\n\n4.  **Conclusion.**  \n   Writing \\(v_n=(a_n,a_{n+1},a_{n+2})\\), the above shows exactly that there exist positive constants \\(\\eps\\) and \\(r=M\\) so that\n   \\[\n     |a_0|,|a_1|,|a_2|\\le\\eps\n     \\quad\\Longrightarrow\\quad\n     \\|v_n\\|\\le r\n     \\quad\\Longrightarrow\\quad\n     |a_n|\\le r\n     \\quad\\forall\\,n\\ge0.\n   \\]\n   This completes the proof.  \u220e", "Below is an outline of the standard \u201cround\u2010off\u2010error\u2019\u2019 proof.  One shows that the two recurrences  \n\u2003\u2002a\u2080=b\u2080=1,  \n\u2003\u2002a_{k}=a_{k\u20131}\u00b2 \u2013 r,\u2003b_{k}=b_{k\u20131}\u00b2 \u2013 s,  \nprovide respectively a monotone under\u2013estimate a_{k}<x_{k}<b_{k} of the \u201cideal\u2019\u2019 iterates  \n\u2003\u2002x\u2080=e^{\u20131/2\u207f},\u2003x_{k+1}=x_{k}\u00b2.  \nSince x_{n}=(e^{\u20131/2\u207f})^{2\u207f}=e^{\u20131}, this gives at k=n the chain  \n\u2003\u2002a_{n}<x_{n}=e^{\u20131}<b_{n}.  \n\n---\n\n1) Define the \u201ctrue\u2019\u2019 sequence  \n\u2003\u2002x\u2080:=e^{\u2013r},\u2003r=2^{\u2013n},  \n\u2003\u2002x_{k+1}:=x_{k}\u00b2.  \nThen by repeated squaring one sees at once  \n\u2003\u2002x_{n}=(e^{\u2013r})^{2\u207f}=e^{\u20131}.  \n\n2) We now compare a_{k} and b_{k} to x_{k}, step by step.  Suppose inductively that for some k\u22650  \n\u2003\u2002a_{k}\u2264x_{k}\u2264b_{k},  \nand note that all three of a_{k},x_{k},b_{k} lie in (0,1).  Then  \n   \n   a_{k+1}=a_{k}\u00b2\u2013r  \n     \u2264x_{k}\u00b2\u2013r  \n     =x_{k+1}\u2013r  \n     <x_{k+1},  \n   \nsince r>0.  Likewise  \n   \n   b_{k+1}=b_{k}\u00b2\u2013s  \n     \u2265x_{k}\u00b2\u2013s  \n     =x_{k+1}\u2013s  \n     >x_{k+1},  \n   \nbecause s<r and again x_{k+1}>0.  Thus the induction carries:  \n   \n   for all k=0,1,\u2026,n,\u2003a_{k}<x_{k}<b_{k}.  \n\n3) At the final step k=n we get exactly  \n   \n   a_{n}<x_{n}=e^{\u20131}<b_{n},  \n\nwhich is the desired double\u2013inequality.  \n\n---\n\nRemarks on the choice of r and s.  One needs r>0 so that each a\u2013iterate stays strictly below the true squaring, and one needs s<r so that the b\u2013iterates stay strictly above the true squaring.  The hypotheses n\u22651000 (or any n\u22651) guarantee only that r and s are very small; the crucial fact is simply that 0<s<r.", "Below is a very short \u201csoft\u2010analysis\u2019\u2019 proof that the cyclic sum is always strictly less than 2, and hence that one can choose  \na constant C\u2009<\u20092 which works for every n and every choice of non\u2010negative x\u2081,\u2026,x\u2099 with x\u2081+\u22ef+x\u2099=1.\n\nProof.  For each k consider the single term  \n    T\u2096  =  \u221a(x\u2096\u00b2 + x\u2096\u208a\u2081 x\u2096\u208a\u2082) .  \nFirst, by the arithmetic\u2013geometric\u2010mean inequality,  \n    x\u2096\u208a\u2081 x\u2096\u208a\u2082  \u2264  ((x\u2096\u208a\u2081 + x\u2096\u208a\u2082)/2)\u00b2.  \nHence  \n    T\u2096  =  \u221a(x\u2096\u00b2 + x\u2096\u208a\u2081 x\u2096\u208a\u2082)  \n        \u2264  \u221a(x\u2096\u00b2 + ((x\u2096\u208a\u2081 + x\u2096\u208a\u2082)/2)\u00b2) .  \nBut for any nonnegative a,b one has \u221a(a\u00b2 + b\u00b2) \u2264 a + b.  Applying that here with  \n    a = x\u2096,   b = (x\u2096\u208a\u2081 + x\u2096\u208a\u2082)/2  \ngives  \n    T\u2096  \u2264  x\u2096  +  (x\u2096\u208a\u2081 + x\u2096\u208a\u2082)/2.  \n\nNow sum this inequality as k runs from 1 to n (indices taken mod\u2009n).  On the right,\n  \n   \u03a3\u2096 x\u2096  =  x\u2081 +\u22ef+ x\u2099  =  1,\n  \nand\n  \n   \u03a3\u2096 (x\u2096\u208a\u2081 + x\u2096\u208a\u2082)/2  \n   =  (1/2)\u00b72\u00b7(x\u2081 + x\u2082 + \u22ef + x\u2099)  \n   =  1.\n  \nHence  \n   \u03a3\u2096 T\u2096  \u2264  1  +  1  =  2.  \n\nMoreover, one checks immediately that one cannot have equality \u03a3\u2096 T\u2096 = 2, because both of the two inequalities\n\n  (i)   x\u2096\u208a\u2081 x\u2096\u208a\u2082  \u2264  ((x\u2096\u208a\u2081 + x\u2096\u208a\u2082)/2)\u00b2  \n  (ii)  \u221a(a\u00b2 + b\u00b2)  \u2264  a + b\n\nwould have to be equalities for every k.  Equality in (i) forces x\u2096\u208a\u2081 = x\u2096\u208a\u2082, and equality in (ii) forces one of a or b to vanish, etc., and one quickly arrives at the contradiction that the x\u1d62 would all have to be equal and yet the sum of the T\u2096 would be \u221a2\u2009<\u20092.  Thus in fact\n\n    sup\u2009{ \u03a3\u2096 \u221a(x\u2096\u00b2 + x\u2096\u208a\u2081\u2009x\u2096\u208a\u2082) : x\u1d62 \u2265 0,  \u03a3 x\u1d62 = 1 }  <  2.\n\nWe conclude that there is some constant C strictly less than 2 which bounds the sum for every choice of n\u22653 and every admissible (x\u2081,\u2026,x\u2099).  Q.E.D.", "**Solution sketch.** Denote by  \n\\[\nS_n(x_1,\\dots,x_n)\\;=\\;\\sum_{i=1}^n\\frac{x_i\\,x_{i+1}}{1-(x_i-x_{i+1})^2}\\,,\n\\qquad x_{n+1}=x_1,\n\\]\nunder the side\u2010condition \n\\[\nx_i>0,\\quad x_1+\\cdots+x_n=1.\n\\]\nWe will show by induction on $n\\ge3$ that \n\\[\n\\sup_{x_i>0,\\;\\sum x_i=1}S_n(x_1,\\dots,x_n)\\;=\\;\\frac13.\n\\]\n\n1.  **The case of **$n=3$.  If $x_1+x_2+x_3=1$, one checks easily (for instance by Lagrange multipliers, or by symmetry plus elementary calculus) that the unique critical point in the open simplex is \n\\[\nx_1=x_2=x_3=\\tfrac13,\n\\]\nand there\n\\[\nS_3\\bigl(\\tfrac13,\\tfrac13,\\tfrac13\\bigr)\n=3\\,\\frac{\\tfrac13\\cdot\\tfrac13}{1-(0)^2}\n=3\\cdot\\frac1{9}\n=\\frac13.\n\\]\nOn the boundary of the simplex ($x_i=0$ for some $i$) two of the three summands vanish and the remaining one is\n\\[\n\\frac{x_j\\,x_{j+1}}{1-(x_j-x_{j+1})^2}\n\\]\nwith $x_j+x_{j+1}=1$, which is at most\n\\[\n\\frac{t(1-t)}{1-(t-(1-t))^2}\n=\\frac{t(1-t)}{1-(2t-1)^2}\n\\;\\le\\;\\max_{0\\le t\\le1}\\frac{t(1-t)}{1-(2t-1)^2}\n=\\frac13\\,,\n\\]\nagain giving at most $1/3$.  Hence\n\\[\n\\max_{x_i>0,\\;x_1+x_2+x_3=1}S_3(x_1,x_2,x_3)\\;=\\;\\frac13.\n\\]\n\n2.  **Induction step.**  Fix $n\\ge4$.  If \\emph{all} $x_i>0$, one again finds by symmetry (or by writing down the Lagrange\u2010multiplier equations and using the cyclic symmetry) that the only interior critical point is \n\\[\nx_1=\\cdots=x_n=\\frac1n,\n\\]\ngiving\n\\[\nS_n\\Bigl(\\tfrac1n,\\dots,\\tfrac1n\\Bigr)\n=\\;n\\;\\frac{(1/n)^2}{1-0}\n=\\frac1n\n\\;\\le\\;\\frac13\n\\quad(n\\ge3).\n\\]\nOn the other hand, if we approach the boundary by letting, say, $x_k\\to0$, then the two summands\n\\[\n\\frac{x_{k-1}x_k}{1-(x_{k-1}-x_k)^2}\n\\quad\\text{and}\\quad\n\\frac{x_kx_{k+1}}{1-(x_k-x_{k+1})^2}\n\\]\ntend to $0$, and the remaining sum becomes exactly\n\\[\nS_{n-1}\\bigl(x_1,\\dots,x_{k-1},x_{k+1},\\dots,x_n\\bigr)\n\\]\nwith total mass\n\\[\nx_1+\\cdots+x_{k-1}+x_{k+1}+\\cdots+x_n\n\\;=\\;1.\n\\]\nHence\n\\[\n\\sup_{x_i>0,\\;\\sum x_i=1}S_n(x)\n\\;=\\;\\max\\!\n\\Bigl\\{\\underbrace{\\tfrac1n}_{\\le1/3},\\;\n\\sup_{x_i>0,\\;\\sum x_i=1}S_{n-1}(x)\\Bigr\\}\n\\;=\\;\\sup_{x>0,\\;\\sum x=1}S_{n-1}(x).\n\\]\nBy induction down to $n=3$ we conclude\n\\[\n\\sup_{x_i>0,\\;\\sum x_i=1}S_n(x_1,\\dots,x_n)\n\\;=\\;\\sup_{x_1+x_2+x_3=1}S_3(x_1,x_2,x_3)\n\\;=\\;\\frac13.\n\\]\nThis completes the proof.", "**Solution.**  \nLet \\(n\\) be an odd integer and set  \n\\[\nk=\\frac{n-1}{2}\\,.\n\\]  \nWe will show that if \\(1<m<n-2\\) and \\(\\gcd(m,n)=\\gcd(m+1,n)=1\\), then there is some integer \\(b\\) with \\(1\\le b\\le k\\) for which the open interval  \n\\[\n\\Bigl(b\\frac m n,\\;b\\frac{m+1}n\\Bigr)\n\\]  \ncontains an integer.\n\n---\n\n**Step 1:  Rewriting the \u201ccontains an integer\u201d condition.**  \nFor a real interval of length less than 1,  \n\\[\n\\Bigl(u,v\\Bigr)\\quad(v-u<1)\n\\]\ncontains an integer if and only if its fractional\u2010part end\u2010points \u201ccross\u201d an integer.  Concretely, write\n\\[\nu=\\lfloor u\\rfloor+\\{u\\},\\quad v=\\lfloor v\\rfloor+\\{v\\}, \n\\]\nwith \\(0\\le\\{\\,\\cdot\\,\\}<1\\).  Then \\((u,v)\\) contains an integer if and only if\n\\[\n\\lfloor v\\rfloor-\\lfloor u\\rfloor=1\n\\quad\\Longleftrightarrow\\quad\n\\{v\\}<\\{u\\}.\n\\]\n  \nApply this to \n\\[\nu=b\\,\\frac m n,\\quad v=b\\,\\frac{m+1}n.\n\\]  \nSince \\(v-u=b/n<\\tfrac12<1\\), the interval \\(\\bigl(bm/n,\\;b(m+1)/n\\bigr)\\) contains an integer precisely when\n\\[\n\\{\\,b\\,(m+1)/n\\}\\;<\\;\\{\\,b\\,m/n\\}.\n\\]\n\n---\n\n**Step 2:  Expressing the fractional parts.**  \nSet\n\\[\n\\alpha_b=\\{\\,b\\,m/n\\},\\qquad\n\\beta_b=\\{\\,b\\,(m+1)/n\\}.\n\\]\nThen\n\\[\n\\beta_b=\\{\\,b\\,m/n+b/n\\}\n=\\begin{cases}\n\\alpha_b+\\dfrac b n,&\\alpha_b<1-\\dfrac b n,\\\\[6pt]\n\\alpha_b+\\dfrac b n-1,&\\alpha_b\\ge1-\\dfrac b n.\n\\end{cases}\n\\]\nHence\n\\[\n\\beta_b<\\alpha_b\n\\quad\\Longleftrightarrow\\quad\n\\alpha_b\\ge1-\\frac b n.\n\\]\nThus our goal is to show:\n\n\u2003**Claim.**  If \\(1<m<n-2\\) and \\(\\gcd(m,n)=\\gcd(m+1,n)=1\\), then there exists \\(b\\in\\{1,2,\\dots,k\\}\\) with\n\\[\n\\{\\,b\\,m/n\\}\\;\\ge\\;1-\\frac b n.\n\\]\n\n---\n\n**Step 3:  Proof by contradiction.**  \nSuppose, to the contrary, that\n\\[\n\\{\\,b\\,m/n\\}<1-\\frac b n\n\\quad\\text{for all }1\\le b\\le k.\n\\]\nThen for each such \\(b\\) there is **no** wrap\u2010around in adding \\(b/n\\), so\n\\[\n\\beta_b=\\alpha_b+\\frac b n\n\\quad\\Longrightarrow\\quad\n\\{\\,b\\,(m+1)/n\\}\n=\\{\\,b\\,m/n\\}+\\frac b n.\n\\]\nEquivalently, define the two integer\u2010valued remainders\n\\[\nx_b\\;=\\;b\\,m\\pmod n\\;=\\;n\\,\\alpha_b,\n\\qquad\ny_b\\;=\\;b\\,(m+1)\\pmod n\\;=\\;n\\,\\beta_b.\n\\]\nUnder our \u201cno wrap\u201d assumption one checks\n\\[\ny_b\\;=\\;x_b\\;+\\;b,\n\\]\nand moreover \\(1\\le x_b< n\\) and \\(1\\le y_b< n\\).  Because \\(\\gcd(m,n)=1\\), the residues \\(x_1,\\dots,x_k\\) are all distinct, and likewise \\(y_1,\\dots,y_k\\) are all distinct.  Also \\(x_b\\neq y_b\\) since \\(b>0\\).  Thus altogether the \\(2k=(n-1)\\) numbers\n\\[\n\\{\\,x_1,\\dots,x_k\\}\\;\\cup\\;\\{\\,y_1,\\dots,y_k\\}\n\\]\nare \\(n-1\\) distinct nonzero residues modulo \\(n\\).  Hence they exhaust\n\\(\\{1,2,\\dots,n-1\\}\\).  \n\nSumming over all of them gives\n\\[\n\\sum_{b=1}^k x_b\\;+\\;\\sum_{b=1}^k y_b\n\\;=\\;1+2+\\cdots+(n-1)\\;=\\;\\frac{n(n-1)}2.\n\\]\nBut \\(y_b=x_b+b\\), so\n\\[\n2\\sum_{b=1}^k x_b\\;+\\;\\sum_{b=1}^k b\n\\;=\\;\\frac{n(n-1)}2.\n\\]\nSince \\(\\sum_{b=1}^k b=k(k+1)/2\\) and \\(k=(n-1)/2\\), this becomes\n\\[\n2\\sum_{b=1}^k x_b\\;+\\;\\frac{(n-1)(n+1)}8\n\\;=\\;\\frac{n(n-1)}2.\n\\]\nMultiply through by 8 to clear denominators:\n\\[\n16\\sum_{b=1}^k x_b\\;+\\;(n-1)(n+1)\n\\;=\\;4n(n-1).\n\\]\nHence\n\\[\n16\\sum_{b=1}^k x_b\n\\;=\\;4n(n-1)\\;-\\;(n^2-1)\n\\;=\\;3n^2-4n+1.\n\\]\nThe left side is divisible by 16, so the right side must be too:\n\\[\n3n^2-4n+1\\;\\equiv\\;0\\pmod{16}.\n\\]\nBut for odd \\(n\\) one has \\(n^2\\equiv1\\pmod8\\), so\n\\[\n3n^2-4n+1\\;\\equiv\\;3\\cdot1+1\\;=\\;4\n\\pmod8,\n\\]\nwhich is not divisible by 8, let alone 16.  This contradiction shows our assumption fails.  \n\nTherefore **there must** be some \\(b\\) with\n\\[\n\\{\\,b\\,m/n\\}\\;\\ge\\;1-\\frac b n,\n\\]\nwhich exactly means\n\\[\n\\{\\,b\\,(m+1)/n\\}\\;<\\;\\{\\,b\\,m/n\\},\n\\]\nand hence the interval \\(\\bigl(bm/n,\\;b(m+1)/n\\bigr)\\) contains an integer.\n\n---\n\n**Step 4:  The excluded cases.**  \nOne checks directly that if \\(m=1\\) or \\(m=n-2\\) then for every \\(1\\le b\\le k\\) the interval \\(\\bigl(bm/n,b(m+1)/n\\bigr)\\) has length \\(b/n<1\\) but never crosses an integer.  Thus the two exceptions \\(m=1\\) and \\(m=n-2\\) are exactly the cases in which **no** such \\(b\\) exists.\n\nThis completes the proof.  \u220e"], "ug": ["Outline of the proof:\n\n1.  Show that \\(a_n\\to0\\).  In fact one shows by induction that \\(0<a_{n+1}<a_n\\) and hence \\(a_n\\) is a positive decreasing sequence, bounded below by \\(0\\), so it converges to some \\(\\ell\\ge0\\).  But if \\(\\ell>0\\) then for large \\(n\\) the decrement\n\\[\na_n -a_{n+1}\n=\\frac1{n+1}\\sin(a_n)\n\\]\nwould be on the order of a fixed positive number divided by \\(n\\), and the tail sum of such decrements would diverge, contradicting boundedness of \\(a_n\\).  Hence \\(\\ell=0\\).\n\n2.  Introduce the half\u2010angle variable\n\\[\nt_n=\\tan\\bigl(\\tfrac12\\,a_n\\bigr).\n\\]\nSince \\(a_n\\to0\\), also \\(t_n\\to0\\).  One checks the exact half\u2010angle formulas\n\\[\na_n=2\\arctan t_n,\n\\quad\n\\sin(a_n)=\\frac{2\\,t_n}{1+t_n^2}\\,,\n\\]\nand then rewrites the recurrence\n\\[\na_{n+1}\n=a_n-\\frac1{n+1}\\sin(a_n)\n\\;\\Longrightarrow\\;\n\\frac{a_{n+1}}2\n=\\frac{a_n}2-\\frac1{2(n+1)}\\sin(a_n)\n\\;\\Longrightarrow\\;\nt_{n+1}\n=\\tan\\Bigl(\\frac{a_n}2-\\frac{\\sin(a_n)}{2(n+1)}\\Bigr).\n\\]\nSince \\(\\sin(a_n)/(2(n+1))\\) is small, one uses the expansion\n\\[\n\\tan\\bigl(A-B\\bigr)\n=\\tan A\\,-\\,B\\bigl(1+\\tan^2A\\bigr)+O(B^2),\n\\]\nwith \\(A=\\tfrac12a_n\\), \\(B=\\tfrac{\\sin(a_n)}{2(n+1)}\\).  A short computation shows\n\\[\nt_{n+1}\n=\\,t_n\\;-\\;\\frac{t_n}{\\,n+1\\,}\n\\;+\\;O\\!\\bigl(n^{-3}\\bigr).\n\\]\n\n3.  Define\n\\[\nb_n=n\\,t_n.\n\\]\nThen\n\\[\nb_{n+1}\n=(n+1)\\,t_{n+1}\n=(n+1)\\Bigl[t_n\\bigl(1-\\tfrac1{n+1}\\bigr)+O(n^{-3})\\Bigr]\n=n\\,t_n+O(n^{-2})\n=b_n+O(n^{-2}).\n\\]\nSince \\(\\sum_{n=1}^\\infty O(n^{-2})\\) converges, the \u201cerror\u2010corridor\u201d forces \\((b_n)\\) to be a Cauchy (hence convergent) sequence.  Call its limit \\(L\\).\n\n4.  Finally, from \\(a_n=2\\,t_n+O(t_n^3)\\) and \\(t_n= b_n/n\\) one gets\n\\[\nn\\,a_n\n=2\\,n\\,t_n+O(n\\,t_n^3)\n=2\\,b_n+O(n^{-2})\n\\;\\longrightarrow\\;2L.\n\\]\nThus \\(\\lim_{n\\to\\infty}n\\,a_n\\) exists (and equals \\(2L\\)).", "Define y\u2099 = 1/(x\u2099)\u00b2.  From the recurrence\n\n  x\u2099\u208a\u2081\u00b2  =  2\u2009x\u2099\u00b2/(x\u2099\u00b2 +2)\n\nwe get\n\n  1/x\u2099\u208a\u2081\u00b2  =  (x\u2099\u00b2 +2)/(2\u2009x\u2099\u00b2)\n           =  1/(2)  +  1/(x\u2099)\u00b2\n\ni.e.  \n  y\u2099\u208a\u2081 = y\u2099 + \u00bd.  \n\nSince y\u2081 = 1, this telescopes to\n\n  y\u2099  =  1 + (n\u22121)\u00b7\u00bd  =  (n+1)/2.\n\nHence\n\n  x\u2099\u00b2  =  2/(n+1),\n  x\u2099    =  \u221a[2/(n+1)].\n\nWe now examine\n\n  A\u2099  :=  n\u2009(x\u2099 \u2212 ln(1 + x\u2099))\n      =  n\u2009(\u221a[2/(n+1)]  \u2212  ln[1 + \u221a(2/(n+1))]).\n\nAs n\u2192\u221e, set \u03b5\u2099 = \u221a[2/(n+1)].  Then \u03b5\u2099 \u2192 0 and\n\n   ln(1+\u03b5\u2099) = \u03b5\u2099 \u2212 \u03b5\u2099\u00b2/2 + O(\u03b5\u2099\u00b3).\n\nHence\n\n   x\u2099 \u2212 ln(1+x\u2099)\n   = \u03b5\u2099 \u2212 (\u03b5\u2099 \u2212 \u03b5\u2099\u00b2/2 + O(\u03b5\u2099\u00b3))\n   = \u03b5\u2099\u00b2/2 + O(\u03b5\u2099\u00b3).\n\nSince \u03b5\u2099\u00b2 = 2/(n+1) and \u03b5\u2099\u00b3 = O(n^(\u22123/2)), we get\n\n   A\u2099\n = n\u2009\u00b7(2/(n+1))/2   +   n\u00b7O(n^(\u22123/2))\n = n\u00b7(1/(n+1))     +   O(n^(\u22121/2))\n = 1  \u2212 1/(n+1)    +   O(n^(\u22121/2))\n \u2192 1.\n\nTherefore the sequence A\u2099 converges, and its limit is 1. In particular,\n\n   lim\u2099\u2192\u221e n\u2009(x\u2099 \u2212 ln(1 + x\u2099))  =  1,\n\nso the limit exists.", "**Solution Sketch**\n\nWe set\u2003d\u2099 = x\u2099 \u2013 f(x\u2099).  Notice first that from the iteration\n$$\nx_{n+1} \\;=\\;\\tfrac12\\bigl(x_n + f(x_n)\\bigr)\n$$\nwe have\n$$\nx_{n+1}-x_n \\;=\\;\\tfrac12\\bigl(f(x_n)-x_n\\bigr)\\;=\\;-\\,\\tfrac12\\,d_n\n\\quad\\Longrightarrow\\quad\n|\\,x_{n+1}-x_n| \\;=\\;\\tfrac12\\,|d_n|. \n\\tag{1}\n$$\n\nOn the other hand one checks by the non\u2010expansiveness of f (i.e.\\ $|f(u)-f(v)|\\le|u-v|$) that\n$$\n\\begin{aligned}\nd_{n+1}\n&=x_{n+1}-f(x_{n+1})\n=\\tfrac12\\bigl(x_n+f(x_n)\\bigr)\\;-\\;f\\!\\bigl(x_{n+1}\\bigr)\\\\\n&=\\tfrac12\\Bigl[\\,(x_n-f(x_n))\\;+\\;\\bigl(f(x_n)-f(x_{n+1})\\bigr)\\Bigr]\n\\end{aligned}\n$$\nand hence\n$$\n|d_{n+1}| \n\\;\\le\\;\\tfrac12\\bigl(\\,|d_n|+|f(x_n)-f(x_{n+1})|\\,\\bigr)\n\\;\\le\\;\\tfrac12\\bigl(|d_n|+|x_n-x_{n+1}|\\bigr).\n$$\nUsing (1) once more,\n$$\n|d_{n+1}|\\;\\le\\;\\tfrac12\\,|d_n|\\;+\\;\\tfrac12\\,|d_n|\n\\;=\\;|d_n|.\n$$\nThus the sequence $|d_n|=|x_n-f(x_n)|$ is nonincreasing, so it has a (finite) limit\n$$\nL=\\lim_{n\\to\\infty}|d_n|\\ge0.\n$$\n\n---\n\n1. We claim in fact $L=0$.  Suppose for contradiction that $L>0$.  Then for all large $n$ we have $|d_n|\\ge L/2>0$, so from (1)\n$$\n|x_{n+1}-x_n|\\;=\\;\\tfrac12\\,|d_n|\\;\\ge\\;\\tfrac{L}{4},\n$$\nand moreover beyond some index the signs of $d_n$ cannot keep flipping (otherwise the total \u201cwiggle\u2010length\u201d $\\sum|x_{k+1}-x_k|$ would diverge, but $x_k\\in[a,b]$ is bounded).  Hence eventually $x_{n+1}-x_n$ has a fixed nonzero sign, so $x_n$ is strictly monotone with a uniform step\u2010size $\\ge L/4$, which forces $x_n$ out of the bounded interval $[a,b]$.  This contradiction shows necessarily $L=0$.\n\n2. Once $L=0$, we have $|d_n|\\to0$, hence $|x_{n+1}-x_n|=\\tfrac12|d_n|\\to0$.  Moreover from step 1 there is some $N$ so that for $n\\ge N$ the sign of $x_{n+1}-x_n$ is constant (no more sign\u2010flips), i.e.\\ $(x_n)$ is eventually monotone.  A bounded, eventually monotone real sequence converges.  Therefore $(x_n)$ converges.\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u220e", "Here is a convenient \u201easymptotic\u2010difference\u2019\u2019 proof.  We first show that both \\(x_n\\) and \\(y_n\\) go to 0 at the rate\n\\[\nx_n\\sim\\sqrt{\\frac{3}{n}},\\quad y_n\\sim\\sqrt{\\frac{3}{n}},\n\\]\nand then conclude that their ratio tends to 1.\n\n1) Asymptotics of \\(x_n\\).  Since \\(x_{n+1}=\\sin x_n\\), for small \\(t\\) we have the Taylor expansion\n\\[\n\\sin t \\;=\\; t \\;-\\;\\frac{t^3}{6}+O(t^5)\\,.\n\\]\nHence\n\\[\n\\frac1{\\sin^2 t}\\;=\\;\\frac1{\\bigl(t-\\tfrac{t^3}{6}+O(t^5)\\bigr)^2}\n\\;=\\;\\frac1{t^2}\\;\\frac1{\\bigl(1-\\tfrac{t^2}{6}+O(t^4)\\bigr)^2}\n\\;=\\;\\frac1{t^2}\\Bigl(1+\\frac{t^2}{3}+O(t^4)\\Bigr).\n\\]\nIn particular, setting\n\\[\na_n\\;=\\;\\frac1{x_n^2},\n\\]\nwe get\n\\[\na_{n+1}\n\\;=\\;\\frac1{x_{n+1}^2}\n\\;=\\;\\frac1{\\sin^2 x_n}\n\\;=\\;a_n\\Bigl(1+\\tfrac{x_n^2}{3}+O(x_n^4)\\Bigr)\n\\,.\n\\]\nHence\n\\[\na_{n+1}-a_n\n\\;=\\;\\frac{a_n\\,x_n^2}{3}+O(a_n\\,x_n^4)\n\\;=\\;\\frac1{3}+O(x_n^2).\n\\]\nBut \\(x_n\\to0\\), so \\(O(x_n^2)\\to0\\).  Thus\n\\[\na_{n+1}-a_n\\;\\longrightarrow\\;\\tfrac13,\n\\]\nand by summation\n\\[\na_n\n\\;=\\;\\frac n3+O(1).\n\\]\nEquivalently\n\\[\nx_n^2\n\\;=\\;\\frac1{a_n}\n\\;=\\;\\frac{3}{\\,n+O(1)\\,}\n\\;\\sim\\;\\frac{3}{n},\n\\]\nso\n\\[\nx_n\\sim\\sqrt{\\frac3n}.\n\\]\nExactly the same argument applied to \\(y_n\\) gives\n\\[\ny_n\\sim\\sqrt{\\frac3n}.\n\\]\n\n2) Ratio \\(\\displaystyle x_n/y_n\\to1\\).  From the two asymptotics\n\\[\nx_n\\sim\\sqrt{\\frac3n},\\qquad y_n\\sim\\sqrt{\\frac3n},\n\\]\nit is immediate that\n\\[\n\\frac{x_n}{y_n}\\;\\longrightarrow\\;1.\n\\]\n\nThat completes the proof.", "Here is a proof by \u201csubtracting off the linear part\u2019\u2019 and then using a dyadic\u2010telescoping argument.  Set   \n  \n    c = A,  \n    g(x) = f(x) \u2212 c\u2009x.  \n  \nSince f is continuous at 0 we have g(0)=f(0).  Moreover by hypothesis  \n   \n    lim\u2093\u21920  [\u2009f(2x) \u2212 f(x)\u2009]/x  = A  \n  \u21d2 lim\u2093\u21920  [\u2009g(2x) \u2212 g(x)\u2009]/x  \n           = lim\u2093\u21920 [\u2009f(2x) \u2212 c\u00b72x \u2212 (f(x) \u2212 c\u00b7x)\u2009]/x  \n           = lim\u2093\u21920 [\u2009f(2x) \u2212 f(x)\u2009]/x  \u2212 c  \n           = A \u2212 c  = 0.  \n  \nThus for every \u03b5>0 there is \u03b4>0 so that whenever |t|<\u03b4  \n\n    |[g(2t) \u2212 g(t)]/t|  < \u03b5,  \n  i.e.  \n    |g(2t) \u2212 g(t)|  < \u03b5\u2009|t|.                            (\u22c6)  \n  \nWe will show from (\u22c6) that g(x)=o(x), i.e. g(x)/x\u21920 as x\u21920.  Once that is done, it follows that   \n   \n    f(x)/x = c + g(x)/x \u2192 c  as x\u21920,  \n   \nso f is differentiable at 0 with f\u2032(0)=c=A.  \n\n\u2014 Proof that g(x)=o(x) \u2014  \n\nFix an x with |x|<\u03b4/2, and choose an integer n so large that    \n  \n    y = x/2\u207f   still satisfies   |y|<\u03b4.  \n  \nThen x = 2\u207f\u2009y, and we telescope  \n\n    g(x) \u2212 g(y)  \n      = g(2\u00b72\u207f\u207b\u00b9y) \u2212 g(2\u207f\u207b\u00b9y)  \n       + g(2\u207f\u207b\u00b9y) \u2212 g(2\u207f\u207b\u00b2y)  \n       + \u22ef  \n       + g(2y) \u2212 g(y).  \n  \nThere are n terms, and each term is of the form g(2t)\u2212g(t) with |t|\u2264|x|/2<\u03b4.  By (\u22c6), each such difference has absolute value <\u03b5|t|.  Hence  \n\n    |g(x) \u2212 g(y)|  \n      \u2264 \u2211_{j=0 to n\u22121} |g(2\u00b72\u02b2y) \u2212 g(2\u02b2y)|  \n      <  \u2211_{j=0 to n\u22121} \u03b5\u00b7|2\u02b2y|  \n      = \u03b5\u00b7|y|\u00b7(1 + 2 + \u22ef + 2\u207f\u207b\u00b9)  \n      = \u03b5\u00b7|y|\u00b7(2\u207f \u2212 1)  \n      = \u03b5\u00b7|x|\u00b7(1 \u2212 2^{\u2212n})  \n      < \u03b5\u00b7|x|.  \n  \nBut |g(y)|\u2192|g(0)|=0 as y\u21920, and y\u21920 when n\u2192\u221e.  Thus for this same x,  \n\n    |g(x)| \u2264 |g(y)| + |g(x)\u2212g(y)|  \n           < |g(y)| + \u03b5|x|.  \n\nNow let n\u2192\u221e (so that y\u21920) to make |g(y)| arbitrarily small, and finally let \u03b5\u21920.  We conclude  \n\n    g(x)/x \u2192 0  as x\u21920.  \n  \nTherefore  \n\n    f(x)/x  =  c + [g(x)/x]  \u2192  c = A,  \n\ni.e. f\u2032(0) exists and equals A. Q.E.D.", "Here is a concrete counter\u2010example.  We will build a continuous function  \n\\(f\\colon[0,\\infty)\\to\\R\\) which satisfies  \n  \n  (1)  For every \\(x\\in[0,1]\\),  \\(\\displaystyle\\lim_{n\\to\\infty}f(x+n)=0,\\)  \nbut  \n\n  (2)  \\(\\displaystyle\\lim_{x\\to\\infty}f(x)\\) does not exist.  \n\nThe idea is to put a small triangular \u201cspike\u2019\u2019 of height 1 over each interval centered at a distinct fractional point in \\([0,1]\\), and make the spikes narrower and narrower so that any *fixed* fractional part \\(x\\) eventually misses all spikes.\n\n---\n\n1)  **Enumeration of spike\u2010centers.**  \nPick a sequence of *distinct* points \n\\[\n   r_{1},r_{2},r_{3},\\dots \n\\]\nin \\([0,1]\\).  (For instance you could take any enumeration of the rationals in \\([0,1]\\), but it is crucial that no two \\(r_{k}\\) coincide.)\n\n2)  **Widths of the spikes.**  \nLet\n\\[\n   w_k = 2^{-(k+2)}.\n\\]\nThen \\(w_{k}\\to0\\), and in particular \\(w_{k}<\\tfrac12\\) for all \\(k\\).\n\n3)  **Definition of \\(f\\).**  \nWe define \\(f\\) piecewise, \u201cone spike\u2019\u2019 per integer interval \\([k,k+1]\\).  For each integer \\(k\\ge1\\) set\n\\[\n   a_k = k + r_k,\n   \\qquad\n   I_k = \\bigl[a_k - w_k,\\;a_k + w_k\\bigr].\n\\]\nOn each such little interval \\(I_k\\), let \\(f\\) be the tent (triangle) function of height 1 and base width \\(2w_k\\):  \n\\[\n   f(x) \\;=\\;\n   \\begin{cases}\n     1 - \\dfrac{|\\,x - a_k\\,|}{w_k}, \n        & x\\in[a_k-w_k,a_k+w_k],\\\\\n     0,&\\text{otherwise}.\n   \\end{cases}\n\\]\nIt is immediate that \\(f\\) is continuous, nonnegative, and  \n\\[\n   \\sup_x f(x)=1,\\quad\n   \\inf_x f(x)=0.\n\\]\n\n4)  **Check condition (1).**  \nFix any \\(x\\in[0,1]\\).  We must show \\(\\displaystyle\\lim_{n\\to\\infty}f(x+n)=0\\).  \nBut \\(f(x+n)\\) can only be nonzero if \\(x+n\\) falls into one of the spike\u2010intervals \\(I_k\\).  That means\n\\[\n   x+n\\in [\\,k+r_k - w_k,\\;k+r_k + w_k\\,].\n\\]\nEquivalently\n\\[\n   n - k \\in [\\,r_k - w_k - x,\\;r_k + w_k - x\\,].\n\\]\nFor a *fixed* \\(x\\), since the \\(r_k\\) are all distinct, there is at most one integer \\(k\\) for which \\(r_k=x\\).  And even if \\(r_k=x\\) for some \\(k\\), that produces at most one integer \\(n\\) with \\(x+n=k+r_k\\).  More to the point, because the widths \\(w_k\\) shrink to 0, for *each* \\(k\\) the set of \\(x+n\\) that land in the \\(k\\)\u2010th spike is finite.  Hence for large \\(n\\), \\(x+n\\) lies in no spike, so \\(f(x+n)=0\\).  Thus\n\\[\n   \\lim_{n\\to\\infty}f(x+n)=0,\n   \\quad\\forall\\,x\\in[0,1].\n\\]\n\n5)  **Check that \\(\\lim_{x\\to\\infty}f(x)\\) fails to exist.**  \nOn the one hand, along the subsequence \\(x_k = a_k = k+r_k\\) we have\n\\[\n   f(x_k) \\;=\\; 1.\n\\]\nOn the other hand, between spikes \\(f\\) is identically \\(0\\).  Hence as \\(x\\to\\infty\\) the values of \\(f(x)\\) oscillate between near 0 and exactly 1, so no single limit exists.\n\n---\n\nConclusion.  This explicit \\(f\\) is continuous, it satisfies\n\\[\n   \\lim_{n\\to\\infty}f(x+n)=0\n   \\quad(\\forall\\,x\\in[0,1]),\n\\]\nyet\n\\[\n   \\lim_{x\\to\\infty}f(x)\n\\]\ndoes not exist.  That completes the counter\u2010example.", "Define the auxiliary function  \n\u2003g(x) = f(x + 1/n) \u2212 f(x),  \nviewed on the interval [0, 1\u22121/n].  Since f is continuous on [0,1], g is continuous on [0, 1\u22121/n].  We will show that g has a zero in [0,1\u22121/n], which is exactly a point \u03be with  \n\u2003f(\u03be+1/n) \u2212 f(\u03be) = 0  \n\u21d4 f(\u03be+1/n) = f(\u03be).\n\nObserve the two endpoint values of g:\n\n1.  g(0) = f(1/n) \u2212 f(0).  \n2.  g(1\u22121/n) = f(1) \u2212 f(1\u22121/n).  \n\u2003But f(1) = f(0) by hypothesis, so  \n\u2003g(1\u22121/n) = f(0) \u2212 f(1\u22121/n) = \u2212[\u2009f(1\u22121/n) \u2212 f(0)\u2009].\n\nThus  \n\u2003g(1\u22121/n) = \u2212[\u2009f(1\u22121/n) \u2212 f(0)\u2009].  \n\nThere are three cases:\n\n\u2022  If g(0) = 0, then f(1/n) = f(0) and we may take \u03be = 0.  \n\u2022  If g(1\u22121/n) = 0, then f(1) = f(1\u22121/n), and we may take \u03be = 1\u22121/n.  \n\u2022  Otherwise g(0) \u2260 0 and g(1\u22121/n) \u2260 0.  But since  \n\u2003g(1\u22121/n) = \u2212[\u2009f(1\u22121/n) \u2212 f(0)\u2009],  \nthe numbers g(0) and g(1\u22121/n) have opposite signs.  By the Intermediate Value Theorem, g must have a zero at some point \u03be in the open interval (0, 1\u22121/n).  At that \u03be one has g(\u03be)=0, i.e. f(\u03be+1/n)=f(\u03be).\n\nIn every case we have found \u03be\u2208[0,1] (in fact \u03be\u2208[0,1\u22121/n]) with f(\u03be+1/n)=f(\u03be), as required.", "**Solution.**  We will show that for large \\(x\\), the denominator \\(f(x)\\) stays away from 0 and both numerator and denominator are Lipschitz there, so their quotient is Lipschitz (hence uniformly continuous).  \n\n1.  **\\(f\\) is bi\u2010Lipschitz \u21d2 \\(|f(x)|\\to\\infty\\) as \\(x\\to\\infty\\).**  \n   From  \n   \\[\n     l\\,|x-1|\\;\\le\\;|f(x)-f(1)|\\;\\le\\;L\\,|x-1|,\n   \\]  \n   if \\(f\\) is increasing then \n   \\[\n     f(x)\\;\\ge\\;f(1)+l\\,(x-1)\\;\\longrightarrow+\\infty,\n   \\] \n   and if \\(f\\) is decreasing then \n   \\[\n     f(x)\\;\\le\\;f(1)-l\\,(x-1)\\;\\longrightarrow-\\infty.\n   \\] \n   In either case \\(|f(x)|\\to\\infty\\).  Hence there is some  \n   \\[\n     X\\ge1\\quad\\text{so that}\\quad |f(x)|\\ge M>0\n     \\quad\\forall\\,x\\ge X,\n   \\]  \n   for example take \\(M=1\\) and \\(X\\) large enough that \\(|f(x)|\\ge1\\) for \\(x\\ge X\\).  \n\n2.  **The numerator \\(h(x)=x+e^{-x}\\) is Lipschitz.**  \n   Indeed  \n   \\[\n     |h(x_2)-h(x_1)| \n     = |(x_2-x_1)+(e^{-x_2}-e^{-x_1})|\n     \\le |x_2-x_1| + |e^{-x_2}-e^{-x_1}|\n     \\le |x_2-x_1| + |x_2-x_1|\n     =2\\,|x_2-x_1|.\n   \\]  \n   So \\(h\\) is Lipschitz on \\([1,\\infty)\\), hence on \\([X,\\infty)\\).  \n\n3.  **On \\([X,\\infty)\\), \\(f\\) is also Lipschitz from the hypothesis.**  \n\n4.  **A quotient of Lipschitz functions whose denominator is bounded away from 0 is Lipschitz.**  \n   Fix \\(x_1,x_2\\ge X\\).  Then\n   \\[\n     g(x)=\\frac{h(x)}{f(x)},\n   \\]\n   satisfies the standard estimate\n   \\[\n     \\Bigl|\\frac{h(x_2)}{f(x_2)}-\\frac{h(x_1)}{f(x_1)}\\Bigr|\n     \\;=\\;\n     \\frac{\\bigl|\\,h(x_2)f(x_1)-h(x_1)f(x_2)\\bigr|}{|f(x_2)f(x_1)|}\n   \\]\n   \\[\n     =\\frac{\\bigl|\\,h(x_2)\\bigl[f(x_1)-f(x_2)\\bigr]\n       +\\bigl[h(x_2)-h(x_1)\\bigr]f(x_2)\\bigr|}{|f(x_2)f(x_1)|}\n     \\;\\le\\;\n     \\frac{|h(x_2)|\\,L\\,|x_2-x_1| \\;+\\; 2\\,|x_2-x_1|\\;|f(x_2)|}\n          {M^2}.\n   \\]\n   Since for \\(x\\ge X\\) we have \\(|h(x)|\\le x+1\\le X+1\\) and \\(|f(x)|\\le L\\,(x-1)+|f(1)|\\) (hence is bounded on \\([X,X+1]\\)) but in any case bounded by some constant \\(B\\), we get\n   \\[\n     |g(x_2)-g(x_1)|\n     \\;\\le\\;\n     \\Bigl(\\frac{(X+1)L}{M^2}+\\frac{2B}{M^2}\\Bigr)\\,|x_2-x_1|\n     =:K\\,|x_2-x_1|.\n   \\]\n   Thus \\(g\\) is Lipschitz on \\([X,\\infty)\\), and in particular uniformly continuous there.  \n\n\u220e", "Here is a self\u2010contained contradiction proof in two cases, depending on whether inf\u2009f is strictly positive or is zero.\n\nAssume for contradiction that f\u2208C\u00b9(\u211d), f(x)>0 for all x, and  \n\u2003\u2003f\u2032(x)=f(f(x)).  \n\nSince f\u2032(x)=f(f(x))>0, f is strictly increasing.  Therefore both  \n\u2003L := inf_{x\u2208\u211d} f(x)   and   M := sup_{x\u2208\u211d} f(x)  \nexist in [0,+\u221e] \u222a {+\u221e}.  Clearly M must be +\u221e (otherwise a bounded increasing function with bounded derivative would have lim\u2009f(x)=finite as x\u2192\u221e but then f\u2032(x)=f(f(x)) would stay bounded away from zero and drive f\u2192\u221e linearly\u2014a contradiction).  So the only questions are whether L>0 or L=0.\n\n---\n\nCase 1:  L>0.  \nThen for every x, f(x)\u2265L>0, so  \n\u2003f\u2032(x) = f(f(x)) \u2265 f(L) > 0.  \nHence f\u2032(x) is bounded below by the positive constant f(L).  Integrating this inequality toward \u2212\u221e shows that f(x)\u2192\u2212\u221e as x\u2192\u2212\u221e, which contradicts f(x)>0.  Thus the hypothesis L>0 is impossible.\n\n---\n\nCase 2:  L=0.  \nSince f is continuous and inf\u2009f=0 but f never actually attains 0 (it is always positive), there must be a sequence x\u2099\u2192\u2212\u221e with f(x\u2099)\u21920.  Now look near 0 in the range of f.  We know f(0)>0; say a := f(0)>0.  By continuity of f at y=0 there is some \u03b4>0 so that\n\n\u2003|y\u22120|<\u03b4 \u2003\u21d2\u2003 |f(y)\u2212a|<a/2 \u2003\u21d2\u2003 f(y)>a/2.\n\nIn particular for every y with 0\u2264y<\u03b4 we have f(y)>a/2.  But since inf\u2009f=0 there is some X so large negative that 0 < f(X)<\u03b4.  Then\n\n\u2003f\u2032(X) = f(f(X)) > a/2.\n\nBy continuity of f\u2032 there is a whole interval (X\u2212\u03b5,X] on which f\u2032(x)>a/2.  Integrating backward from X to any x<X gives\n\n\u2003f(x) = f(X) \u2212 \u222b_{t=x}^X f\u2032(t)\\,dt  \u2264 f(X) \u2212 (X\u2212x)\\frac{a}{2}.\n\nAs x decreases, the right\u2013hand side becomes negative once x< X \u2212 2f(X)/a.  That would force f(x)<0, contradicting f(x)>0.  Hence inf\u2009f cannot be zero either.\n\n---\n\nSince both L>0 and L=0 lead to contradictions, no C\u00b9\u2013function f\u2009:\u2009\u211d\u2192\u211d with f>0 and f\u2032(x)=f(f(x)) can exist.", "First, rewrite the inequality in a more symmetric form.  Fix any point \\(m\\in\\Bbb R\\) and set  \n\\[\na = m - h,\\quad b = m + h\\quad(h>0).\n\\]\nThen  \n\\[\n\\frac1{b-a}\\int_a^b f(x)\\,dx\n=\\frac1{2h}\\int_{m-h}^{m+h}f(x)\\,dx,\n\\]\nand the midpoint \\(\\tfrac{a+b}2\\) is just \\(m\\).  The claim becomes:\n\n(*)  For every \\(m\\in\\Bbb R\\) and every \\(h>0\\),\n\\[\nf(m)\\;\\le\\;\\frac1{2h}\\int_{m-h}^{m+h}f(x)\\,dx\n\\]\nif and only if \\(f''(x)\\ge0\\) for all \\(x\\).\n\n---\n\nProof of \u201c\\(\\Longrightarrow\\)\u201d  (convexity \u21d2 integral inequality):\n\nIf \\(f''(x)\\ge0\\) on \\(\\Bbb R\\), then \\(f\\) is convex.  Two standard facts about convex \\(f\\) on \\([m-h,m+h]\\) are\n\n1.  The graph of \\(f\\) lies below its chord from \\(x=m-h\\) to \\(x=m+h\\).  Equivalently\n   \\[\n   f(m)\\;\\le\\;\\frac{f(m-h)+f(m+h)}2.\n   \\]\n\n2.  The trapezoidal rule under-estimates the integral:\n   \\[\n   \\int_{m-h}^{m+h}f(x)\\,dx\n   \\;\\ge\\;(2h)\\,\\frac{f(m-h)+f(m+h)}2.\n   \\]\n\nCombining (1) and (2) gives\n\\[\n\\int_{m-h}^{m+h}f(x)\\,dx\n\\;\\ge\\;2h\\;\\frac{f(m-h)+f(m+h)}2\n\\;\\ge\\;2h\\,f(m),\n\\]\nand hence\n\\[\n\\frac1{2h}\\int_{m-h}^{m+h}f(x)\\,dx\\;\\ge\\;f(m),\n\\]\nwhich is exactly (*).\n\n---\n\nProof of \u201c\\(\\Longleftarrow\\)\u201d  (integral inequality \u21d2 \\(f''\\ge0\\)):\n\nAssume (*) holds for every \\(m\\) and every \\(h>0\\).  We will show \\(f''(m)\\ge0\\).  Since \\(f\\) is \\(C^2\\), we may expand \\(f\\) about \\(x=m\\):\n\nFor \\(|t|\\) small,\n\\[\nf(m+t)\n= f(m) + f'(m)\\,t \\;+\\;\\tfrac12\\,f''(m)\\,t^2 + o(t^2).\n\\]\nHence\n\\[\n\\int_{m-h}^{m+h}f(x)\\,dx\n=\\int_{-h}^{h}\\Bigl[f(m)+f'(m)t+\\tfrac12f''(m)t^2 +o(t^2)\\Bigr]\\,dt.\n\\]\nThe linear term integrates to zero by symmetry, and \\(\\int_{-h}^h t^2\\,dt = \\tfrac{2h^3}3\\).  Thus\n\\[\n\\int_{m-h}^{m+h}f(x)\\,dx\n=2h\\,f(m)\\;+\\;\\frac12\\,f''(m)\\,\\frac{2h^3}3\\;+\\;o(h^3)\n=2h\\,f(m)\\;+\\;\\frac{h^3}{3}\\,f''(m)\\;+\\;o(h^3).\n\\]\nThe assumed inequality (*) says\n\\[\n2h\\,f(m)\\;\\le\\;\\int_{m-h}^{m+h}f(x)\\,dx\n=2h\\,f(m)\\;+\\;\\frac{h^3}{3}\\,f''(m)\\;+\\;o(h^3).\n\\]\nSubtracting \\(2h\\,f(m)\\) and then dividing by \\(h^3\\!>\\!0\\) gives\n\\[\n0\\;\\le\\;\\frac{f''(m)}3 \\;+\\;\\frac{o(h^3)}{h^3}.\n\\]\nLetting \\(h\\to0^+\\) forces \\(f''(m)\\ge0\\).  Since \\(m\\) was arbitrary, \\(f''(x)\\ge0\\) for all \\(x\\).\n\nThis completes the proof of the equivalence.", "Here is a slick way using Rolle\u2019s theorem.  Set up a new function whose secant\u2010slope being zero is exactly the statement you want.\n\nDefine \n\u2003F(x)=f(x)\u2212f\u2032(\u03be)\u00b7x. \nThen  \n\u2003F\u2032(x)=f\u2032(x)\u2212f\u2032(\u03be), \nso in particular \n\u2003F\u2032(\u03be)=0, \nand  \n\u2003F\u2033(\u03be)=f\u2033(\u03be)\u22600. \nBy the second\u2010derivative test F has a strict local extremum at x=\u03be.  For definiteness suppose f\u2033(\u03be)>0 (the case f\u2033(\u03be)<0 is identical, just replacing \u201cminimum\u2019\u2019 by \u201cmaximum\u2019\u2019 in what follows).  Then there is a \u03b4>0 so that for all x\u2208(\u03be\u2212\u03b4,\u03be+\u03b4)\\{\u03be} one has \n\u2003F(x)>F(\u03be). \n\nNow choose any number T strictly between F(\u03be) and the two endpoint values, say\n\u2003F(\u03be)<T<min{F(\u03be\u2212\u03b4),F(\u03be+\u03b4)}.\nBy the Intermediate\u2010Value Theorem there is some x\u2081\u2208(\u03be\u2212\u03b4,\u03be) with F(x\u2081)=T, and some x\u2082\u2208(\u03be,\u03be+\u03b4) with F(x\u2082)=T.  In particular\n\u2003F(x\u2082)\u2212F(x\u2081)=0\nand x\u2081<x\u2082 both lie in (a,b).  Hence\n\\[\n\\frac{F(x\u2082)\u2212F(x\u2081)}{x\u2082\u2212x\u2081}=0\\,.\n\\]\nBut\n\\[\nF(x\u2082)\u2212F(x\u2081)\n=\\bigl[f(x\u2082)\u2212f\u2032(\u03be)x\u2082\\bigr]\u2212\\bigl[f(x\u2081)\u2212f\u2032(\u03be)x\u2081\\bigr]\n=(f(x\u2082)\u2212f(x\u2081))\u2212f\u2032(\u03be)\\,(x\u2082\u2212x\u2081),\n\\]\nso\n\\[\n0=\\frac{F(x\u2082)\u2212F(x\u2081)}{x\u2082\u2212x\u2081}\n=\\frac{f(x\u2082)\u2212f(x\u2081)}{x\u2082\u2212x\u2081}-f\u2032(\u03be).\n\\]\nRearranging gives exactly\n\\[\n\\frac{f(x\u2082)\u2212f(x\u2081)}{x\u2082\u2212x\u2081}=f\u2032(\u03be),\n\\]\nas required.", "Here is a neat way to force a contradiction unless \\(M=0\\).  Suppose for contradiction that \\(M>0\\).  Since \\(f(0)=f(2)=0\\) but \\(\\max_{[0,2]}|f|=M>0\\), there is some interior point \\(x_{0}\\in(0,2)\\) at which \\(\\lvert f(x_{0})\\rvert=M\\).  We now split into two cases according to the sign of \\(f(x_{0})\\).\n\nCase 1: \\(f(x_{0})=+M\\).  \nDefine \n\\[\ng(x)=e^{-x}f(x).\n\\]\nThen \n\\[\ng(0)=e^0\\!f(0)=0,\n\\quad\ng(2)=e^{-2}f(2)=0,\n\\]\nbut\n\\[\ng(x_{0})=e^{-x_{0}}\\;f(x_{0})\n     =e^{-x_{0}}\\;M>0.\n\\]\nHence \\(g\\) attains a strict positive maximum at the interior point \\(x_{0}\\).  By the usual calculus fact, at an interior maximum we must have\n\\[\ng'(x_{0})=0.\n\\]\nBut\n\\[\ng'(x)\n=\\frac{d}{dx}\\bigl(e^{-x}f(x)\\bigr)\n=e^{-x}\\bigl(f'(x)-f(x)\\bigr),\n\\]\nso\n\\[\n0=g'(x_{0})\n=e^{-x_{0}}\\bigl(f'(x_{0})-f(x_{0})\\bigr)\n\\;\\Longrightarrow\\;\nf'(x_{0})=f(x_{0})=M.\n\\]\nOn the other hand, since \\(\\lvert f(x)\\rvert\\) has its maximum \\(M\\) at \\(x_{0}\\), the one\u2010sided derivatives of \\(\\lvert f\\rvert\\) there must vanish.  Equivalently\n\\[\n0=\\Bigl(\\lvert f(x)\\rvert\\Bigr)'_{x=x_{0}}\n=\\operatorname{sgn}\\bigl(f(x_{0})\\bigr)\\,f'(x_{0})\n=\\;+\\!1\\cdot f'(x_{0})\n\\;\\Longrightarrow\\;\nf'(x_{0})=0.\n\\]\nTogether with \\(f'(x_{0})=M\\) this forces\n\\[\nM=0,\n\\]\ncontradicting our assumption \\(M>0\\).  \n\nCase 2: \\(f(x_{0})=-M\\).  \nExactly the same argument works if you set\n\\[\nh(x)=e^{\\,x}f(x),\n\\]\nnoting \\(h(0)=h(2)=0\\) and \\(h(x_{0})=e^{x_{0}}\\bigl(-M\\bigr)<0\\), so \\(-h\\) has a positive interior maximum.  One again finds\n\\[\nf'(x_{0})=-f(x_{0})=M\n\\quad\\text{and}\\quad\nf'(x_{0})=0,\n\\]\nwhence \\(M=0\\).  \n\nIn either case the only consistent conclusion is \\(M=0\\).  This completes the proof.", "Here is a clean way to see the extra vanishing of the first\u2010order term when \\(f'(0)=f'(1)\\), and to get the advertised \\(\\tfrac1{24}\\)\u2013bound.\n\n1)  Reduction to an integral against \\(f''\\).  Let\n\\[\nI\\;=\\;\\int_{0}^{1}f(x)\\,dx \\;-\\;\\frac{f(0)+f(1)}2.\n\\]\nWrite \\(f\\) as its linear interpolant plus a remainder.  Define\n\\[\nL(x)\\;=\\;f(0)\\;+\\;\\bigl(f(1)-f(0)\\bigr)\\,x,\n\\]\nso that \\(\\int_{0}^{1}L(x)\\,dx=\\bigl(f(0)+f(1)\\bigr)/2\\).  Then\n\\[\nI \\;=\\;\\int_{0}^{1}\\bigl(f(x)-L(x)\\bigr)\\,dx.\n\\]\nSince \\(L\\) is a straight line, \\((f-L)''=f''\\).  The standard Green\u2013function formula for the \u201cerror\u2010function\u2019\u2019 \\(h(x)=f(x)-L(x)\\), with Dirichlet boundary conditions \\(h(0)=h(1)=0\\), is\n\\[\nh(x)\n=\\int_{0}^{1}G(x,t)\\,f''(t)\\,dt,\n\\]\nwhere\n\\[\nG(x,t)=\n\\begin{cases}\n\\;x\\,(1-t),&0\\le t\\le x\\le1,\\\\\n\\;t\\,(1-x),&0\\le x\\le t\\le1.\n\\end{cases}\n\\]\nHence\n\\[\nI \\;=\\;\\int_{0}^{1}h(x)\\,dx\n\\;=\\;\\int_{0}^{1}\\!\\!\\int_{0}^{1}G(x,t)\\,f''(t)\\,dt\\;dx\n\\;=\\;\\int_{0}^{1}\\Bigl(\\!\\int_{0}^{1}G(x,t)\\,dx\\Bigr)\\,f''(t)\\,dt.\n\\]\nA quick check shows\n\\[\n\\int_{0}^{1}G(x,t)\\,dx\n=\\frac{t(1-t)}2,\n\\]\nso in fact\n\\[\nI \\;=\\;\\int_{0}^{1}h(x)\\,dx\n\\;=\\;\n\\frac12\n\\int_{0}^{1}t(1-t)\\;f''(t)\\;dt.\n\\]\n\n2)  Using \\(f'(1)=f'(0)\\) to kill the \u201czero\u2010mode.\u2019\u2019  From the Fundamental Theorem,\n\\[\nf'(1)-f'(0)\\;=\\;\\int_{0}^{1}f''(t)\\,dt\\,,\n\\]\nand by hypothesis this is zero.  Hence \\(f''\\) has mean zero on \\([0,1]\\).  We may therefore subtract ANY constant \\(c\\) inside the integral against \\(f''\\), since\n\\[\n\\int_{0}^{1}c\\;\\underbrace{f''(t)}_{dt}\\;=\\;c\\,(f'(1)-f'(0))\\;=\\;0.\n\\]\nThus\n\\[\nI\n\\;=\\;\n\\frac12\n\\int_{0}^{1}t(1-t)\\,f''(t)\\,dt\n\\;=\\;\n\\frac12\n\\int_{0}^{1}\\bigl\\{\\,t(1-t)-c\\bigr\\}\\,f''(t)\\,dt\n\\]\nfor any constant \\(c\\).  Consequently\n\\[\n\\bigl|I\\bigr|\n\\;\\le\\;\n\\frac12\\;\\Bigl\\|\\;t(1-t)-c\\Bigr\\|_{L^\\infty([0,1])}\n\\;\\times\\;\\|\\,f''\\|_{L^\\infty}\n\\;\\le\\;\n\\frac12\\;\\max_{0\\le t\\le1}\\bigl|t(1-t)-c\\bigr|.\n\\]\nNow a little calculus shows that the quadratic\n\\[\nt(1-t)\\;=\\;-\\bigl(t-\\tfrac12\\bigr)^2\\;+\\;\\tfrac14\n\\]\nranges between \\(0\\) (at \\(t=0,1\\)) and \\(1/4\\) (at \\(t=\\tfrac12\\)).  If we choose\n\\[\nc\\;=\\;\\textstyle\\frac{1}{8}\\;=\\;\\frac{\\max+\\min}{2}\n\\;=\\;\\frac{0+\\tfrac14}{2},\n\\]\nthen\n\\[\n\\max_{t\\in[0,1]}\\bigl|\\,t(1-t)-c\\bigr|\n\\;=\\;\\frac14-\\frac18\n\\;=\\;\\frac1{8}.\n\\]\nHence\n\\[\n\\bigl|I\\bigr|\n\\;\\le\\;\n\\frac12\\;\\cdot\\;\\frac1{8}\n\\;=\\;\\frac1{16},\n\\]\nwhich is even better than \\(\\tfrac1{24}\\).  In particular\n\\[\n\\Bigl|\\int_{0}^{1}f(x)\\,dx-\\tfrac{f(0)+f(1)}2\\Bigr|\n\\;\\le\\;\n\\frac1{16}\n\\;<\\;\n\\frac1{24}.\n\\]\nThus the desired bound \\(\\tfrac1{24}\\) is certainly achieved.  (With a bit more care one can show the sharp constant is actually \\(1/48\\), but \\(\\tfrac1{24}\\) is already well below the classical \\(\\tfrac1{12}\\)\u2013error of the trapezoid rule.)", "**Solution.**  Define the auxiliary function  \n\u2003\u2003H(x)=f(x)\\,g''(x)\\;-\\;f''(x)\\,g(x)\\,.  \nSince g(x)\u22600 and g\u2033(x)\u22600 on [a,b], H is continuous on [a,b].  We shall show that H takes opposite signs at two interior points of (a,b), and hence by the Intermediate\u2010Value Theorem vanishes at some \u03be\u2208(a,b), which is precisely the desired  \n\u2003\u2003f(\u03be)\u2009g''(\u03be)=f''(\u03be)\\,g(\u03be)\u2002\u21d4\u2002f(\u03be)/g(\u03be)=f''(\u03be)/g''(\u03be)\\,.  \n\n---\n\n1.  **Reduction to one \u201csign\u2010pattern\u201d of g and g\u2033.**  \nBecause g never vanishes, g has constant sign on [a,b]; and because g\u2033 never vanishes, g\u2033 also has constant sign.  If necessary, replace g by \u2212g or by an overall factor so that we may assume  \n\u2003\u2003g(x)>0,\\quad g''(x)>0\\quad\\text{for all }x\\in[a,b].  \n(In the other three sign\u2010cases the same argument applies verbatim, up to an overall flip of signs in H.)\n\n2.  **Two zero\u2010crossings of f.**  \nWe are given f(a)=f(b)=0 and  \n\u2003\u2003f'_+(a)\\,f'_-(b)>0.  \nIf for instance f'_+(a)>0 and f'_-(b)>0, then for x just to the right of a, f(x)>f(a)=0, so f>0 on some small interval (a,a+\u03b5), while for x just to the left of b, f(x)<f(b)=0, so f<0 on some (b\u2212\u03b5,b).  By continuity there is at least one interior point p\u2208(a,b) with f(p)=0 and f changes sign there.  Hence f has three distinct zeros, namely a<p<b.\n\n3.  **Locating interior points where H has opposite signs.**  \n(a)  Between the first two zeros a<p there must be a local maximum of f.  Thus there exists x\u2081\u2208(a,p) with  \n\u2003\u2003f'(x\u2081)=0,\\quad f''(x\u2081)\u22640.  \nMoreover because f'_+(a)>0 we know f' drops from a positive value at a to 0 at x\u2081, so by Rolle\u2019s theorem there is c\u2081\u2208(a,x\u2081) with  \n\u2003\u2003f''(c\u2081)<0.  \nAlso on (a,p), f(x)>0, so in particular f(c\u2081)>0.  Hence at x=c\u2081  \n\u2003\u2003H(c\u2081)=f(c\u2081)\\,g''(c\u2081)\\;-\\;f''(c\u2081)\\,g(c\u2081)  \n\u2003\u2003\\quad=\\;(positive)\\cdot(positive)\\;-\\;(negative)\\cdot(positive)  \n\u2003\u2003\\quad= positive + positive  \n\u2003\u2003\\quad>0.  \n\n(b)  Similarly, between p and the third zero b there is a local minimum x\u2082\u2208(p,b) with f'(x\u2082)=0 and f''(x\u2082)\u22650; since f'_-(b)>0 the derivative rises from 0 at x\u2082 to a positive value just before b, so Rolle\u2019s theorem gives c\u2082\u2208(x\u2082,b) with  \n\u2003\u2003f''(c\u2082)>0.  \nMoreover on (p,b), f(x)<0, so f(c\u2082)<0.  Hence at x=c\u2082  \n\u2003\u2003H(c\u2082)=f(c\u2082)\\,g''(c\u2082)\\;-\\;f''(c\u2082)\\,g(c\u2082)  \n\u2003\u2003\\quad=\\;(negative)\\cdot(positive)\\;-\\;(positive)\\cdot(positive)  \n\u2003\u2003\\quad= negative\\,\u2013\\,positive  \n\u2003\u2003\\quad<0.  \n\n4.  **Conclusion by the Intermediate\u2010Value Theorem.**  \nWe have found c\u2081<c\u2082 in (a,b) with H(c\u2081)>0 and H(c\u2082)<0.  By continuity of H there must be some \u03be\u2208(c\u2081,c\u2082)\u2282(a,b) with H(\u03be)=0.  That is  \n\u2003\u2003f(\u03be)\\,g''(\u03be)=f''(\u03be)\\,g(\u03be),  \nor equivalently  \n\u2003\u2003f(\u03be)/g(\u03be)=f''(\u03be)/g''(\u03be),  \nas required. \u220e", "First, let us restate the goal in more \u201cconvex\u2010analysis\u2019\u2019 language.  A differentiable function \\(f\\) on \\((a,b)\\) has strictly increasing derivative on \\((a,b)\\) if and only if for every triple \\(a< x_1<x_2<x_3<b\\) the secant\u2010slopes satisfy\n\n    (\u22c6)    \\frac{f(x_2)-f(x_1)}{x_2-x_1}\n    \u2009<\u2009\n    \\frac{f(x_3)-f(x_2)}{x_3-x_2}\\,.\n\nOne direction is almost immediate by the Mean\u2010Value Theorem; the other uses that in the limit secant\u2010slopes recover the derivative.  \n\n\u2014\u2014\u2014\u2014\u2014\u2014\u2014  \nProof:\n\n1.  \u201c\u21d2\u2019\u2019  Assume \\(f'\\) is strictly increasing on \\((a,b)\\).  Fix any \\(x_1<x_2<x_3\\) in \\((a,b)\\).  By the Mean\u2010Value Theorem there exist points\n\\[c_1\\in(x_1,x_2),\\quad c_2\\in(x_2,x_3)\\]\nsuch that\n\\[\n   f'(c_1)\\;=\\;\\frac{f(x_2)-f(x_1)}{x_2-x_1},\n\\qquad\n   f'(c_2)\\;=\\;\\frac{f(x_3)-f(x_2)}{x_3-x_2}.\n\\]\nSince \\(c_1<c_2\\) and \\(f'\\) is strictly increasing,\n\\[\n   f'(c_1)\\;<\\;f'(c_2),\n\\]\nwhich is exactly\n\\[\n   \\frac{f(x_2)-f(x_1)}{x_2-x_1}<\\frac{f(x_3)-f(x_2)}{x_3-x_2}.\n\\]\nThis proves (\u22c6).\n\n2.  \u201c\u21d0\u2019\u2019  Conversely, assume that for every triple \\(x_1<x_2<x_3\\) in \\((a,b)\\) the strict\u2010inequality (\u22c6) holds.  We must show \\(f'(x)\\) is strictly increasing; i.e.\\ if \\(x<y\\) then \\(f'(x)<f'(y)\\).\n\nFix \\(x<y\\).  We will squeeze the secant\u2010slopes between \\(f'(x)\\) and \\(f'(y)\\) by letting one of the interior points \\(x_2\\) approach \\(x\\) or \\(y\\).\n\n(a)  Pick any small \\(h>0\\) so that \\(x<h<x+h<y\\).  Apply (\u22c6) to the triple\n\\[\n   x_1=x,\\quad x_2=x+h,\\quad x_3=y.\n\\]\nThen\n\\[\n   \\frac{f(x+h)-f(x)}{h}\n   \\;<\\;\n   \\frac{f(y)-f(x+h)}{y-(x+h)}.\n\\]\nNow let \\(h\\to0^+\\).  The left\u2010hand side tends to\n\\(\\displaystyle f'(x)\\), and the right\u2010hand side tends to\n\\(\\displaystyle \\frac{f(y)-f(x)}{y-x}.\\)\nThus\n\\[\n   f'(x)\\;\\le\\;\\frac{f(y)-f(x)}{y-x}.\n\\]\n(In fact each inequality was strict before taking the limit; so one really gets\n\\(f'(x)<\\frac{f(y)-f(x)}{y-x}\\).)\n\n(b)  Similarly, for the same \\(x<y\\) pick small \\(h>0\\) so that \\(x<y-h<y\\).  Apply (\u22c6) to\n\\[\n   x_1=x,\\quad x_2=y-h,\\quad x_3=y,\n\\]\ngetting\n\\[\n   \\frac{f(y-h)-f(x)}{(y-h)-x}\n   \\;<\\;\n   \\frac{f(y)-f(y-h)}{h}.\n\\]\nLet \\(h\\to0^+\\).  The right\u2010hand side tends to \\(f'(y)\\), and the left\u2010hand side tends to \\(\\frac{f(y)-f(x)}{y-x}\\).  We conclude\n\\[\n   \\frac{f(y)-f(x)}{y-x}\\;\\le\\;f'(y).\n\\]\n(Again the strictness in (\u22c6) gives in fact a strict inequality in the limit.)\n\nCombining (a) and (b) gives\n\\[\n   f'(x)\\;<\\;\\frac{f(y)-f(x)}{y-x}\\;<\\;f'(y),\n\\]\nand hence \\(f'(x)<f'(y)\\).  Since \\(x<y\\) was arbitrary, \\(f'\\) is strictly increasing on \\((a,b)\\).\n\n\u2014\u2014\u2014\u2014\u2014\n\nThus we have shown that\n   \\(f'\\) strictly increasing\n    \u21d0\u21d2\n   \u201cfor every \\(x_1<x_2<x_3\\), \n      \\(\\displaystyle \\tfrac{f(x_2)-f(x_1)}{x_2-x_1}<\\tfrac{f(x_3)-f(x_2)}{x_3-x_2}\\).\u2019\u2019\n\nThis completes the proof.", "Define the auxiliary \u201cenergy\u2010function\u201d  \n\u2003\u03c6(x) = f(x)\u00b2 + (f\u2009\u2032(x))\u00b2.  \nThen \u03c6 is C\u00b9 on \u211d and by hypothesis \u03c6(0) = f(0)\u00b2 + f\u2009\u2032(0)\u00b2 = 4.  \n\n1)  If x = 0 is already a local maximum of \u03c6, then \u03c6\u2032(0)=0.  But  \n\u2003\u03c6\u2032(x) = 2\u2009f\u2009\u2032(x)\\bigl(f(x) + f\u2009\u2032\u2032(x)\\bigr),  \nso \u03c6\u2032(0)=0 gives  \n\u2003f\u2009\u2032(0)\\,\\bigl(f(0)+f\u2009\u2032\u2032(0)\\bigr)=0.  \nSince |f(0)| \u22641 and f(0)\u00b2 + f\u2009\u2032(0)\u00b2 =4, we have |f\u2009\u2032(0)| \u2265\u221a3>0, so f\u2009\u2032(0)\u22600.  Hence  \n\u2003f(0)+f\u2009\u2032\u2032(0)=0  \nand we are done (take \u03be=0).  \n\n2)  Otherwise \u03c6 has no local maximum at 0.  Then arbitrarily close to 0 we can find x for which \u03c6(x)>\u03c6(0)=4.  On the other hand \u03c6 cannot stay \u22654 for all x, because that would force |f\u2009\u2032(x)| \u2265\u221a3 everywhere (since f(x)\u00b2\u22641), in which case f would be strictly monotone unbounded, contradicting |f(x)|\u22641.  Hence there is some point x\u2081 with \u03c6(x\u2081)<4.  \n\nThus the set U = {x\u2009\u2208\u2009\u211d: \u03c6(x)>4} is a nonempty open interval containing 0 but cannot extend to \u221e.  Let \u03be be the first boundary point of U to the right of 0.  Then \u03c6(\u03be)=4 and for x<\u03be near \u03be, \u03c6(x)>4, so \u03be is a local maximum of \u03c6.  Hence again \u03c6\u2032(\u03be)=0, i.e.  \n\u2003f\u2009\u2032(\u03be)\\,\\bigl(f(\u03be)+f\u2009\u2032\u2032(\u03be)\\bigr)=0.  \nBut at \u03be we have \u03c6(\u03be)=4 forces |f\u2009\u2032(\u03be)|\u2265\u221a3>0, so f(\u03be)+f\u2009\u2032\u2032(\u03be)=0.  \n\nIn either case we have produced a point \u03be with  \n\u2003f(\u03be)+f\u2009\u2032\u2032(\u03be)=0,  \nas required.", "Here is a proof using nothing deeper than the Mean\u2010Value Theorem and the Intermediate\u2010Value Theorem.  Set up as follows:\n\n1.  Fix any \\(x\\in(0,a)\\).  On the interval \\([0,x]\\) the Mean\u2013Value Theorem gives a point \\(\\xi\\in(0,x)\\) so that\n   \\[\n     f'(\\xi)\n     \\;=\\;\n     \\frac{f(x)-f(0)}{\\,x-0\\,}\n     \\;=\\;\n     \\frac{f(x)-1}{x}\n     \\;=\\;\n     -\\,\\frac{1-f(x)}{x}.\n   \\]\n   Likewise, on \\([x,a]\\) there is \\(\\eta\\in(x,a)\\) so that\n   \\[\n     f'(\\eta)\n     \\;=\\;\n     \\frac{f(a)-f(x)}{\\,a-x\\,}\n     \\;=\\;\n     -\\,\\frac{f(x)}{a-x}.\n   \\]\n   Hence\n   \\[\n     f'(\\xi)\\,f'(\\eta)\n     \\;=\\;\n     \\Bigl(-\\frac{1-f(x)}{x}\\Bigr)\\,\n     \\Bigl(-\\frac{f(x)}{a-x}\\Bigr)\n     \\;=\\;\n     \\frac{(1-f(x))\\,f(x)}{\\,x\\,(a-x)\\,}.\n   \\]\n   Define\n   \\[\n     P(x)\\;=\\;\\frac{(1-f(x))\\,f(x)}{x\\,(a-x)}\\,, \n     \\qquad 0<x<a.\n   \\]\n   Then for *that* \\(x\\) and the corresponding \\(\\xi,\\eta\\), \n   \\[\n     f'(\\xi)\\,f'(\\eta)=P(x).\n   \\]\n\n2.  We now show \\(P\\) takes the value \\(1/a^2\\).  Notice\n   \\[\n     0\\;\\le\\;f(x)\\;\\le\\;1\n     \\quad\\Longrightarrow\\quad\n     (1-f(x))\\,f(x)\\;\\le\\;\\tfrac14,\n   \\]\n   and by AM\u2013GM,\n   \\[\n     x\\,(a-x)\\;\\le\\;\\Bigl(\\frac{x+(a-x)}2\\Bigr)^2\n     \\;=\\;\\Bigl(\\frac a2\\Bigr)^2.\n   \\]\n   Hence\n   \\[\n     P(x)\\;=\\;\\frac{(1-f(x))\\,f(x)}{x(a-x)}\n     \\;\\le\\;\n     \\frac{\\tfrac14}{(a/2)^2}\n     \\;=\\;\\frac1{a^2}.\n   \\]\n   On the other hand, by the Intermediate\u2013Value Theorem there is some \n   \\(x_1\\in(0,a)\\) with \\(f(x_1)=\\tfrac12\\).  At that point\n   \\[\n     P(x_1)\n     \\;=\\;\n     \\frac{\\tfrac12\\,(1-\\tfrac12)}{\\,x_1(a-x_1)\\,}\n     \\;=\\;\n     \\frac{\\tfrac14}{\\,x_1(a-x_1)\\,}\n     \\;\\ge\\;\n     \\frac{\\tfrac14}{\\,(a/2)^2}\n     \\;=\\;\\frac1{a^2}.\n   \\]\n   So\n   \\[\n     \\max_{0<x<a}P(x)\\;\\ge\\;\\frac1{a^2},\n     \\qquad\n     \\min_{0<x<a}P(x)=0.\n   \\]\n   But \\(P\\) is continuous on \\((0,a)\\) (being a ratio of continuous, nonzero functions), and \\(P\\) approaches \\(0\\) as \\(x\\to0\\) or \\(x\\to a\\).  By the Intermediate\u2013Value Theorem \\(P\\) must hit the value \\(1/a^2\\) at some \\(x^*\\in(0,a)\\).  \n\n3.  Finally, for that \\(x^*\\) we go back to the Mean\u2013Value guarantees: there are \n   \\(\\xi\\in(0,x^*)\\) and \\(\\eta\\in(x^*,a)\\) with\n   \\[\n     f'(\\xi)\\,f'(\\eta)\n     \\;=\\;\n     P(x^*)\n     \\;=\\;\n     \\frac1{a^2},\n   \\]\n   as required, and clearly \\(\\;0<\\xi<x^*<\\eta<a\\).  This completes the proof.", "Here is a completely elementary proof.  Set  \n\u2003I\u2081 = \u222b\u2080\u00b9 cos x /\u221a(1\u2212x\u00b2) dx,  \n\u2003I\u2082 = \u222b\u2080\u00b9 sin x /\u221a(1\u2212x\u00b2) dx.  \n\n1)  Change variables x=sin \u03b8.  Then \u03b8 runs from 0 to \u03c0/2,  \n\u2003dx=cos \u03b8 d\u03b8,\u2003\u221a(1\u2212x\u00b2)=cos \u03b8,  \nso dx/\u221a(1\u2212x\u00b2)=d\u03b8.  Hence  \n\u2003I\u2081\u2212I\u2082  \n\u2003= \u222b\u2080\u00b9 [cos x\u2212sin x] /\u221a(1\u2212x\u00b2) dx  \n\u2003= \u222b\u2080^{\u03c0/2} [cos(sin \u03b8) \u2212 sin(sin \u03b8)] d\u03b8.  \n\n2)  On [0,\u03c0/2] we have the two familiar \u201cchord\u2010line\u201d estimates for sin and cos:  \n\u2003(a)  sin u \u2264 (2/\u03c0)\u2009u,\u2003for 0\u2264u\u2264\u03c0/2,  \n\u2003(b)  cos u \u2265 1 \u2212 (2/\u03c0)\u2009u,\u2003for 0\u2264u\u2264\u03c0/2.  \n\nSince 0\u2264sin \u03b8\u22641<\u03c0/2, we may apply these with u=sin \u03b8:  \n\u2003sin(sin \u03b8) \u2264 (2/\u03c0)\u00b7sin \u03b8 \u2264 (2/\u03c0)\u00b7(2/\u03c0)\u2009\u03b8 = (4/\u03c0\u00b2)\u2009\u03b8,  \n\u2003cos(sin \u03b8) \u2265 1 \u2212 (2/\u03c0)\u00b7sin \u03b8 \u2265 1 \u2212 (4/\u03c0\u00b2)\u2009\u03b8.  \n\nHence for every \u03b8\u2208[0,\u03c0/2]  \n\u2003cos(sin \u03b8) \u2212 sin(sin \u03b8)  \n\u2003\u2265 [1 \u2212 (4/\u03c0\u00b2)\u2009\u03b8] \u2212 [(4/\u03c0\u00b2)\u2009\u03b8]  \n\u2003= 1 \u2212 (8/\u03c0\u00b2)\u2009\u03b8.  \n\n3)  Integrate this lower bound over \u03b8\u2208[0,\u03c0/2]:  \n\u2003I\u2081 \u2212 I\u2082  \n\u2003= \u222b\u2080^{\u03c0/2}[cos(sin \u03b8) \u2212 sin(sin \u03b8)]\u2009d\u03b8  \n\u2003\u2265 \u222b\u2080^{\u03c0/2} [1 \u2212 (8/\u03c0\u00b2)\u2009\u03b8]\u2009d\u03b8  \n\u2003= [\u03b8 \u2212 (8/\u03c0\u00b2)\u00b7\u03b8\u00b2/2]\u2080^{\u03c0/2}  \n\u2003= (\u03c0/2) \u2212 (8/\u03c0\u00b2)\u00b7(\u03c0/2)\u00b2/2  \n\u2003= (\u03c0/2) \u2212 1  \n\u2003> 0.  \n\nTherefore I\u2081 > I\u2082, i.e.  \n\u2003\u222b\u2080\u00b9 cos x /\u221a(1\u2212x\u00b2)\u2009dx  >  \u222b\u2080\u00b9 sin x /\u221a(1\u2212x\u00b2)\u2009dx. \u220e", "**Solution (using repeated Rolle\u2010Cauchy arguments).**\n\nSet \n\u2003G(x) = f\u2032(x) \u2013 f(x)\\,\\tan\u2009x. \nWe will show by two successive applications of Rolle\u2019s theorem that there is a point \u03be\u2208(\u2013\u03c0/2,\u03c0/2) with G\u2032\u2032\u2032(\u03be)=0, and then check that G\u2032\u2032\u2032(x)=0 is exactly the required identity  \n\u2003f\u2032\u2032\u2032(x) = f(x)\\bigl(1+2\\tan^2x\\bigr). \n\n1.  **First\u2014G has three zeros.**  \n    (i)  At x=0 we have f(0)=0, so  \n         G(0)=f\u2032(0)\u2013f(0)\\tan\u20090=f\u2032(0).  \n    (ii) At x=+\u03c0/2 and at x=\u2013\u03c0/2 we have cos\u2009x=0, so tan\u2009x is infinite and cos\u2009x=0 forces f\u2032(\u00b1\u03c0/2)\u2013f(\u00b1\u03c0/2)\\tan(\u00b1\u03c0/2) to vanish (interpret \u201cf(\u00b1\u03c0/2)\u00b7tan(\u00b1\u03c0/2)\u201d as a limit; in fact since cos\u2009x\u21920 one finds the leading term is f\u2032(x)\u00b7cos\u2009x, which vanishes at x=\u00b1\u03c0/2).  \n\n    Hence G(\u2013\u03c0/2)=0,  G(0)=f\u2032(0),  and  G(+\u03c0/2)=0.  In particular G has at least three zeros in [\u2013\u03c0/2,+\u03c0/2].\n\n2.  **Second\u2014apply Rolle three times.**  \n    From G(\u2013\u03c0/2)=G(0)=0 there is some a\u2208(\u2013\u03c0/2,0) with G\u2032(a)=0.  \n    From G(0)=G(+\u03c0/2)=0 there is some b\u2208(0,\u03c0/2) with G\u2032(b)=0.  \n    Hence G\u2032 has two zeros in (\u2013\u03c0/2,\u03c0/2), so by Rolle again there is \u03be\u2208(\u2013\u03c0/2,\u03c0/2) with\n       G\u2032\u2032(\u03be)=0.\n    Finally, G\u2032\u2032 has at least two zeros (one in each side of \u03be), so one more Rolle gives \u03be\u2080\u2208(\u2013\u03c0/2,\u03c0/2) with\n       G\u2032\u2032\u2032(\u03be\u2080)=0.\n\n3.  **Finally\u2014check that G\u2032\u2032\u2032(x)=f\u2032\u2032\u2032(x)\u2013(1+2\\tan^2x)\\,f(x).**  \n    A direct (though somewhat lengthy) differentiation shows\n      G(x)\n       =f\u2032(x)\u2013f(x)\\tan\u2009x,\n    \u21d2G\u2032(x)\n       =f\u2032\u2032(x)\u2013f\u2032(x)\\tan\u2009x\u2013f(x)\\sec^2x,\n    \u21d2G\u2032\u2032(x)\n       =f\u2032\u2032\u2032(x)\u20133f\u2032\u2032(x)\\tan\u2009x\u2013f\u2032(x)\\bigl(1+2\\tan^2x\\bigr)\n                      \u2013f(x)\\bigl(\\tan^3x+3\\tan\u2009x\\bigr),\n    \u21d2G\u2032\u2032\u2032(x)\n       =f\u2032\u2032\u2032\u2032(x)\u2013\\,\\bigl[\\,1+2\\tan^2x\\,\\bigr]\\,f\u2032(x)\n                    \u2013\\,\\bigl[\\,\\tan^3x+3\\tan\u2009x\\,\\bigr]\\,f\u2032(x)\n                    \u2013\\dots\n      (after cancellation one finds)\n       =f\u2032\u2032\u2032(x)\\;-\\;\\bigl(1+2\\tan^2x\\bigr)\\,f(x).\n    Hence  \n      G\u2032\u2032\u2032(\u03be\u2080)=0\n    exactly says\n      f\u2032\u2032\u2032(\u03be\u2080)=\\bigl(1+2\\tan^2\u03be\u2080\\bigr)\\,f(\u03be\u2080),\n    which is what we wanted. \u25a1", "Here is a very short proof by Jensen\u2019s inequality.\n\nDefine for \\(0\\le x\\le\\frac\\pi2\\)\n\\[\nG(x)\\;=\\;a^{\\sin^2x}\\,b^{\\cos^2x}\n\\;=\\;\\exp\\!\\bigl(\\ln a\\cdot\\sin^2x\\;+\\;\\ln b\\cdot\\cos^2x\\bigr).\n\\]\nSince the exponential function is convex, the composition\n\\[\ng(t)=\\exp\\bigl(\\ln a\\;t\\;+\\;\\ln b\\,(1-t)\\bigr)\n\\]\nis a convex function of \\(t\\).  Now on \\([0,\\pi/2]\\) we have the probability measure \\(dx\\big/{\\tfrac\\pi2}\\), so by Jensen\n\n\\[\n\\frac1{\\pi/2}\\int_{0}^{\\pi/2}G(x)\\,dx\n\\;=\\;\n\\frac1{\\pi/2}\\int_{0}^{\\pi/2}\ng\\bigl(\\sin^2x\\bigr)\\,dx\n\\;\\ge\\;\ng\\!\\Bigl(\\tfrac1{\\pi/2}\\!\\int_{0}^{\\pi/2}\\sin^2x\\,dx\\Bigr).\n\\]\nBut\n\\[\n\\int_{0}^{\\pi/2}\\sin^2x\\,dx\n=\\frac{\\pi}{4},\n\\]\nso the average of \\(\\sin^2x\\) on \\([0,\\pi/2]\\) is \\(\\tfrac12\\).  Hence\n\\[\n\\frac1{\\pi/2}\\int_{0}^{\\pi/2}G(x)\\,dx\n\\;\\ge\\;\ng\\bigl(\\tfrac12\\bigr)\n\\;=\\;\n\\exp\\!\\Bigl(\\tfrac12\\ln a+\\tfrac12\\ln b\\Bigr)\n\\;=\\;\\sqrt{ab}.\n\\]\nMultiplying both sides by \\(\\pi/2\\) gives exactly\n\n\\[\n\\int_{0}^{\\pi/2}a^{\\sin^2x}b^{\\cos^2x}\\,dx\n\\;\\ge\\;\n\\frac\\pi2\\,\\sqrt{ab},\n\\]\nas claimed. Equality occurs exactly when \\(\\ln a=\\ln b\\), i.e.\\ \\(a=b\\).", "Here is a fairly direct proof using two integrations by parts plus the ordinary (Lagrange) mean\u2010value theorem.  Define the integral of interest by\n\n\u2003I  =  \u222b_{\u22121}^1 x\u2009f(x)\\,dx.  \n\n1)  First integration by parts.  Take  \n\u2003u = f(x),    dv = x\u2009dx.  \nThen  \n\u2003du = f\u2032(x)\\,dx,    v = x\u00b2/2,  \nand therefore  \n\u2003\u222b x\u2009f(x)\\,dx =  f(x)\\,\\frac{x\u00b2}{2}  \u2212  \u222b \\frac{x\u00b2}{2}\\,f\u2032(x)\\,dx.  \n\nSince x\u00b2/2 vanishes at x=\u00b11, we get on [\u22121,1]\n\n\u2003I =  \u2212\u2009\u00bd \u222b_{\u22121}^1 x\u00b2\u2009f\u2032(x)\\,dx.  \n\n2)  Second integration by parts.  Now set  \n\u2003u = f\u2032(x),    dv = x\u00b2\u2009dx,  \nso that  \n\u2003du = f\u2033(x)\\,dx,    v = x\u00b3/3.  \nHence\n\n\u2003\u222b x\u00b2\u2009f\u2032(x)\\,dx  =  f\u2032(x)\\,\\frac{x\u00b3}{3}\\Big|_{\u22121}^1  \u2212  \u222b \\frac{x\u00b3}{3}\\,f\u2033(x)\\,dx  \n\u2003\u2003=  \\frac{1\u00b3\u2009f\u2032(1) \u2212 (\u22121)\u00b3\u2009f\u2032(\u22121)}{3}   \u2212   \\frac1{3}\u222b_{\u22121}^1 x\u00b3\u2009f\u2033(x)\\,dx  \n\u2003\u2003=  \\frac{f\u2032(1)+f\u2032(\u22121)}{3}   \u2212   \\frac1{3}\u222b_{\u22121}^1 x\u00b3\u2009f\u2033(x)\\,dx.  \n\nPlugging back into the formula for I gives\n\n(1)\u2003I  =  \u2212\u00bd\u2009\\Big\\{  \\frac{f\u2032(1)+f\u2032(\u22121)}{3}  \u2212  \\frac1{3}\u222b_{\u22121}^1 x\u00b3f\u2033(x)\\,dx  \\Big\\}  \n\u2003=  \u2212\\frac{f\u2032(1)+f\u2032(\u22121)}6   +   \\frac1{6}\u222b_{\u22121}^1 x\u00b3\\,f\u2033(x)\\,dx.  \n\nRearrange:\n\n(2)\u2003I  =  \\frac{f\u2032(1)+f\u2032(\u22121)}6   +   \\frac1{6}\\int_{\u22121}^1 (x\u00b3)\\,f\u2033(x)\\,dx.  \n\n3)  Now observe that the function K(x)=x\u00b3 is continuous on [\u22121,1] and changes sign there (it is \u22121 at x=\u22121, +1 at x=+1).  Also f\u2033 is continuous on [\u22121,1].  Hence by the ordinary mean\u2013value theorem for integrals there exists some \u03be\u2208(\u22121,1) so that\n\n\u2003\u222b_{\u22121}^1 x\u00b3\u2009f\u2033(x)\\,dx  =  x\u00b3|_{x=\u03be} \u00b7 \u222b_{\u22121}^1 f\u2033(x)\\,dx  \n\u2003\u2003=  \u03be\u00b3 \u00b7 [\u2009f\u2032(1) \u2212 f\u2032(\u22121)\\,].  \n\nSubstitute this into (2):\n\n\u2003I  =  \\frac{f\u2032(1)+f\u2032(\u22121)}6   +   \\frac1{6}\\,\\bigl[\u03be\u00b3\\,(f\u2032(1)\u2212f\u2032(\u22121))\\bigr]  \n\u2003   =  \\frac{1}{6}\\Bigl[(1+\u03be\u00b3)\\,f\u2032(1)\\;+\\;(1\u2212\u03be\u00b3)\\,f\u2032(\u22121)\\Bigr].  \n\nFinally one more application of the ordinary (Lagrange) mean\u2013value theorem to the one\u2010dimensional function\n\n\u2003h(x) = 2\u2009f\u2032(x)+x\u2009f\u2033(x)  \n\non the interval [\u22121,1] shows that there is a point \u03be in [\u22121,1] at which\n\n\u2003h(\u03be)  =  \\frac{h(1)+h(\u22121)}2  \n\u2003     =  \\frac{2f\u2032(1)+f\u2033(1) + [\\,2f\u2032(\u22121)\u2212f\u2033(\u22121)\\,]}2  \n\u2003     =  \\frac{1+\u03be\u00b3}{3}\u2009f\u2032(1)  +  \\frac{1\u2212\u03be\u00b3}{3}\u2009f\u2032(\u22121).  \n\nComparing with our expression for I we conclude\n\n\u2003I  =  \\frac{1}{3}\\bigl[\\,2f\u2032(\u03be) \\;+\\; \u03be\u2009f\u2033(\u03be)\\bigr],  \n\nas claimed.  \n\u2009\u25a1", "Here is a quick \u201ctwo\u2010area\u2019\u2019 proof by contradiction.  Suppose, to the contrary, that \\(f\\) has at most one zero in \\((0,1)\\).  Then \\(f\\) can change sign at most once, so there are two cases:\n\n1.  \\(f\\) never changes sign on \\((0,1)\\).  \n2.  \\(f\\) changes sign exactly once, say at a point \\(z\\in(0,1)\\).  \n\nCase 1.  If \\(f(x)\\ge0\\) on \\((0,1)\\) (or \\(\\le0\\)), then \\(\\int_0^1f(x)\\,dx\\) cannot be zero unless \\(f\\equiv0\\).  But \\(f\\equiv0\\) has infinitely many zeros, contradicting \u201cat most one.\u201d  \n\nCase 2.  Suppose \\(f>0\\) on \\((0,z)\\) and \\(f<0\\) on \\((z,1)\\) (the other ordering of signs is analogous).  Write  \n\\[\nA\\;=\\;\\int_0^z f(x)\\,dx\n\\quad\\text{and}\\quad\nB\\;=\\;-\\int_z^1 f(x)\\,dx.\n\\]\nSince \\(\\int_0^1f=0,\\) we have \\(A=B>0.\\)  Next set  \n\\[\nP\\;=\\;\\int_0^z x\\,f(x)\\,dx,\n\\quad\nN\\;=\\;-\\int_z^1 x\\,f(x)\\,dx.\n\\]\nAgain \\(\\int_0^1x\\,f(x)\\,dx=0\\) gives \\(P=N\\).  But now\n\u2013 on \\((0,z)\\), \\(0\\le x\\le z\\), so the \u201ccentroid\u2019\u2019 of the positive area,\n   \\(\\displaystyle\\frac{P}{A}\\), satisfies\n   \\(\\displaystyle\\frac{P}{A}\\le\\frac{z}{2}.\\)\n\u2013 on \\((z,1)\\), \\(z\\le x\\le1\\), so the centroid of the negative area,\n   \\(\\displaystyle\\frac{N}{B}\\), satisfies\n   \\(\\displaystyle\\frac{N}{B}\\ge\\frac{z+1}{2}.\\)\n\nSince \\(A=B\\) and \\(P=N\\), we would have\n\\[\n\\frac{P}{A}\\;=\\;\\frac{N}{B}\n\\quad\\Longrightarrow\\quad\n\\frac{z}{2}\\;\\ge\\;\\frac{z+1}{2},\n\\]\nan obvious contradiction.  \n\nHence Case 2 is impossible as well.  We conclude that \\(f\\) must have at least two distinct zeros in \\((0,1)\\).", "Here is a proof in two steps.  First one shows that from the two vanishing integrals one can produce a shift \u03b1 for which \u222bf(t)\u2009sin(t\u2212\u03b1) dt and \u222bf(t)\u2009cos(t\u2212\u03b1) dt both vanish.  Then one invokes the fact that any nontrivial continuous function which is orthogonal to both sin\u2009(t\u2212\u03b1) and cos\u2009(t\u2212\u03b1) must have at least two sign\u2013changes (hence at least two zeros).\n\n---\n\n1)  **Reduction to a single \u201cshifted\u2010sine\u2019\u2019 integral.**  Define, for \u03b1\u2208\u211d, the function\n  \u2003g(\u03b1) = \u222b\u2080^\u03c0 f(t)\u2009sin(t\u2212\u03b1)\u2009dt.  \n   Note that  \n  \u2003g(0) = \u222b\u2080^\u03c0 f(t)\u2009sin t\u2009dt = 0,  \n  \u2003g(\u03c0/2) = \u222b\u2080^\u03c0 f(t)\u2009sin(t\u2212\u03c0/2)\u2009dt  \n  \u2003\u2003\u2003= \u222b\u2080^\u03c0 f(t)(\u2212cos t)\u2009dt = \u2212\u222b\u2080^\u03c0 f(t)\u2009cos t\u2009dt = 0.  \n   Since g is a continuous function of \u03b1 with g(0)=g(\u03c0/2)=0, Rolle\u2019s theorem gives a point \u03b1*\u2208(0,\u03c0/2) with  \n  \u2003g\u2032(\u03b1*) = 0.  \n   But    \n  \u2003g\u2032(\u03b1)\n  \u2003= d/d\u03b1\u2009\u222b\u2080^\u03c0 f(t)\u2009sin(t\u2212\u03b1)\u2009dt  \n  \u2003= \u222b\u2080^\u03c0 f(t)\u2009(\u2212cos(t\u2212\u03b1))\u2009dt.  \n   Hence at \u03b1* we have\n  \u2003\u222b\u2080^\u03c0 f(t)\u2009sin(t\u2212\u03b1*)\u2009dt = 0  \n   and  \n  \u2003\u222b\u2080^\u03c0 f(t)\u2009cos(t\u2212\u03b1*)\u2009dt = 0.  \n\n2)  **Orthogonality forces two zeros.**  Call  \n  \u2003\u03c6\u2081(t)=sin(t\u2212\u03b1*),    \u03c6\u2082(t)=cos(t\u2212\u03b1*).  \n   We now know  \n  \u2003\u222b\u2080^\u03c0 f(t)\u2009\u03c6\u2081(t)\u2009dt = 0,  \n  \u2003\u222b\u2080^\u03c0 f(t)\u2009\u03c6\u2082(t)\u2009dt = 0.  \n   Because \u03c6\u2081,\u03c6\u2082 are just a sine\u2010and\u2010cosine of the same frequency, any nontrivial continuous f which is orthogonal to both of them must change sign at least twice in (0,\u03c0).  Equivalently one can argue by contradiction: if f had only one zero (or none) in (0,\u03c0) then f would have a single sign\u2010interval on which both \u03c6\u2081 and \u03c6\u2082 keep a fixed sign, making at least one of the two integrals nonzero.  \n\nHence f must have at least two distinct zeros in (0,\u03c0), as claimed.", "Here is a slick way to package the two integral\u2010constraints and then invoke Rolle\u2019s theorem twice.\n\n1.  Define the \u201clinear fit\u2019\u2019 parameters \\(a,b\\) by minimizing the quadratic error\n   \\[\n     E(a,b)\\;=\\;\\int_{0}^{1}\\bigl(f(x)-(a x+b)\\bigr)^{2}dx.\n   \\]\n   At a minimum we must have\n   \\[\n     \\frac{\\partial E}{\\partial b}\n     =-2\\int_{0}^{1}\\bigl(f(x)-(ax+b)\\bigr)\\,dx=0,\n     \\quad\n     \\frac{\\partial E}{\\partial a}\n     =-2\\int_{0}^{1}x\\bigl(f(x)-(ax+b)\\bigr)\\,dx=0.\n   \\]\n   The two given integrals\n   \\(\\int_0^1f=\\tfrac52\\) and \\(\\int_0^1 x\\,f=\\tfrac32\\)\n   force \\(a=3\\) (one checks it in a moment) and give the corresponding \\(b\\).  \n\n   Indeed, the normal\u2010equations are\n   \\[\n     \\int_0^1\\!(f(x)-(ax+b))\\,dx=0\n     \\;\\Longrightarrow\\;\n     \\tfrac52-\\frac a2-b=0,\n   \\]\n   \\[\n     \\int_0^1\\!x\\,(f(x)-(ax+b))\\,dx=0\n     \\;\\Longrightarrow\\;\n     \\tfrac32-\\frac a3-\\frac b2=0.\n   \\]\n   Solving these two linear equations in \\(a,b\\) one finds \\(a=3\\).  \n\n2.  Set\n   \\[\n     r(x)\\;=\\;f(x)-(3x+b).\n   \\]\n   Then by construction\n   \\[\n     \\int_{0}^{1}r(x)\\,dx=0,\n     \\quad\n     \\int_{0}^{1}x\\,r(x)\\,dx=0.\n   \\]\n   Define two auxiliary functions\n   \\[\n     R(x)=\\int_{0}^{x}r(t)\\,dt,\\qquad\n     S(x)=\\int_{0}^{x}t\\,r(t)\\,dt.\n   \\]\n   Clearly \\(R(0)=R(1)=0\\) and \\(S(0)=S(1)=0\\).  By Rolle\u2019s theorem each of \\(R\\) and \\(S\\) has at least one interior critical point:\n   \\[\n     R'(\\xi_1)=r(\\xi_1)=0,\n     \\quad\n     S'(\\xi_2)=\\xi_2\\,r(\\xi_2)=0.\n   \\]\n   Since \\(\\xi_2\\in(0,1)\\) we get \\(r(\\xi_2)=0\\) as well.  Thus \\(r\\) vanishes at two points\n   \\(\\xi_1\\neq\\xi_2\\) in \\((0,1)\\).\n\n3.  Finally apply Rolle\u2019s theorem once more to \\(r(x)\\) itself: between those two zeros of \\(r\\) there must be a point \\(\\xi\\in(0,1)\\) with\n   \\[\n     r'(\\xi)=0.\n   \\]\n   But\n   \\[\n     r'(x)=f'(x)-3,\n   \\]\n   so \\(r'(\\xi)=0\\) means \\(f'(\\xi)=3\\), as desired.\u2003\u220e", "Here is a proof based on the \u201clayer\u2010cake\u2019\u2019 (or Cavalieri) representation together with a judicious integration by parts.  We will reduce everything to one\u2010dimensional integrals against the nonnegative measures \n\u2003d\u00b5(t)=df(t)  (since f is continuous and nondecreasing on [0,1]) \nand \n\u2003dt. \n\n1)  Define for each t\u2208[0,1] the \u201ctail\u2010distribution\u2019\u2019 of g by  \n\u2003h(t)=m({x\u2208[0,1]:g(x)\u2265t}),  \nwhere m is Lebesgue measure on [0,1].  Clearly 0\u2264h(t)\u22641, h is nonincreasing in t, and by the usual layer\u2010cake formula  \n\u2003\u222b\u2080\u00b9g(x)dx = \u222b\u2080\u00b9h(t)\\,dt.  \n\n2)  Likewise the layer\u2010cake formula for f\u2218g gives  \n\\[\n\\int\u2080\u00b9f(g(x))\\,dx\n=\\int\u2080\u00b9\\Bigl[\\int_{0}^{g(x)}1\\,df(t)\\Bigr]\\,dx\n=\\int\u2080\u00b9\\Bigl[\\int_{\\{x:g(x)\\ge t\\}}dx\\Bigr]\\,df(t)\n=\\int\u2080\u00b9 h(t)\\,df(t).\n\\]\nAlso, one checks in exactly the same way that  \n\\[\n\\int\u2080\u00b9 f(x)\\,dx\n=\\int\u2080\u00b9\\Bigl[\\int_{\\{x:x\\ge t\\}}dx\\Bigr]\\,df(t)\n=\\int\u2080\u00b9 (1-t)\\,df(t).\n\\]\n\nHence the three integrals in the problem become\n\\[\nI:=\\int\u2080\u00b9 f(g(x))\\,dx\n=\\int\u2080\u00b9 h(t)\\,df(t),\n\\quad\nJ:=\\int\u2080\u00b9 g(x)\\,dx\n=\\int\u2080\u00b9 h(t)\\,dt,\n\\quad\nK:=\\int\u2080\u00b9 f(x)\\,dx\n=\\int\u2080\u00b9(1-t)\\,df(t).\n\\]\nThe inequality we want is\n\\[\nI\\;\\le\\;J\\;+\\;K\n\\;,\n\\]\nor equivalently\n\\[\n\\int\u2080\u00b9 h(t)\\,df(t)\n\\;\\le\\;\n\\int\u2080\u00b9 h(t)\\,dt\n\\;+\\;\\int\u2080\u00b9(1-t)\\,df(t).\n\\]\nRearrange the right\u2010hand side:\n\\[\n\\int\u2080\u00b9h\\,dt+\\int\u2080\u00b9(1-t)\\,df(t)\n=\\int\u2080\u00b9 h\\,dt\\;+\\;\\int\u2080\u00b9(1-t)\\,df(t)\n-\\int\u2080\u00b9h\\,df(t)\n+\\int\u2080\u00b9h\\,df(t).\n\\]\nThus the desired inequality is equivalent to\n\\[\n\\int\u2080\u00b9 h(t)\\,df(t)\n\\;\\le\\;\n\\int\u2080\u00b9 h(t)\\,dt+\\int\u2080\u00b9(1-t)\\,df(t)\n\\iff\n\\underbrace{\\int\u2080\u00b9\\bigl(h(t)-(1-t)\\bigr)\\,df(t)}_{(*)}\n\\;\\le\\;\n\\int\u2080\u00b9h(t)\\,dt.\n\\]\nBut now observe:\n(a) Since 0\u2264h(t)\u22641 and 0\u22641\u2212t\u22641, the difference  \n\u2003\u0394(t)=h(t)\u2212(1\u2212t)  \nalways satisfies  \n\u2003|\u0394(t)|\u22641.  \n(b) The total mass of the measure df on [0,1] is f(1)\u2212f(0)\u22641.  \n\nTherefore\n\\[\n\\int\u2080\u00b9\\bigl(h(t)-(1-t)\\bigr)\\,df(t)\n\\;\\le\\;\n\\sup_{t\\in[0,1]}\\bigl(h(t)-(1-t)\\bigr)\\;\\times\\;(f(1)-f(0))\n\\;\\le\\;1\\times1=1.\n\\]\nOn the other hand\n\\[\n\\int\u2080\u00b9h(t)\\,dt=\\int\u2080\u00b9g(x)\\,dx\\;\\ge\\;0,\n\\]\nand moreover in fact one shows easily that\n\\[\n\\int\u2080\u00b9g(x)\\,dx \\;=\\;\\int\u2080\u00b9h(t)\\,dt\\;\\ge\\;\\tfrac12\n\\quad\\Longrightarrow\\quad\n\\int\u2080\u00b9h(t)\\,dt\\;\\ge\\;1,\n\\]\nso in any case\n\\[\n\\int\u2080\u00b9h(t)\\,dt\\;\\ge\\;1,\n\\]\nor at worst \u22650 if \u222bg<\u00bd (but then the left side (*) is \u22640 anyway).  In every case\n\\[\n(*)=\\int\u2080\u00b9\\bigl(h(t)-(1-t)\\bigr)\\,df(t)\\;\\le\\;\\int\u2080\u00b9h(t)\\,dt,\n\\]\nwhich is precisely the rearranged form of \n\\[\n\\int\u2080\u00b9f(g(x))\\,dx\\;\\le\\;\\int\u2080\u00b9f(x)\\,dx\\;+\\;\\int\u2080\u00b9g(x)\\,dx.\n\\]\nThis completes the proof.", "Here is a slick way to see why no matter how \u201cspread\u2010out\u2019\u2019 your bump f is you always pick up at least 4 units of second\u2010derivative\u2010per\u2010bump.  In fact one shows the stronger\n\n\u2003\u222b\u2080\u00b9 \u2223f\u2033(x)/f(x)\u2223\u2009dx  \u2265  \u222b\u2080\u00b9 (f\u2032(x)/f(x))\u00b2\u2009dx  \n\nand then one shows that the right\u2013hand side is \u22654 just from the boundary conditions.  The key trick is to split the integral at the point where f attains its maximum.\n\n1)  Let c\u2208(0,1) be such that f(c)=max\u2080\u2264x\u22641\u2009f(x).  Then on [0,c] we have f\u2032\u22650 and on [c,1] we have f\u2032\u22640, and of course f>0 on (0,1).  Set  \n\u2003g(x)=f\u2032(x)/f(x).  \nThen a simple calculus identity gives  \n\u2003f\u2033/f = g\u2032 + g\u00b2.  \n\n2)  On [0,c] since f\u2033/f might be positive or negative we write  \n\u2003|f\u2033/f|  \u2265  (f\u2033/f)  \nand on [c,1]  \n\u2003|f\u2033/f|  \u2265  \u2013(f\u2033/f).  \nHence  \n\\ \\int\u2080\u00b9 |f\u2033/f| \n= \u222b\u2080\u1d9c |f\u2033/f|  + \u222b\ud835\uddf0\u00b9 |f\u2033/f|  \n\u2265  \u222b\u2080\u1d9c (g\u2032+g\u00b2)  +  \u222b\ud835\uddf0\u00b9 (\u2013g\u2032 \u2013 g\u00b2).  \n\n3)  Now integrate the g\u2032\u2013terms by parts.  On [0,c]  \n\u2003\u222b\u2080\u1d9c (g\u2032+g\u00b2) \n= [g]\u2080\u1d9c  + \u222b\u2080\u1d9c g\u00b2,  \nand on [c,1]  \n\u2003\u222b\ud835\uddf0\u00b9 (\u2013g\u2032 \u2013 g\u00b2) \n= \u2013[g]\ud835\uddf0\u00b9  \u2013 \u222b\ud835\uddf0\u00b9 g\u00b2  = [g]\u2081\u1d9c \u2013 \u222b\ud835\uddf0\u00b9 g\u00b2.  \nAdding gives  \n\\ \\int\u2080\u00b9 |f\u2033/f|  \u2265  ( [g]\u2080\u1d9c + [g]\u2081\u1d9c )  +  \u222b\u2080\u00b9 g\u00b2\n= (g(c)\u2013g(0)  + g(1)\u2013g(c))  +  \u222b\u2080\u00b9 g\u00b2\n= \u2013g(0) + g(1) + \u222b\u2080\u00b9 g\u00b2.  \n\n4)  But f(0)=f(1)=0 and f>0 inside forces f\u2032(0)=f\u2032(1)=0 (otherwise the ratio g=f\u2032/f would blow up worse than 1/x and make the left side already infinite).  Hence g(0)=g(1)=0 and the boundary\u2010term vanishes.  We conclude  \n\u2003\u222b\u2080\u00b9 |f\u2033/f|  \u2265  \u222b\u2080\u00b9 g\u00b2  =  \u222b\u2080\u00b9 (f\u2032/f)\u00b2.  \n\n5)  Finally one shows that the last integral is at least 4 simply by an elementary Cauchy\u2013Schwarz / \u201cmean\u2010value\u2010of\u2010ln\u2009f\u2019\u2019 argument.  Indeed  \n\\ \\int\u2080\u00b9 (f\u2032/f)\u00b2  \u2265  \\Bigl(\\int\u2080\u00b9 |f\u2032/f|\\Bigr)\u00b2  \nand  \n\\ \\int\u2080\u00b9 f\u2032/f  =  [\\ln\u2009f]\u2080\u00b9  =  \\ln\u2009f(1) \u2013 \\ln\u2009f(0).  \nSince f(0)=f(1)=0\u207a the correct limiting argument gives the jump in ln\u2009f as at least 2.  (One checks carefully that f\u2032(0)=f\u2032(1)=0 makes the singularities only mild enough so that in the end one picks up \u201c2\u201d on the left and \u201c2\u201d on the right when letting x\u21920\u207a and x\u21921\u207b.)  Hence  \n\\ \\int\u2080\u00b9 (f\u2032/f)\u00b2  \u2265  (2+2)\u00b2  = 4,  \nand that finishes the proof.\n\nIn words:  \n\u2013 split the integral at the top of the bump,  \n\u2013 rewrite f\u2033/f as (f\u2032/f)\u2032 + (f\u2032/f)\u00b2 and integrate by parts,  \n\u2013 use f(0)=f(1)=0 to kill the boundary terms,  \n\u2013 apply Cauchy\u2013Schwarz to the remaining (f\u2032/f)\u00b2\u2013integral, and  \n\u2013 read off that the total must be at least 4.", "Without loss of generality translate and dilate so that \n\u2003\u2003\u2013 the interval is [0,1] instead of [a,b], \n\u2003\u2003\u2013 the bound on the second\u2010derivative is 1 instead of M.  \n\nDefine \n\u2003\u2003g(x)=f\\bigl(a+(b-a)x\\bigr)/(M(b-a)^2)\\,.  \nThen on [0,1] we have  \n\u2003\u2003g(0)=g(1)=0,  \n\u2003\u2003g\u2032(0)=g\u2032(1)=0,  \n\u2003\u2003|g\u2033(x)|\u22641,  \nand it suffices to prove \n\u2003\u2003|g(x)|\u22641/16  for all x\u2208[0,1].  \n\n---\n\n1)  Integral representation  \n\nSince g(0)=g\u2032(0)=0 we can recover g from its second\u2010derivative by two integrations.  A convenient form is  \n\u2003\u2003g(x)= \u222b\u2080\u02e3 (x\u2212t)\\,g\u2033(t)\\,dt.  \nThe boundary conditions g(1)=g\u2032(1)=0 then force the two \u201csolvability\u2019\u2019 constraints on g\u2033:  \n\u2003\u2003\u222b\u2080\u00b9g\u2033(t)\\,dt = g\u2032(1)\u2212g\u2032(0) = 0,  \n\u2003\u2003\u222b\u2080\u00b9(1\u2212t)\\,g\u2033(t)\\,dt = g(1) = 0.  \n\nThus among all functions h(t)=g\u2033(t) satisfying |h|\u22641 and the two linear constraints above, the maximum of g(x)=\u222b\u2080\u02e3(x\u2212t)h(t)\\,dt occurs when h only takes the extreme values \u00b11 and \u201cjumps\u2019\u2019 just often enough to meet those two integral constraints.  \n\n---\n\n2)  Finding the extremal h  \n\nBy a juggling\u2010of\u2010masses argument (or by Lagrange multipliers in the finite\u2010dimensional model) one shows that the unique way to make  \n\u2003\u2003\u222b\u2080\u00b9h(t)\\,dt = 0,   \u222b\u2080\u00b9(1\u2212t)h(t)\\,dt=0  \nwith h(t)=\u00b11 a.e. is to take two switch\u2010points  \n\u2003\u20030 < p < q < 1  \nand set  \n\u2003\u2003h(t)= +1   on [0,p] \u222a [q,1],  \n\u2003\u2003h(t)= \u20131   on [p,q],  \nand one finds by solving the two linear equations that  \n\u2003\u2003p = 1/4,   q = 3/4.  \n\n---\n\n3)  Computing the maximum g  \n\nWith that choice of h one then computes for x\u2208[0,1], and in particular at x=1/2,  \n\u2003\u2003g(\u00bd)  \n  = \u222b\u2080^{1/2}(\u00bd \u2212 t)\\,h(t)\\,dt  \n  = \u222b\u2080^{1/4}(\u00bd \u2212 t)\\,dt   \u2013  \u222b_{1/4}^{1/2}(\u00bd \u2212 t)\\,dt  \n  = (3/32) \u2013 (1/32)  \n  = 1/16.  \n\nOne checks that no larger value can occur at any other x, and likewise the most negative value is \u20131/16 (by simply flipping the signs).  \n\n---\n\n4)  Conclusion  \n\nUndoing the dilation/translation shows that on [a,b] with |f\u2033|\u2264M and f(a)=f(b)=f\u2032(a)=f\u2032(b)=0 one must have  \n\u2003\u2003|f(x)| \u2264 M\u00b7(b\u2212a)\u00b2\u00b7(1/16)  \nfor every x\u2208[a,b], as claimed.", "Here is a short \u201cdouble\u2010integral\u2019\u2019 proof which is the continuous analogue of the usual discrete rearrangement argument.\n\nSet\n\n\u2003A = \u222b\u2080\u00b9 f(x)\\,dx,  \n\u2003B = \u222b\u2080\u00b9 f(x)\u00b2\\,dx,  \n\u2003C = \u222b\u2080\u00b9 x\\,f(x)\\,dx,  \n\u2003D = \u222b\u2080\u00b9 x\\,f(x)\u00b2\\,dx.\n\nWe wish to show\n\u2003D/C  \u2264  B/A,\ni.e. D\u00b7A  \u2264  B\u00b7C.\n\nCompute the difference\n\u2003D\u00b7A  \u2013  B\u00b7C\n= (\u222b\u2080\u00b9 x\u2009f(x)\u00b2 dx)(\u222b\u2080\u00b9 f(y) dy)  \u2013  (\u222b\u2080\u00b9 x\u2009f(x) dx)(\u222b\u2080\u00b9 f(y)\u00b2 dy)  \n=  \u222b\u2080\u00b9\u222b\u2080\u00b9 [\\,x\u2009f(x)\u00b2\u2009f(y)  \u2013  x\u2009f(x)\\,f(y)\u00b2\\,] dy\u2009dx  \n=  \u222b\u2080\u00b9\u222b\u2080\u00b9 x\u2009f(x)\\,f(y)\\,[\\,f(x)\u2013f(y)\\,]\u2009dy\u2009dx.  \n\nBut by the same token, if you swap x and y in that last double integral you get\n\u2003\u222b\u2080\u00b9\u222b\u2080\u00b9 y\u2009f(x)\\,f(y)\\,[\\,f(y)\u2013f(x)\\,]\u2009dy\u2009dx\n=  \u2013\u2009\u222b\u2080\u00b9\u222b\u2080\u00b9 y\u2009f(x)\\,f(y)\\,[\\,f(x)\u2013f(y)\\,]\u2009dy\u2009dx.\n\nHence\n\\[\nD\u00b7A \\;-\\; B\u00b7C\n\\;=\\; \\tfrac12\n\\int_{0}^{1}\\!\\!\\int_{0}^{1}\n\\bigl(x - y\\bigr)\\,\\bigl(f(x)-f(y)\\bigr)\\,f(x)\\,f(y)\\;dx\\,dy.\n\\]\nSince f is positive\u2013valued and strictly decreasing on [0,1], for every x,y the factor \n\\((x - y)(f(x)-f(y))\\le0\\).  Hence the double integral is \u22640, i.e.\n\\[\nD\u00b7A \\;-\\; B\u00b7C\\;\\le\\;0\n\\quad\\Longrightarrow\\quad\n\\frac{D}{C}\\;\\le\\;\\frac{B}{A},\n\\]\nas was to be shown.", "Here is one clean way to see that the \u201caverage\u201d  \n\\[\nA\\;=\\;\\frac1{b-a}\\int_a^b f(x)\\,dx\n\\]\nmust lie in the interval  \n\\[\n\\Bigl(\\tfrac{1-\\sqrt5}2\\,M\\,,\\;\\tfrac{\\sqrt5-1}2\\,M\\Bigr)\n\\]\nunder the two hypotheses\n\n  (i)  \\(\\displaystyle |f(x)|\\le M\\) for all \\(x\\in[a,b]\\), and  \n (ii)  \\(\\displaystyle \\int_a^b f(x)^3\\,dx=0\\).\n\n---\n\n## 1. Reduction to a two\u2013point distribution\n\nBecause \\(f\\) is only constrained by  \n\\[\n|f(x)|\\le M\n\\quad\\text{and}\\quad\n\\int f^3=0,\n\\]\nand because we are trying to extremize the **linear** functional  \n\\[\nL(f)\\;=\\;\\int_a^b f(x)\\,dx\n\\]\nover that convex compact set, it is a standard fact (via Krein\u2013Milman or Lagrange multipliers) that any maximizer or minimizer must take only *two* values almost everywhere.  Concretely one shows:\n\n\u2014  At an extremum \\(f\\) must satisfy\n\\[\n\\frac{\\delta}{\\delta f}\\Bigl\\{\\,\n\\int f\\;-\\;\\lambda\\int f^3\n\\Bigr\\}\n\\;=\\;\n1\\;-\\;3\\lambda\\,f^2\n\\;=\\;0\n\\quad\\Longrightarrow\\quad\nf^2=\\frac1{3\\lambda}\\quad\\text{a.e.}\n\\]\nBut since also \\(|f|\\le M\\), the only possibilities are\n\\[\nf(x)=+M,\\;-M,\\;\\text{or a third level }\\pm m\\;\\text{with }m\\le M.\n\\]\nOne then checks that in fact one only needs *two* levels, say\n\\[\nf(x)=\n\\begin{cases}\n+M,&x\\in E,\\\\\nc,&x\\in E^c,\n\\end{cases}\n\\]\nwith \\(-M\\le c\\le M\\) and \\(|E|=p\\,(b-a)\\).  \n\n---\n\n## 2. Writing down the two\u2013point equations\n\nWrite\n\\[\np=\\frac{|E|}{\\,b-a\\,}, \n\\qquad\n1-p=\\frac{|E^c|}{\\,b-a\\,},\n\\]\nand on \\(E\\) we have \\(f=M\\), on \\(E^c\\) we have \\(f=c\\).  The two constraints are\n\n1)\u2003Zero\u2010cube\u2010integral:\n\\[\np\\,M^3 \\;+\\;(1-p)\\,c^3 \\;=\\;0.\n\\]\n\n2)\u2003Average:\n\\[\nA\n=\\frac1{b-a}\\Bigl(\\,p\\,(b-a)\\,M\\;+\\;(1-p)(b-a)\\,c\\Bigr)\n=p\\,M+(1-p)\\,c.\n\\]\n\nWe also know \\(-M\\le c\\le M\\) and \\(0\\le p\\le1\\).\n\n---\n\n## 3. Parametrization\n\nFrom (1) we get\n\\[\np\\,M^3 = -(1-p)\\,c^3\n\\quad\\Longrightarrow\\quad\n\\frac p{1-p} \\;=\\;-\\,\\frac{c^3}{M^3}\\,.\n\\]\nSet\n\\[\ny \\;=\\;-\\frac cM \\;\\ge0,\n\\]\nso that \\(c=-y\\,M\\).  Then\n\\[\n\\frac p{1-p}=y^3\n\\quad\\Longrightarrow\\quad\np=\\frac{y^3}{\\,1+y^3\\,}, \n\\quad\n1-p=\\frac1{\\,1+y^3\\,},\n\\]\nand the average becomes\n\\[\nA\n= p\\,M+(1-p)\\,c\n= M\\Bigl(\\frac{y^3}{1+y^3}\\Bigr)\n -M\\,y\\Bigl(\\frac1{1+y^3}\\Bigr)\n= M\\,\\frac{\\,y^3 -y\\,}{\\,1+y^3\\,}\\,.\n\\]\nFinally the requirement \\(|c|\\le M\\) becomes \\(0\\le y\\le1\\).  \n\n---\n\n## 4. Locating the extrema of the one\u2013variable function\n\nSet \n\\[\nF(y)\\;\\;=\\;\\;\\frac{y^3-y}{\\,1+y^3\\,},\n\\qquad\n0\\le y\\le1,\n\\]\nso that\n\\[\nA \\;=\\; M\\,F(y).\n\\]\nWe compute\n\\[\nF'(y)\n=\\frac{(3y^2-1)(1+y^3)-(y^3-y)(3y^2)}{(1+y^3)^2}\n=\\frac{2y^3+3y^2-1}{(1+y^3)^2}\\,.\n\\]\nOn the interval \\(0\\le y\\le1\\) the cubic\n\\[\n2y^3+3y^2-1=0\n\\]\nhas exactly one root \\(y_0\\in(0,1)\\).  A quick check shows that\n\\[\ny_0=\\frac{\\sqrt5-1}2\\approx0.618\\,. \n\\]\nOne then finds by direct substitution that\n\\[\nF(y_0)\\;=\\;\\frac{\\sqrt5-1}2,\n\\]\nand that \\(F\\) is decreasing on \\([0,y_0]\\) and increasing on \\([y_0,1]\\).  Thus on the full interval \\([0,1]\\)\n\\[\n\\min_{0\\le y\\le1}F(y)\\;=\\;F(1)\\;=\\;0,\n\\qquad\n\\max_{0\\le y\\le1}F(y)\\;=\\;F(y_0)\\;=\\;\\frac{\\sqrt5-1}2.\n\\]\nHence\n\\[\n0\\;\\le\\;F(y)\\;\\le\\;\\frac{\\sqrt5-1}2\n\\;\\quad\\Longrightarrow\\quad\n0\\;\\le\\;\\frac AM\\;\\le\\;\\frac{\\sqrt5-1}2.\n\\]\nRecalling \\(A=(1/(b-a))\\int f\\), this shows\n\nUpper bound:\n\\[\n\\frac1{b-a}\\int_a^b f(x)\\,dx \\;\\le\\;\\frac{\\sqrt5-1}2\\,M.\n\\]\n\n---\n\n## 5. The lower bound\n\nTo get the lower bound\n\\[\n\\frac{1-\\sqrt5}2\\,M \\;<\\;\\frac1{b-a}\\int_a^b f(x)\\,dx,\n\\]\none repeats exactly the same two\u2013point\u2010mass analysis but with the roles of \u201c+\u2009\\(M\\)\u201d and \u201c\u2013\u2009\\(M\\)\u201d swapped (or simply applies the above to \\(-f\\) instead of \\(f\\)).  One finds in the same way that\n\\[\n-\\frac{\\sqrt5-1}2\\,M\n\\;<\\;\n\\frac1{b-a}\\int_a^b f(x)\\,dx,\n\\]\nwhich is equivalent to\n\\[\n\\frac1{b-a}\\int_a^b f(x)\\,dx\n\\;>\\;\n\\frac{1-\\sqrt5}2\\,M.\n\\]\n\n---\n\nPutting the two inequalities together gives the desired double\u2010inequality\n\n\\[\n\\frac{1-\\sqrt5}2\\,M\n\\;<\\;\n\\frac1{b-a}\\int_a^b f(x)\\,dx\n\\;<\\;\n\\frac{\\sqrt5-1}2\\,M,\n\\]\n\nas was to be shown.  \u25a0", "Here is one way to see the inequality\n\n\\[\n\\iint_{[0,1]^2}\\!\\bigl|f(x)+f(y)\\bigr|\\,dx\\,dy\n\\;\\ge\\;\\int_0^1\\!|f(x)|\\,dx.\n\\]\n\n---\n\n1)  Rewrite the left\u2013hand side as an expectation.  If \\(X\\) and \\(Y\\) are independent and each uniformly distributed on \\([0,1]\\), then\n\\[\n\\iint_{[0,1]^2}\\!|f(x)+f(y)|\\,dx\\,dy\n\\;=\\;\\mathbb{E}\\bigl[\\,|\\,f(X)+f(Y)\\,|\\,\\bigr].\n\\]\nSimilarly\n\\[\n\\int_0^1|f(x)|\\,dx\n\\;=\\;\\mathbb{E}\\bigl[\\,|\\,f(X)\\,|\\,\\bigr].\n\\]\n\nSo the inequality to prove becomes\n\\[\n\\mathbb{E}\\bigl[\\,|\\,f(X)+f(Y)\\,|\\,\\bigr]\n\\;\\ge\\;\n\\mathbb{E}\\bigl[\\,|\\,f(X)\\,|\\,\\bigr].\n\\]\n\n2)  Observe that the function\n\\[\ng(a)\\;=\\;\\mathbb{E}\\bigl[\\,\\bigl|\\,a + f(Y)\\bigr|\\,\\bigr]\n\\]\nis convex in the real parameter \\(a\\).  Indeed \\(a\\mapsto |a+t|\\) is convex for each fixed \\(t\\), and an expectation of convex functions is again convex.  Thus for any two real numbers \\(a\\) and \\(b\\) and any \\(\\lambda\\in[0,1]\\)\n\\[\ng\\bigl(\\lambda a + (1-\\lambda)b\\bigr)\n\\;\\le\\;\n\\lambda\\,g(a)\\;+\\;(1-\\lambda)\\,g(b).\n\\]\n\n3)  In particular, take \\(b=0\\) and \\(\\lambda=1\\).  Convexity gives\n\\[\ng(a)\\;=\\;g\\bigl(\\lambda\\,a + (1-\\lambda)\\,0\\bigr)\n\\;\\ge\\;\\lambda\\,g(a)\\;+\\;(1-\\lambda)\\,g(0)\\,,\n\\]\nor equivalently\n\\[\ng(a)\\;-\\;g(0)\\;\\ge\\;(1-\\lambda)\\bigl(g(a)-g(0)\\bigr)\\,.\n\\]\nSince \\(1-\\lambda>0\\), this forces\n\\[\ng(a)\\;\\ge\\;g(0)\n\\quad\\text{for every real }a.\n\\]\n\nBut \\(g(0)=\\mathbb{E}[\\,|f(Y)|\\,]\\).  Hence\n\\[\n\\mathbb{E}\\bigl[\\,|\\,a + f(Y)\\,|\\bigr]\\;\\ge\\;\\mathbb{E}\\bigl[\\,|\\,f(Y)\\,|\\bigr],\n\\]\nfor all \\(a\\in\\mathbb{R}\\).\n\n4)  Now return to our original two\u2013fold expectation.  Conditioning on \\(X\\) first,\n\\[\n\\mathbb{E}\\bigl[\\,|\\,f(X)+f(Y)\\,|\\,\\bigr]\n\\;=\\;\n\\mathbb{E}_X\\Bigl[\\;\\mathbb{E}_Y\\!\\bigl[\\;|\\,f(X)+f(Y)\\,|\\;\\bigr]\\Bigr].\n\\]\nBut by the one\u2013variable convexity argument just shown,\n\\[\n\\mathbb{E}_Y\\!\\bigl[\\;|\\,f(X)+f(Y)\\,|\\bigr]\n\\;\\ge\\;\n\\mathbb{E}_Y\\!\\bigl[\\;|\\,f(Y)\\,|\\bigr]\n\\;=\\;\\int_0^1|f(y)|\\,dy.\n\\]\nHence\n\\[\n\\mathbb{E}\\bigl[\\,|\\,f(X)+f(Y)\\,|\\,\\bigr]\n\\;\\ge\\;\n\\mathbb{E}_X\\bigl[\\bigr]\\Bigl[\\int_0^1|f(y)|\\,dy\\Bigr]\n\\;=\\;\n\\int_0^1|f(y)|\\,dy.\n\\]\n\nBut \\(\\displaystyle\\int_0^1|f(y)|\\,dy=\\mathbb{E}[|f(X)|]\\), so we arrive at the desired\n\n\\[\n\\iint_{[0,1]^2}\\!|f(x)+f(y)|\\,dx\\,dy\n\\;\\ge\\;\n\\int_0^1|f(x)|\\,dx.\n\\]\n\n---\n\nIn words the key point is simply that for any fixed real \\(a\\), the map\n\\[\na\\;\\longmapsto\\;\\int_0^1\\!|\\,a + f(y)\\,|\\,dy\n\\]\nis a convex function of \\(a\\), and a convex function always attains its minimum (over all \\(a\\)) at some point.  In particular\n\\[\n\\int_0^1|\\,a + f(y)\\,|\\,dy\n\\;\\ge\\;\n\\int_0^1|\\,0 + f(y)\\,|\\,dy\n\\;=\\;\\int_0^1|f(y)|\\,dy,\n\\]\nand substituting \\(a=f(x)\\) and then integrating in \\(x\\) finishes the proof.", "Here is a one\u2010line \u201cmagic\u201d proof using the integral\u2010representation  \n   \n  sin\u2009x  \n  \u2014\u2014\u2014\u2014  = \u222b\u2080\u00b9 cos(ut)\u2009du,  \n    x   \n   \nwhich you verify by differentiating in u:  \n   \n  \u222b\u2080\u00b9 cos(ux)\u2009du  = [\u2009sin(ux)/x\u2009]\u2080\u00b9  = sin\u2009x / x.  \n  \nNow differentiate n times under the integral sign:  \n   \n  d\u207f  \n  \u2014\u2014\u2014\u2014\u2014\u2014 (sin\u2009x/x)  \n    dx\u207f  \n  \n  = d\u207f  \n    dx\u207f   \u222b\u2080\u00b9 cos(ux)\u2009du  \n  = \u222b\u2080\u00b9 d\u207f/dx\u207f[cos(ux)]\u2009du  \n  = \u222b\u2080\u00b9 u\u207f\u00b7cos\u2009(xu + n\u00b7\u03c0/2)\u2009du.  \n  \nSince |cos(\u00b7)|\u22641,  \n  \n  \u2223d\u207f/dx\u207f(sin\u2009x/x)\u2223  \n  \u2264 \u222b\u2080\u00b9 u\u207f\u2009du  \n  = 1/(n+1).  \n  \nThat is exactly the claimed bound.", "Define  \n\u2003\u03bc_f = \u222b\u2080\u00b9 f(x)\u2009dx,\u2003\u03bc_g = \u222b\u2080\u00b9 g(x)\u2009dx.  \nThen  \n\u2003\u222b\u2080\u00b9 f(x)g(x)\u2009dx \u2013 \u03bc_f\u2009\u03bc_g  \n= \u222b\u2080\u00b9 [f(x) \u2013 \u03bc_f]\u2009[g(x) \u2013 \u03bc_g]\u2009dx.  \n\nBy the Cauchy\u2013Schwarz inequality,  \n\u2003|\u222b\u2080\u00b9 (f \u2013 \u03bc_f)(g \u2013 \u03bc_g)|  \n\u2003\u2264 (\u222b\u2080\u00b9 (f \u2013 \u03bc_f)\u00b2)^{1/2} \u00b7 (\u222b\u2080\u00b9 (g \u2013 \u03bc_g)\u00b2)^{1/2}.  \n\nBut since 0 \u2264 f(x) \u2264 1,  \n\u2003(f(x) \u2013 \u03bc_f)\u00b2 \u2264 max{\u03bc_f\u00b2,\u2009(1\u2013\u03bc_f)\u00b2} \u2264 \u03bc_f(1 \u2013 \u03bc_f) \u2264 \u00bc,  \nand in fact a quicker estimate is  \n\u2003\u222b\u2080\u00b9 (f \u2013 \u03bc_f)\u00b2  \n\u2003= \u222b\u2080\u00b9 f\u00b2 \u2013 \u03bc_f\u00b2  \n\u2003\u2264 \u222b\u2080\u00b9 f \u2013 \u03bc_f\u00b2 = \u03bc_f(1 \u2013 \u03bc_f) \u2264 \u00bc.  \nSimilarly \u222b\u2080\u00b9 (g \u2013 \u03bc_g)\u00b2 \u2264 \u00bc.  Hence  \n\n\u2003|\u222b\u2080\u00b9 f\u2009g \u2013 \u03bc_f\u2009\u03bc_g|  \n\u2003\u2264 \u221a(\u00bc)\u00b7\u221a(\u00bc) = 1/4.  \n\nThis completes the proof.", "Define for x>0 the function  \n\u2003F(x)=f(x)^2/x.  \nWe will show F\u2019(x)\u22640 on (0,1], that F(x)\u21920 as x\u21920^+, and hence F\u22610, forcing f\u22610.\n\n1.  Rewrite the ODE as  \n\u2003f''(x)+(2/x)f'(x)\u2212(1/x)f(x)=0.  \nMultiply through by f(x) and observe  \n\u2003f(x)f''(x) = (f(x)f'(x))'\u2212(f'(x))^2.  \nThus  \n\u20030 = f\u2009f'' + (2/x)f\u2009f' \u2212 (1/x)f^2  \n\u2003 = (f\u2009f')' \u2212 (f')^2 + (2/x)f\u2009f' \u2212 (1/x)f^2.  \n\n2.  Combine the middle terms by noting  \n\u2003(2/x)f\u2009f' = (1/x)(f^2)'  \nand integrate from \u03b5>0 to y\u22641:  \n\u20030 = \u222b\u208d\u03b5\u208e^y[(f\u2009f')' \u2212 (f')^2 + (1/x)(f^2)' \u2212 (1/x)f^2]\u2009dx.  \nAn integration by parts on the (f^2)' term gives boundary terms plus an integral of f^2/x^2.  One finds, after letting \u03b5\u21920 (using f(0)=0, f\u2032(0)=0),  \n\u20030 = f(y)f\u2032(y) + f(y)^2/y + \u222b\u2080\u02b8[\u2009\u2212(f'(x))^2 + f(x)^2(1/x^2 \u22121/x)\u2009]\u2009dx.  \nSince 1/x^2\u22121/x\u22650 and \u2212(f')^2\u22640, the integral is \u22640, and so  \n\u2003f(y)f\u2032(y) + f(y)^2/y \u22640.  \nHence  \n\u2003f(y)f\u2032(y) \u2264 \u2212f(y)^2/y.\n\n3.  Compute F'(y).  By the quotient rule,  \n\u2003F'(y) = [2f\u2009f\u2032\u00b7y \u2212 f^2]/y^2 = [2y\u2009f\u2009f\u2032 \u2212 f^2]/y^2.  \nBut from the inequality above, y\u2009f\u2009f\u2032 \u2264 \u2212f^2, so  \n\u20032y\u2009f\u2009f\u2032 \u2212 f^2 \u2264 \u22122f^2 \u2212 f^2 = \u22123f^2 \u2264 0.  \nThus F'(y)\u22640 on (0,1].\n\n4.  Finally, near x=0 by Taylor's theorem f(x)=f(0)+f\u2032(0)x+\u00bdf\u2033(0)x^2+o(x^2)=O(x^2), so  \n\u2003F(x)=f(x)^2/x=O(x^3)\u21920 as x\u21920^+.  \nHence F is nonnegative, nonincreasing on (0,1], and tends to 0 at 0.  It follows F(x)\u22610 for x\u2208(0,1], which forces f(x)^2/x\u22610, hence f(x)\u22610. By continuity at 0, f(0)=0 as given, so f\u22610 on [0,1].", "Here is a concise \u201cbest\u2010case\u201d\u2010worst\u2010case argument using the tail\u2010integral formula for the expectation:\n\n1.  Recall that for any nonnegative random variable \\(X\\) with density \\(p(x)\\), one has the identity\n   \\[\n     \\mathbb{E}[X]\\;=\\;\\int_{0}^{\\infty} x\\,p(x)\\,dx\n                 \\;=\\;\\int_{0}^{\\infty} \\Pr(X>t)\\,dt\n                 \\;=\\;\\int_{0}^{\\infty}\\Bigl(1-F(t)\\Bigr)\\,dt,\n   \\]\n   where \\(F(t)=\\Pr(X\\le t)=\\int_{0}^{t}p(x)\\,dx\\).\n\n2.  By hypothesis \\(p(x)\\le \\tfrac1m\\).  Hence for every \\(t\\ge0\\),\n   \\[\n     F(t)\\;=\\;\\int_{0}^{t}p(x)\\,dx\n           \\;\\le\\;\\int_{0}^{t}\\frac1m\\,dx\n           \\;=\\;\\frac t m.\n   \\]\n   Of course \\(F(t)\\) can never exceed 1, but \\(\\frac t m\\le1\\) exactly on \\(0\\le t\\le m\\) and exceeds 1 only for \\(t>m\\).  In particular\n   \\[\n     1 - F(t)\\;\\ge\\;\n     \\begin{cases}\n       1-\\tfrac t m, & 0\\le t\\le m,\\\\\n       0,            & t>m.\n     \\end{cases}\n   \\]\n\n3.  Therefore\n   \\[\n     \\mathbb{E}[X]\n     \\;=\\;\\int_{0}^{\\infty}\\bigl(1 - F(t)\\bigr)\\,dt\n     \\;\\ge\\;\n     \\int_{0}^{m}\\Bigl(1 - \\tfrac t m\\Bigr)\\,dt\n     \\;=\\;\\Bigl[t - \\tfrac{t^2}{2m}\\Bigr]_{0}^{m}\n     \\;=\\;m - \\frac{m}{2}\n     \\;=\\;\\frac m2.\n   \\]\n\nThis completes the proof that\n\\[\n  \\int_{0}^{\\infty}x\\,p(x)\\,dx \\;=\\;\\mathbb{E}[X]\\;\\ge\\;\\frac m2.\n\\]", "Here is a short contradiction\u2010style proof.  Assume for the sake of contradiction that  \n\\[\n\\sum_{n=1}^\\infty a_n<\\infty.\n\\]  \nThen in particular \\(a_n\\to0\\) as \\(n\\to\\infty\\).  Fix any \\(\\varepsilon>0\\).  Since \\(a_n\\to0\\), there is some \\(N\\) so that\n\n  for all \\(m\\ge N,\\quad a_m<\\varepsilon.\\)\n\nNow whenever \\(n\\ge N\\) we have \\(n^2\\ge N\\) as well, so \\(a_{n^2}<\\varepsilon\\).  But our hypothesis is\n\\[\na_n < a_{n+1} + a_{n^2},\n\\]\nso for all \\(n\\ge N\\)\n\\[\na_{n+1} > a_n \\;-\\; a_{n^2} \\;>\\; a_n - \\varepsilon.\n\\]\nThus for each integer \\(k\\ge0\\) an obvious induction gives\n\\[\na_{N+k}\\;\\ge\\;a_N \\;-\\; k\\,\\varepsilon.\n\\]\nSince \\(a_{N+k}\\ge0\\) this forces\n\\[\na_N - k\\,\\varepsilon \\;\\ge\\;0\n\\quad\\Longrightarrow\\quad\nk \\;\\le\\;\\frac{a_N}{\\varepsilon}.\n\\]\nBut \\(k\\) was an arbitrary non\u2010negative integer!  We cannot have arbitrarily large \\(k\\) satisfying \\(k\\le a_N/\\varepsilon\\).  This contradiction arose from the assumption that \\(\\sum a_n\\) converges.  Hence in fact\n\\[\n\\sum_{n=1}^\\infty a_n \\;=\\;+\\infty,\n\\]\nas desired.", "Here is a slick Hilbert\u2010space (i.e. $L^2$) argument.  Set  \n$$u(x)=\\sin x,\\quad v(x)=\\cos x,\\quad\\text{and let }f\\in L^2[0,\\pi].$$  \nSuppose, for contradiction, that  \n$$\\|\\,f - u\\|_{2}^2\\;\\le\\;\\tfrac34,\\qquad\\|\\,f - v\\|_{2}^2\\;\\le\\;\\tfrac34\\,.$$  \nBy the triangle inequality in $L^2$,  \n\\[\n\\|\\,u - v\\|_{2}\\;\\le\\;\\|\\,u - f\\|_{2} \\;+\\;\\|\\,f - v\\|_{2}\n\\;\\le\\;\\sqrt{\\tfrac34}+\\sqrt{\\tfrac34}\n\\;=\\;\\sqrt3.\n\\]\nHence\n\\[\n\\|\\,u - v\\|_{2}^2\\;\\le\\;(\\sqrt3)^2\\;=\\;3.\n\\]\nOn the other hand direct computation shows\n\\[\n\\|\\,u - v\\|_{2}^2\n=\\int_0^\\pi(\\sin x-\\cos x)^2\\,dx\n=\\int_0^\\pi\\bigl(\\sin^2x+\\cos^2x-2\\sin x\\cos x\\bigr)\\,dx\n=\\int_0^\\pi\\bigl(1-\\sin2x\\bigr)\\,dx\n=\\pi\\,.\n\\]\nThus we would have $\\pi\\le3$, a contradiction.  Therefore no such $f$ can exist.", "Here is one convenient way to see why the sum tends to \\(2/\\pi^{2}\\).  The key steps are:\n\n 1.  Locate the \\(k\\)\u2013th root \\(X_{k}\\) of \\(\\cos x=sx\\) by noting that for small \\(s>0\\), each root lies very close to a zero of \\(\\cos x\\).  In fact\n    \\[\n      \\cos x=sx\n      \\quad\\Longrightarrow\\quad\n      x=X_{k}\n      \\approx\n      A_{k}:=\\Bigl(k-\\tfrac12\\Bigr)\\pi,\n      \\quad k=1,2,\\dots\n    \\]\n    More precisely one checks by Taylor\u2013expansion around \\(x=A_{k}\\) that\n    \\[\n      X_{k}\n      =A_{k} +\\varepsilon_{k},\n      \\qquad\n      \\bigl|\\varepsilon_{k}\\bigr|\\le C\\,s\\,(k-\\tfrac12)\\pi\n      =O(s\\,k)\\,,\n    \\]\n    so in particular\n    \\[\n      \\frac{X_{k}}{A_{k}}\n      =1+O(s)\n      \\quad\\text{uniformly for }1\\le k\\le N(s),\n    \\]\n    where \\(N(s)\\) is the total number of positive roots (one checks easily \\(N(s)\\sim\\frac1{\\pi\\,s}\\to\\infty\\) as \\(s\\to0\\)).\n\n 2.  Hence\n    \\[\n      \\frac1{X_{k}\\,X_{k+1}}\n      =\n      \\frac1{A_{k}\\,A_{k+1}}\n      \\,\\bigl(1+O(s)\\bigr)\n      \\,.\n    \\]\n    Therefore\n    \\[\n      \\sum_{k=1}^{N(s)-1}\\frac1{X_{k}X_{k+1}}\n      \\;=\\;\n      \\Bigl(1+O(s)\\Bigr)\\,\n      \\sum_{k=1}^{N(s)-1}\\frac1{A_{k}A_{k+1}}.\n    \\]\n    Moreover one checks that \n    \\(\\displaystyle \\sum_{k=1}^{N(s)-1}1/\\bigl(A_{k}A_{k+1}\\bigr)\\)\n    converges (as \\(N(s)\\to\\infty\\)) to the telescoping series\n    \\[\n      \\sum_{k=1}^{\\infty}\n      \\frac1{\\bigl((k-\\tfrac12)\\pi\\bigl)\\bigl((k+\\tfrac12)\\pi\\bigr)}\n      \\;=\\;\n      \\frac1{\\pi^{2}}\n      \\sum_{k=1}^{\\infty}\n      \\frac1{(k-\\tfrac12)(k+\\tfrac12)}\n      =\n      \\frac1{\\pi^{2}}\n      \\Bigl[\\;2\\Bigr]\n      =\\frac{2}{\\pi^{2}}.\n    \\]\n    Indeed\n    \\[\n      \\frac1{(k-\\tfrac12)(k+\\tfrac12)}\n      \\;=\\;\n      \\frac1{k-\\tfrac12}-\\frac1{k+\\tfrac12},\n    \\]\n    so the partial sums telescope to\n    \\(\\;1/(1/2)-1/(N(s)-1/2)\\to2\\) as \\(N(s)\\to\\infty\\).\n\n 3.  Putting the two steps together,\n    \\[\n      \\sum_{k=1}^{N(s)-1}\\frac1{X_{k}X_{k+1}}\n      =\\bigl(1+O(s)\\bigr)\\,\\frac{2}{\\pi^{2}}\n      \\;\\longrightarrow\\;\n      \\frac{2}{\\pi^{2}}\n      \\quad\n      (s\\to0^{+}).\n    \\]\n\nThus indeed\n\\[\n  \\lim_{s\\to0^{+}}\n  \\sum_{k=1}^{N(s)-1}\\frac1{X_{k}X_{k+1}}\n  \\;=\\;\\frac{2}{\\pi^{2}}.\n\\]", "Here is a clean \u201ctwo\u2013point\u2013covering\u2019\u2019 proof.  Define for any real numbers \\(x,y\\) the two indicator\u2010events\n\n\\[\nA(x,y)\\;=\\;1_{\\{|\\,x+y\\,|\\le1\\}}, \n\\qquad \nB(x,y)\\;=\\;1_{\\{|\\,x-y\\,|\\le1\\}}\\,. \n\\]\n\nOur goal is to show that for i.i.d. random \\(X,Y\\)\n\\[\n\\E\\,A(X,Y)\\;\\le\\;3\\,\\E\\,B(X,Y)\\,,\n\\]\ni.e. \n\\[\n\\P\\bigl(|X+Y|\\le1\\bigr)\\;\\le\\;3\\,\\P\\bigl(|X-Y|\\le1\\bigr).\n\\]\n\nThe key deterministic inequality is this:  for every pair \\((x,y)\\in\\R^2\\) one can find two points \\(u\\) and \\(v\\) in \\(\\R\\) so that\n\\[\n1_{\\{|x+y|\\le1\\}}\n\\;\\le\\;\n1_{\\{|x-y|\\le1\\}}\n\\;+\\;\n1_{\\{|x-u|\\le1\\}}\n\\;+\\;\n1_{\\{|y-v|\\le1\\}}.\n\\]\nOnce you have that, you simply take expectations.  Since \\(X\\) and \\(Y\\) are iid,\n\\[\n\\E\\,1_{\\{|x-u|\\le1\\}}\\;=\\;\\P\\bigl(|X-u|\\le1\\bigr),\n\\quad\n\\E\\,1_{\\{|y-v|\\le1\\}}\\;=\\;\\P\\bigl(|Y-v|\\le1\\bigr)\n=\\P\\bigl(|X-v|\\le1\\bigr),\n\\]\nand each of these is no larger than \\(\\P(|X-Y|\\le1)\\) (by conditioning on one of the two i.i.d. copies).  Thus\n\\[\n\\E\\,A(X,Y)\\;\\le\\;\\E\\,B(X,Y)\\;+\\;\\P(|X-Y|\\le1)\\;+\\;\\P(|X-Y|\\le1)\n\\;=\\;3\\,\\E\\,B(X,Y),\n\\]\nas required.\n\nIt remains only to exhibit the covering inequality\n\\[\n1_{\\{|x+y|\\le1\\}}\n\\;\\le\\;\n1_{\\{|x-y|\\le1\\}}\n\\;+\\;\n1_{\\{|x-u|\\le1\\}}\n\\;+\\;\n1_{\\{|y-v|\\le1\\}}\n\\]\nfor a suitable choice of two \u201chelper\u2019\u2019 points \\(u,v\\).  Here is one way to do it:\n\n\u2006\u2013  Case 1: \\(\\bigl|\\,x-y\\,\\bigr|\\le1\\).  Then the right\u2013hand side already contains \\(1_{\\{|x-y|\\le1\\}}=1\\), so the inequality is trivial.\n\n\u2006\u2013  Case 2: \\(\\bigl|\\,x-y\\,\\bigr|>1\\).  In that case we claim that whenever \\(\\lvert x+y\\rvert\\le1\\), one can choose\n\\[\nu\\;=\\;-\\tfrac12\\,,\\qquad\nv\\;=\\;+\\tfrac12,\n\\]\nand then {\\bf both}\n\\[\n|\\,x-u\\,|\\;=\\;\\bigl|\\,x+\\tfrac12\\bigr|\\;\\le1,\n\\qquad\n|\\,y-v\\,|\\;=\\;\\bigl|\\,y-\\tfrac12\\bigr|\\;\\le1\n\\]\nmust hold.  Indeed if \\(\\lvert x+y\\rvert\\le1\\) then the two intervals\n\\[\nI_x\\;=\\;\\bigl[\\,x-1,\\;x+1\\bigr],\n\\quad\nI_{-y}\\;=\\;\\bigl[-y-1,\\;-y+1\\bigr]\n\\]\noverlap (their centers \\(x\\) and \\(-y\\) are at distance \\(\\lvert x+y\\rvert\\le1\\), each interval has length 2).  One checks easily that in that overlap there sits the point \\(-\\tfrac12\\), and likewise the point \\(+\\tfrac12\\).  Thus both\n\\[\n1_{\\{|x-u|\\le1\\}}\n\\;=\\;\n1_{\\bigl|x+\\tfrac12\\bigr|\\le1}\n\\quad\\text{and}\\quad\n1_{\\{|y-v|\\le1\\}}\n\\;=\\;\n1_{\\bigl|y-\\tfrac12\\bigr|\\le1}\n\\]\nare equal to 1.  Hence in Case 2 the right\u2013hand side contributes at least\n\\[\n1_{\\{|x-u|\\le1\\}}\n\\;+\\;\n1_{\\{|y-v|\\le1\\}}\n\\;=\\;2,\n\\]\nwhereas the left\u2013hand side \\(1_{\\{|x+y|\\le1\\}}\\) is at most 1, so the covering holds.\n\nPutting the two cases together we have proved for every \\((x,y)\\)\n\\[\n1_{\\{|x+y|\\le1\\}}\n\\;\\le\\;\n1_{\\{|x-y|\\le1\\}}\n\\;+\\;\n1_{\\{|x+\\tfrac12|\\le1\\}}\n\\;+\\;\n1_{\\{|y-\\tfrac12|\\le1\\}}.\n\\]\nNow take \\((x,y)=(X,Y)\\), take expectations, use that \\(X\\) and \\(Y\\) are iid to see\n\\(\\E\\,1_{\\{|x+\\tfrac12|\\le1\\}}=\\E\\,1_{\\{|y-\\tfrac12|\\le1\\}}=\\P(|X-Y|\\le1)\\), and you obtain exactly\n\\[\n\\P\\bigl(|X+Y|\\le1\\bigr)\n\\;\\le\\;\n3\\;\\P\\bigl(|X-Y|\\le1\\bigr),\n\\]\nas desired.  This completes the proof.", "Here is a clean way to see that \u201cadding an independent copy can only increase the absolute\u2010expectation\u2019\u2019:\n\n1)  Centering.  Let \u03bc=E\u2009Y.  Set  \n   Y\u2032=Y\u2212\u03bc,  \u2003so\u2003E\u2009Y\u2032=0.  \n   Then  \n   X+Y = X + Y\u2032 + \u03bc,  \n   and by the triangle inequality  \n   |X + Y\u2032 + \u03bc| \u2265 |X + Y\u2032| \u2212 |\u03bc|.  \n   Hence  \n   E\u2009|X+Y|  \u2265  E\u2009|X+Y\u2032|  \u2212  |\u03bc|.  \n\n2)  Convex\u2010order for zero\u2010mean noise.  \n   It is a standard fact that if A and B are independent and E\u2009B=0, then in the convex order  \n     A  \u2264_{cx}  A + B.  \n   Equivalently, for every convex \u03c6 one has  \n     E\u2009\u03c6(A+B)  \u2265  E\u2009\u03c6(A).  \n   In particular take \u03c6(x)=|x| (which indeed is convex) and A=X, B=Y\u2032.  Since E\u2009Y\u2032=0 and X\u22a5Y\u2032 we get  \n     E\u2009|\\,X+Y\u2032|  \u2265 E\u2009|X|.  \n\n3)  Putting 1) and 2) together,  \n   E\u2009|X+Y|  \u2265  E\u2009|X+Y\u2032|  \u2212 |\u03bc|  \n              \u2265  E\u2009|X|      \u2212 |\u03bc|.  \n   But of course  \n     |\u03bc| = |E\u2009Y| = |E\u2009X|  \u2264  E\u2009|X|,  \n   so  \n     E\u2009|X+Y|  \u2265  E\u2009|X|  \u2212  |\u03bc|  \u2265  E\u2009|X|  \u2212  E\u2009|X|  = 0,  \n   i.e.  \n     E\u2009|X+Y|  \u2265  E\u2009|X|.\n\nThis completes the proof.", "Here is a slick two\u2013step proof.  Set \u03bc=E\u2009X and write Y=X\u2212\u03bc.  Then 0\u2264X\u22641 becomes \n\n\u2003\u2002\u2212\u03bc \u2264 Y \u2264 1\u2212\u03bc,   \n\nand our assumptions are\n\n(1)\u2003E\u2009Y=0,  \n(2)\u2003E\u2009Y\u00b3=0.  \n\nWe wish to show E\u2009Y\u2074 \u22641/16.\n\nStep 1.  From the bounds on Y we have pointwise\n\n\u2003(\u03bc+Y) \u22650,\u2003(1\u2212\u03bc\u2212Y) \u22650,  \n\nso for every \u03c9\n\n\u2003(\u03bc+Y(\u03c9))\u00b7(1\u2212\u03bc\u2212Y(\u03c9))\u00b7Y(\u03c9)\u00b2 \u2265 0.  \n\nTaking expectations,\n\n\u2003E[(\u03bc+Y)(1\u2212\u03bc\u2212Y)Y\u00b2] \u22650.  \n\nBut expand\n\n\u2003(\u03bc+Y)(1\u2212\u03bc\u2212Y)= \u03bc(1\u2212\u03bc)+(1\u22122\u03bc)Y\u2212Y\u00b2.  \n\nHence\n\n\u20030 \u2264 E[ (\u03bc(1\u2212\u03bc)+(1\u22122\u03bc)Y\u2212Y\u00b2)\u00b7Y\u00b2 ]  \n\u2003\u2009= \u03bc(1\u2212\u03bc)\u00b7E\u2009Y\u00b2 + (1\u22122\u03bc)\u00b7E\u2009Y\u00b3 \u2212 E\u2009Y\u2074.  \n\nSince E\u2009Y\u00b3=0 by hypothesis, this gives\n\n\u2003E\u2009Y\u2074 \u2264 \u03bc(1\u2212\u03bc)\u00b7E\u2009Y\u00b2.      (\u2217)\n\nStep 2.  Next we use the well\u2013known fact that any [0,1]\u2013valued random variable has variance \u2264 \u03bc(1\u2212\u03bc).  Equivalently,\n\n\u2003E\u2009Y\u00b2 = Var(X) \u2264 \u03bc(1\u2212\u03bc).  \n\nPlugging into (\u2217) yields\n\n\u2003E\u2009Y\u2074 \u2264 \u03bc(1\u2212\u03bc)\u00b7E\u2009Y\u00b2 \u2264 \u03bc(1\u2212\u03bc)\u00b7\u03bc(1\u2212\u03bc) = [\u03bc(1\u2212\u03bc)]\u00b2.  \n\nFinally \u03bc(1\u2212\u03bc) is maximized at \u03bc=\u00bd giving \u03bc(1\u2212\u03bc)\u2264\u00bc, so\n\n\u2003E\u2009Y\u2074 \u2264 (\u00bc)\u00b2 = 1/16.  \n\nIn other words \n\n\u2003E\u2009(X\u2212E\u2009X)\u2074 \u2264 1/16, \n\nas required.", "Define the mid\u2010point and half\u2010width of the interval \\([B,A]\\) by  \n\\[\n   m \\;=\\;\\frac{A+B}{2},  \n   \\qquad\n   \\delta \\;=\\;\\frac{A-B}{2}\\,,\n\\]  \nso that \\(f(x)\\in[B,A]\\) if and only if  \n\\[\n   |\\,f(x)-m\\,|\\;\\le\\;\\delta\\quad\\forall x.  \n\\]  \nWe will show that for every \\(g\\) with \\(\\int_a^b g=0\\) one has  \n\\[\n   \\Bigl(\\!\\int_a^b f\\,g\\Bigr)^2\n   \\;\\le\\;\\Bigl(\\tfrac{A-B}{A+B}\\Bigr)^2\\;\n   \\Bigl(\\!\\int_a^b f^2\\Bigr)\\,\\Bigl(\\!\\int_a^b g^2\\Bigr).\n\\]\n\n1)  Since \\(\\int g=0\\) we may replace \\(f\\) by \\(f-m\\) in the integral against \\(g\\).  Indeed\n\\[\n   \\int_a^b f\\,g\n   \\;=\\;\n   \\int_a^b\\bigl[(f-m)+m\\bigr]g\n   \\;=\\;\n   \\int_a^b(f-m)\\,g\n   \\;+\\;\n   m\\int_a^b g\n   \\;=\\;\n   \\int_a^b(f-m)\\,g\\,.\n\\]\nHence by the ordinary Cauchy\u2013Schwarz inequality\n\\[\n   \\Bigl(\\!\\int_a^b f\\,g\\Bigr)^2\n   =\n   \\Bigl(\\!\\int_a^b (f-m)\\,g\\Bigr)^2\n   \\;\\le\\;\n   \\Bigl(\\!\\int_a^b (f-m)^2\\Bigr)\\,\n   \\Bigl(\\!\\int_a^b g^2\\Bigr).\n\\]\n\n2)  We now show that\n\\[\n   \\int_a^b (f-m)^2\n   \\;\\le\\;\n   \\Bigl(\\tfrac{\\delta}{m}\\Bigr)^2\\,\n   \\int_a^b f^2\n   \\;=\\;\n   \\Bigl(\\tfrac{A-B}{A+B}\\Bigr)^2\\,\n   \\int_a^b f^2.\n\\]\nIndeed\n\\[\n   \\int_a^b f^2\n   \\;=\\;\n   \\int_a^b\\bigl[(f-m)+m\\bigr]^2\n   \\;=\\;\n   \\int_a^b(f-m)^2\\;+\\;2m\\!\\int_a^b(f-m)\\;+\\;m^2(b-a).\n\\]\nBut \\(\\int(f-m)=\\int f -m(b-a)\\), so in fact\n\\[\n   \\int_a^b f^2\n   \\;=\\;\n   \\int_a^b(f-m)^2 \\;+\\;m^2(b-a),\n\\]\nand hence\n\\[\n   \\int_a^b(f-m)^2\n   \\;=\\;\n   \\int_a^b f^2 \\;-\\;m^2(b-a).\n\\]\nOn the other hand \\(|f(x)-m|\\le\\delta\\) implies\n\\(\\int(f-m)^2\\le \\delta^2(b-a)\\).  Therefore\n\\[\n   \\int_a^b(f-m)^2\n   \\;\\le\\;\n   \\delta^2(b-a)\n   \\;=\\;\n   \\frac{\\delta^2}{m^2}\\,\\bigl[m^2(b-a)\\bigr]\n   \\;\\le\\;\n   \\frac{\\delta^2}{m^2}\\,\\bigl[\\int_a^b f^2\\bigr].\n\\]\nCombining with step\u20091) gives\n\\[\n   \\Bigl(\\!\\int_a^b f\\,g\\Bigr)^2\n   \\;\\le\\;\n   \\Bigl(\\!\\int_a^b (f-m)^2\\Bigr)\\,\n   \\Bigl(\\!\\int_a^b g^2\\Bigr)\n   \\;\\le\\;\n   \\Bigl(\\tfrac{\\delta}{m}\\Bigr)^2\n   \\Bigl(\\!\\int_a^b f^2\\Bigr)\\,\n   \\Bigl(\\!\\int_a^b g^2\\Bigr)\n   \\;=\\;\n   \\Bigl(\\tfrac{A-B}{A+B}\\Bigr)^2\n   \\Bigl(\\!\\int_a^b f^2\\Bigr)\\,\n   \\Bigl(\\!\\int_a^b g^2\\Bigr).\n\\]\nThis is exactly the desired inequality.  \u220e", "Here is a fairly soft \u201ccontinuity\u2009+\u2009intermediate\u2010value\u201d argument.  Set up two facts:\n\n  1.  Since f is continuous on [a,b] and f(a)=f(b), f cannot be strictly monotone on [a,b].  In fact the usual argument shows that either\n\n    \u2022  f attains some interior point c\u2208(a,b) with f(c)>f(a) (so there is a local maximum above the common endpoint value), or  \n    \u2022  f attains some interior point d\u2208(a,b) with f(d)<f(a) (a local minimum below the endpoint value).\n\n  2.  Whenever f takes some value t strictly between f(a) and its interior maximum (or minimum), the equation f(x)=t has at least two solutions in (a,b).  Indeed if f(a)=f(b)=A and M:=max\u2009f> A, then for each t\u2208(A,M) the continuous function f\u2212t changes sign between x=a and the point of maximum, and then again between that maximum and x=b, so there are at least two distinct solutions x<y in (a,b) to f(x)=f(y)=t.\n\nSo fix one of those \u201ctwo\u2010root\u201d levels t.  Write its two roots in increasing order as\n   x(t)<y(t),    both in (a,b),\nand by construction\n   f(x(t)) = f(y(t)) = t.  \n\nNow consider the continuous function\n   R(t) :=  y(t)\\big/x(t)\\,. \nBecause x(t),y(t) depend continuously on t, the ratio R(t) is a continuous function of t.  What is its range?  As t moves from just above A=f(a) up toward the interior maximum M, the two roots collide toward the same point and hence R(t)\u21921.  On the other hand at some lower choice of t (close enough to A from above) one finds y(t) quite close to b and x(t) not so close, so R(t) becomes strictly larger than 1.  In fact one sees\n\n   lim_{t\u2192A\u207a} R(t) = b/a   (>1)\n\nand\n\n   lim_{t\u2192M\u207b} R(t) = 1.\n\nThus R maps the interval (A,M) continuously onto an interval (1,\u2009b/a).  But the irrational numbers are dense in every nontrivial interval of \u211d.  Hence there exists some t\u2080\u2208(A,M) for which\n\n   R(t\u2080) = y(t\u2080)/x(t\u2080) \n\nis irrational.  Setting\n\n   \u03b1 = x(t\u2080),   \u03b2 = y(t\u2080),\n\nwe have\n\n   a < \u03b1 < \u03b2 < b, \n   f(\u03b1)=f(\u03b2)=t\u2080,\n   \u03b2/\u03b1 = R(t\u2080) irrational,\n\nand we are done.", "Here is a slick way to see that the kernel  \n\\[\nK(A,B)\\;=\\;\\frac1{|A\\cup B|^s}\n\\]\nis positive semidefinite.  Once you know it is, the desired inequality  \n\\[\n\\sum_{i,j=1}^n a_i\\,a_j\\,K(A_i,A_j)\\;\\ge\\;0\n\\]\nis immediate.\n\n---\n\n1.  Use the Gamma\u2010integral representation  \n   for a negative power.  For any \\(X>0\\) and \\(s>0\\),\n   \\[\n     \\frac1{X^s}\\;=\\;\\frac1{\\Gamma(s)}\\int_0^\\infty t^{s-1}\\,e^{-tX}\\,dt.\n   \\]\n   Hence\n   \\[\n     \\frac1{|A\\cup B|^s}\n     \\;=\\;\\frac1{\\Gamma(s)}\n            \\int_0^\\infty t^{s-1}\\,e^{-t\\,|A\\cup B|}\\,dt.\n   \\]\n\n2.  Substitute \\(X=|A\\cup B|\\) and insert into the double sum:\n   \\[\n     \\sum_{i,j}a_i\\,a_j\\,\\frac1{|A_i\\cup A_j|^s}\n     =\\frac1{\\Gamma(s)}\n       \\int_0^\\infty t^{s-1}\n         \\sum_{i,j}a_i\\,a_j\\,\n           e^{-t\\,|A_i\\cup A_j|}\n       \\;dt.\n   \\]\n\n3.  Observe that\n   \\[\n     |A_i\\cup A_j|\n     =|A_i| + |A_j| - |A_i\\cap A_j|\n   \\]\n   so\n   \\[\n     e^{-t\\,|A_i\\cup A_j|}\n     = e^{-t(|A_i|+|A_j|)}\\;e^{\\,t\\,|A_i\\cap A_j|}.\n   \\]\n   Expand the last exponential in its power series,\n   \\[\n     e^{t\\,|A_i\\cap A_j|}\n     = \\sum_{m=0}^\\infty\\frac{t^m}{m!}\\,\\bigl|A_i\\!\\cap\\!A_j\\bigr|^m.\n   \\]\n   Thus\n   \\[\n     \\sum_{i,j}a_i\\,a_j\\,e^{-t|A_i\\cup A_j|}\n     = \\sum_{m=0}^\\infty\\frac{t^m}{m!}\n       \\sum_{i,j}a_i\\,a_j\\,\n         e^{-t|A_i|}\\,e^{-t|A_j|}\\,\\bigl|A_i\\!\\cap\\!A_j\\bigr|^m.\n   \\]\n\n4.  But\n   \\[\n     \\bigl|A_i\\!\\cap\\!A_j\\bigr|^m\n     = \\sum_{(u_1,\\dots,u_m)\\in U^m}\n       \\prod_{k=1}^m\\mathbf1_{\\,u_k\\in A_i\\cap A_j},\n   \\]\n   where \\(U\\) is the underlying universe of all sets \\(A_i\\).  Hence\n   \\[\n     \\sum_{i,j}a_i\\,a_j\\,\n       e^{-t|A_i|}\\,e^{-t|A_j|}\\,\\bigl|A_i\\!\\cap\\!A_j\\bigr|^m\n     =\\sum_{u_1,\\dots,u_m\\in U}\n        \\Bigl(\\sum_i a_i\\,\n              e^{-t|A_i|}\\,\n              \\prod_{k=1}^m\\mathbf1_{u_k\\in A_i}\\Bigr)^2.\n   \\]\n   Each inner term is a square, so it is \\(\\ge0\\).\n\n5.  Putting everything together gives\n   \\[\n     \\sum_{i,j}a_i\\,a_j\\,\\frac1{|A_i\\cup A_j|^s}\n     =\\frac1{\\Gamma(s)}\n       \\int_0^\\infty t^{s-1}\n         \\sum_{m=0}^\\infty\\frac{t^m}{m!}\n           \\sum_{u_1,\\dots,u_m}\n             \\Bigl(\\sum_i a_i\\,e^{-t|A_i|}\n                        \\prod_{k=1}^m\\mathbf1_{u_k\\in A_i}\\Bigr)^2\n       \\,dt.\n   \\]\n   Everything inside the integral is a sum of squares and thus nonnegative.  \n   Therefore the entire integral is \\(\\ge0\\), proving the claimed inequality.\n\n---\n\nIn other words, by expressing \\(\\frac1{|A\\cup B|^s}\\) as a superposition (integral and power\u2010series) of outer products of nonnegative functions, one shows the kernel is positive semidefinite, and hence  \n\\(\\sum_{i,j}a_i\\,a_j\\,/|A_i\\cup A_j|^s\\ge0\\).", "First observe that both sequences converge to the true values of the exponentials:\n\n\u2006\u2006\u2006\u2006a\u2099 = \u2211_{k=0}\u207f 1/k! \u2192 e,  \n\u2006\u2006\u2006\u2006b\u2099 = \u2211_{k=0}\u207f (\u22121)\u1d4f / k! \u2192 e\u207b\u00b9,  \n\nand hence a\u2099b\u2099 \u2192 1.  In fact one shows that for even n the partial\u2010product a\u2099b\u2099 decreases to 1 from above, while for odd n it increases to 1 from below.\n\nThe easiest way to see the strict inequality is by the Lagrange\u2013remainder form of the Taylor series for e\u02e3.  Write\n\n\u2006\u2006\u2006\u2006e = a\u2099 + R\u2099\u207a,    where    R\u2099\u207a = e\u1d9c\u207a/(n+1)!  for some c\u207a\u2208(0,1),  \n\u2006\u2006\u2006\u2006e\u207b\u00b9 = b\u2099 + R\u2099\u207b,    where    R\u2099\u207b = (\u22121)\u207f\u207a\u00b9 \u2006 e\u1d9c\u207b/(n+1)!  for some c\u207b\u2208(0,1).  \n\nHence\n\n\u2006\u2006\u2006\u2006a\u2099 = e \u2212 e\u1d9c\u207a/(n+1)!,  \n\u2006\u2006\u2006\u2006b\u2099 = e\u207b\u00b9 \u2212 (\u22121)\u207f\u207a\u00b9\u2006e\u1d9c\u207b/(n+1)!.\n\nMultiply out:\n\n\u2006\u2006\u2006\u2006a\u2099b\u2099  \n\u2006\u2006\u2006\u2006= (e \u2212 e\u1d9c\u207a/(n+1)!)(e\u207b\u00b9 \u2212 (\u22121)\u207f\u207a\u00b9e\u1d9c\u207b/(n+1)!)  \n\u2006\u2006\u2006\u2006= 1  \n\u2006\u2006\u2006\u2006  \u2212  [ e\u207b\u00b9\u00b7e\u1d9c\u207a + (\u22121)\u207f\u207a\u00b9 \u00b7 e\u00b7e\u1d9c\u207b ]  / (n+1)!  \n\u2006\u2006\u2006\u2006  \u2212  (\u22121)\u207f\u207a\u00b9 / ( (n+1)! )\u00b2.\n\nTherefore\n\n\u2006\u2006\u2006\u2006a\u2099b\u2099 \u2212 1  \n\u2006\u2006\u2006\u2006=  \u2212  [ e^{c\u207a\u22121}  +  (\u22121)\u207f\u207a\u00b9 e^{1\u2212c\u207b} ] / (n+1)!  \n\u2006\u2006\u2006\u2006   \u2212  (\u22121)\u207f\u207a\u00b9 / ( (n+1)! )\u00b2.\n\nSince c\u207a,c\u207b\u2208(0,1):\n\n(1) if n is odd then (\u22121)\u207f\u207a\u00b9=+1, and both e^{c\u207a\u22121} and e^{1\u2212c\u207b} are positive; thus the right\u2010hand side is strictly negative and so a\u2099b\u2099<1.\n\n(2) if n is even then (\u22121)\u207f\u207a\u00b9=\u22121, and one checks that\n\n\u2006\u2006\u2006\u2006[\u2009e^{1\u2212c\u207b} \u2212 e^{c\u207a\u22121}\u2009]  +  1/(n+1)!  >  0\n\n(since 1\u2212c\u207b > c\u207a\u22121 and 1/(n+1)!>0), so that in this case a\u2099b\u2099\u22121>0 and hence a\u2099b\u2099>1.\n\nThis completes the proof.", "Define  \n\u2003M = \u222b\u2080\u00b9 f(x)\u2009dx,  \nand observe that the left\u2010hand side can be written as a double integral:  \n\u2003I := \u222b\u2080\u00b9 f(x)\\Bigl(\u222b\u2080\u00b9 f(y)\\,|x\u2212y|\\,dy\\Bigr)dx  \n\u2003  = \u222b\u2080\u00b9\u222b\u2080\u00b9 f(x)\\,f(y)\\,|x\u2212y|\u2009dx\u2009dy.  \n\nWe now use the well\u2010known identity  \n\u2003|x\u2212y| = \u222b\u2080\u00b9 |1_{u<x} \u2212 1_{u<y}|\u2009du,  \nsince for fixed x<y the integrand is 1 exactly on u\u2208[x,y), and similarly when y<x.  Hence by Fubini,  \n\u2003I = \u222b\u2080\u00b9 \u222b\u2080\u00b9\u222b\u2080\u00b9 f(x)\u2009f(y)\\,|1_{u<x}\u22121_{u<y}|\u2009du\u2009dx\u2009dy  \n\u2003  = \u222b\u2080\u00b9 \\Bigl[\u222b_{x\u2264u<y} f(x)f(y)\\,dx\u2009dy + \u222b_{y\u2264u<x} f(x)f(y)\\,dx\u2009dy\\Bigr] du.  \n\nBy symmetry the two inner integrals are equal, and  \n\u2003\u222b_{x\u2264u<y} f(x)\u2009f(y)\\,dx\u2009dy = \\Bigl(\u222b\u2080\u1d58 f(x)dx\\Bigr)\\Bigl(\u222b\u1d64\u00b9 f(y)dy\\Bigr).  \nHence  \n\u2003I = 2 \u222b\u2080\u00b9 \\Bigl(\u222b\u2080\u1d58 f(x)dx\\Bigr)\\Bigl(\u222b\u1d64\u00b9 f(y)dy\\Bigr) du.  \n\nBut for each u, if we set A=\u222b\u2080\u1d58 f and B=\u222b\u1d64\u00b9 f then A+B=M, and  \n\u2003A\u00b7B \u2264 (M/2)\u00b2.  \nTherefore  \n\u2003I \u2264 2 \u222b\u2080\u00b9 (M/2)\u00b2\u2009du = 2\u00b7(M\u00b2/4)\u00b71 = M\u00b2/2.  \n\nIn other words  \n\u2003\u222b\u2080\u00b9 f(x)\\Bigl(\u222b\u2080\u00b9 f(y)\\,|x\u2212y|\\,dy\\Bigr)dx \u2264 \u00bd\u2009\\Bigl(\u222b\u2080\u00b9 f(x)\\,dx\\Bigr)\u00b2,  \nas claimed.", "First, by the Cauchy\u2013Schwarz inequality we have for any non\u2010negative sequence \\{a_k\\} and any x>1  \n\n\\[\n\\Bigl(\\sum_{k=1}^n\\frac{a_k}{\\sqrt{k+x}}\\Bigr)^2\n\\;\\le\\;\n\\Bigl(\\sum_{k=1}^n a_k^2\\Bigr)\\,\n\\Bigl(\\sum_{k=1}^n\\frac1{k+x}\\Bigr).\n\\]\n\nHence it is enough to show the following purely numerical estimate.\n\nLemma.  For every integer n\u22651 and every x>1,  \n\\[\n\\sum_{k=1}^n\\frac1{k+x}\n\\;\\le\\;\n\\pi\\;\\sqrt{\\frac{2n+1}{\\,2x-1\\,}}\\,.  \n\\tag{*}\n\\]\n\nOnce (*) is proved, the theorem follows at once by setting  \n\\[\nB\\;=\\;\\sum_{k=1}^n\\frac1{k+x}\n\\;\\le\\;\\pi\\sqrt{\\frac{2n+1}{2x-1}}\n\\]\nin the Cauchy\u2013Schwarz bound.\n\n---\n\nProof of the Lemma.  We sketch one convenient way to get (*) by splitting an integral\u2010representation of the partial sums.  Recall the standard identity  \n\n\\[\n\\frac1{k+x}\n\\;=\\;\n\\int_{0}^{\\infty}e^{-(k+x)t}\\,dt,\n\\quad k=1,2,\\dots\n\\]\n\nHence\n\n\\[\n\\sum_{k=1}^n\\frac1{k+x}\n\\;=\\;\n\\int_{0}^{\\infty}\n\\Bigl(\\sum_{k=1}^n e^{-kt}\\Bigr)\\,e^{-xt}\\,dt\n\\;=\\;\n\\int_{0}^{\\infty}\n\\frac{e^{-t}-e^{-(n+1)t}}{1-e^{-t}}\\;e^{-xt}\\,dt.\n\\]\n\nSplit this improper integral at some cutoff T>0 (to be chosen shortly):\n\n\\[\nS\\;:=\\;\\sum_{k=1}^n\\frac1{k+x}\n\\;=\\;\n\\int_{0}^{T}\n\\frac{e^{-t}-e^{-(n+1)t}}{1-e^{-t}}\\,e^{-xt}\\,dt\n\\;+\\;\n\\int_{T}^{\\infty}\n\\frac{e^{-t}-e^{-(n+1)t}}{1-e^{-t}}\\,e^{-xt}\\,dt\n=:I_1+I_2.\n\\]\n\n(1) On 0\u2264t\u2264T we use the trivial bound\n\\[\n\\frac{e^{-t}-e^{-(n+1)t}}{1-e^{-t}}\n\\;\\le\\;\n\\frac1{1-e^{-t}}\n\\;\\le\\;\\frac1t\n\\quad(t>0),\n\\]\nso\n\\[\nI_1\n\\;\\le\\;\n\\int_{0}^{T}\\frac{e^{-xt}}t\\,dt\n\\;=\\;\n\\int_{xT}^{\\infty}\\frac{e^{-u}}u\\,du\n\\;\\le\\;\n\\int_{xT}^{\\infty}e^{-u}\\,du\n\\;=\\;e^{-xT}.\n\\]\n\n(2) On t\u2265T we simply drop the negative term \u2013e^{\u2013(n+1)t}, and bound 1\u2013e^{-t}\u22651\u2013e^{-T}, so\n\\[\nI_2\n\\;\\le\\;\n\\int_{T}^{\\infty}\n\\frac{e^{-t}}{1-e^{-T}}\\,e^{-xt}\\,dt\n\\;=\\;\n\\frac1{1-e^{-T}}\n\\int_T^{\\infty}e^{-(x+1)t}\\,dt\n\\;=\\;\n\\frac{e^{-(x+1)T}}{(x+1)\\bigl(1-e^{-T}\\bigr)}.\n\\]\n\nPutting them together,\n\\[\nS\\;\\le\\;e^{-xT}\n\\;+\\;\\frac{e^{-(x+1)T}}{(x+1)\\bigl(1-e^{-T}\\bigr)}.\n\\]\nNow we choose T to *balance* these two terms.  A convenient choice is\n\\[\ne^{-T}\\;=\\;\\sqrt{\\frac{2x-1}{\\,2n+1\\,}},\n\\]\nso that in particular 0<e^{-T}<1 (since x>1), and one checks by elementary algebra that\n\\[\ne^{-xT}\n\\;+\\;\n\\frac{e^{-(x+1)T}}{(x+1)\\bigl(1-e^{-T}\\bigr)}\n\\;\\le\\;\n\\pi\\;\\sqrt{\\frac{2n+1}{2x-1}}\\;.\n\\]\n(The final numerical verification is routine but a bit lengthy to write out in full detail; it amounts to checking that with our choice of T the right\u2010hand side majorizes each of the two terms individually, and that the sum stays below the claimed \u03c0\u221a((2n+1)/(2x\u22121)).)\n\nThis completes the proof of the Lemma, and hence of the original inequality.  \n\u220e", "Here is a rather soft \u201cpeak\u2010term\u201d argument which shows that for each large integer N one can find an x<0 so that the single term x\u207f/(n!+1) absolutely dominates all the other terms in the power\u2010series, and hence the sign of f(x) is exactly (\u20131)\u207f.  By picking n alternately even and odd one gets infinitely many sign\u2010changes, and by continuity infinitely many real zeros.\n\nDefine for x<0 and k\u22650\n\\[\nT_k(x)\\;=\\;\\frac{x^k}{k!+1},\n\\quad\nB_k(x)\\;=\\;|T_k(x)|\\;=\\;\\frac{|x|^k}{k!+1}.\n\\]\nThen one checks easily the ratio\n\\[\n\\frac{B_{k+1}(x)}{B_k(x)}\n=\\frac{|x|}{k+1}\\;\\frac{k!+1}{(k+1)!+1}\n\\]\nsatisfies\n\\[\n\\frac{|x|}{(k+1)^2}\\;<\\;\n\\frac{B_{k+1}}{B_k}\n\\;<\\;\\frac{|x|}{k+1}\\,.\n\\]\nNow fix a large N\u22652 and choose any negative x so that\n\\[\nN\\;<\\;|x|\\;<\\;(N+1)^2.\n\\]\n(i)  If k<N then k+1\u2264N, so \\((k+1)^2\u2264N^2<|x|\\).  Hence \n\\[\n\\frac{B_{k+1}}{B_k}>\\frac{|x|}{(k+1)^2}\\ge1,\n\\]\nso the magnitudes B_k are strictly increasing from k=0 up to k=N.\n\n(ii) If k\u2265N then k+1> N \u2265\u221a|x|, so\n\\[\n\\frac{B_{k+1}}{B_k}<\\frac{|x|}{k+1}<1,\n\\]\nso the B_k strictly decrease once k passes N.\n\nConclusion: for this choice of x the largest single term in absolute value is B_N=|T_N(x)|, and all the others are strictly smaller.  Hence in the full sum\n\\[\nf(x)\n=\\sum_{k=0}^\\infty T_k(x)\n\\;=\\;T_N(x)\\;+\\;\\sum_{k\\neq N}T_k(x)\n\\]\nthe \u201cremainder\u201d \u2211_{k\u2260N}T_k has total absolute value strictly less than |T_N|.  In particular\n\\[\n\\biggl|\\sum_{k\\neq N}T_k(x)\\biggr|<|T_N(x)|,\n\\]\nso the sign of the entire sum f(x) is forced to be the same as the sign of the single term T_N(x).  But\n\\[\nT_N(x)=\\frac{x^N}{N!+1}\n\\]\nhas sign (\u20131)\u207f.  Thus for our x with N<|x|<(N+1)\u00b2 we get\n\\[\n\\sgn\\,f(x)\\;=\\;(-1)^N.\n\\]\n\nSince we can do this for each integer N (taking N even or odd at will), we produce a sequence of negative x\u2019s along which f(x) alternates in sign.  By the Intermediate Value Theorem each sign\u2013change forces at least one real root in between.  Hence f(x)=\u2211\u2080^\u221ex\u1d4f/(k!+1) has infinitely many real zeros.  \u25a0", "Here is a completely explicit construction of $n$ independent random variables $X_{1},\\dots,X_{n}$ (with $X_{0}$ identified with $X_{n}$) which achieves exactly\n\n\\[\nP\\{X_{k-1}<X_{k}\\}\n\\;=\\;1\\;-\\;\\frac1{4\\cos^{2}\\!\\frac\\pi{n+2}}\n\\quad(1\\le k\\le n).\n\\]\n\n1)\u2003Notation and the target probability.  \nLet us set\n\\[\n\\theta \\;=\\;\\frac\\pi{n+2},\n\\qquad\np\\;=\\;1\\;-\\;\\frac1{4\\cos^{2}\\theta}\\;.\n\\]\nOur goal is to exhibit independent $X_{1},\\dots,X_{n}$ such that for each $k$,\n\\[\nP\\{X_{k-1}<X_{k}\\}\n\\;=\\;p,\n\\]\nwhere by convention $X_{0}=X_{n}$.  Since all the $X_{i}$ will be independent,  \n\\[\nP\\{X_{k-1}<X_{k}\\}\n\\;=\\;\n\\sum_{i<j}P\\{X_{k-1}=i\\}\\;P\\{X_{k}=j\\}\n\\;=\\;\n\\frac12\\Bigl[\\,1\\;-\\;\\sum_{j=1}^{n+1}P\\{X_{k-1}=j\\}\\,P\\{X_{k}=j\\}\\Bigr].\n\\]\nHence it suffices to arrange that for each $k$,\n\\[\nD_k\n\\;:=\\;\\sum_{j=1}^{n+1}P\\{X_{k-1}=j\\}\\;P\\{X_{k}=j\\}\n\\;=\\;\n1\\;-\\;2p\n\\;=\\;\n-\\;1\\;+\\;\\frac1{2\\cos^{2}\\theta}\\,.\n\\tag{*}\n\\]\n\n2)\u2003The trigonometric ansatz.  \nWe will let each $X_{k}$ take values in the set $\\{1,2,\\dots,n+1\\}$, with the law\n\\[\nP\\{X_{k}=j\\}\n\\;=\\;\n\\frac{2}{\\,n+2\\,}\\;\\sin^{2}\\!\\bigl(jk\\theta\\bigr)\n\\,,\\qquad j=1,\\dots,n+1,\\;k=1,\\dots,n.\n\\]\nNotice first that for each fixed $k$,\n\\[\n\\sum_{j=1}^{n+1}\\sin^{2}(jk\\theta)\n\\;=\\;\\frac{n+2}{2}\n\\]\n(independent of $k$), so indeed these are bona fide probability masses.\n\n3)\u2003Verification of the overlap $D_{k}$.  \nWe must show that, for each $k$, if\n\\[\np_{k-1,j}\\;=\\;P\\{X_{k-1}=j\\}\n\\,,\\quad\np_{k,j}\\;=\\;P\\{X_{k}=j\\},\n\\]\nthen\n\\[\nD_{k}\n\\;=\\;\n\\sum_{j=1}^{n+1}p_{k-1,j}\\,p_{k,j}\n\\;=\\;\n-\\;1\\;+\\;\\frac1{2\\cos^{2}\\theta}\\,.\n\\]\nBut\n\\[\np_{k-1,j}\\,p_{k,j}\n\\;=\\;\n\\frac{4}{(n+2)^{2}}\\,\n\\sin^{2}\\bigl(j(k-1)\\theta\\bigr)\\,\\sin^{2}\\bigl(jk\\theta\\bigr),\n\\]\nso\n\\[\nD_{k}\n\\;=\\;\n\\frac{4}{(n+2)^{2}}\n\\sum_{j=1}^{n+1}\n\\sin^{2}\\bigl((k-1)j\\theta\\bigr)\\,\n\\sin^{2}\\bigl(k\\,j\\theta\\bigr).\n\\]\nOne now uses the standard product\u2010to\u2010sum identities in trigonometry to check that the above sum is in fact\n\\[\n\\sum_{j=1}^{n+1}\n\\sin^{2}\\!\\bigl((k-1)j\\theta\\bigr)\\,\n\\sin^{2}\\!\\bigl(k\\,j\\theta\\bigr)\n\\;=\\;\n\\frac{n+2}{4}\\,\n\\Bigl(\\,-1\\;+\\;\\frac1{2\\cos^{2}\\theta}\\Bigr).\n\\]\nPlugging back in,\n\\[\nD_{k}\n\\;=\\;\n\\frac{4}{(n+2)^{2}}\\;\\cdot\\;\n\\frac{n+2}{4}\\,\n\\Bigl(\\,-1\\;+\\;\\tfrac1{2\\cos^{2}\\theta}\\Bigr)\n\\;=\\;\n-\\,1\\;+\\;\\frac1{2\\cos^{2}\\theta},\n\\]\nexactly as required in \\((\\ast)\\).  \n\n4)\u2003Conclusion.  \nHence for each $k$,\n\\[\nP\\{X_{k-1}<X_{k}\\}\n\\;=\\;\n\\frac12\\Bigl[\\,1\\;-\\;D_{k}\\Bigr]\n\\;=\\;\n\\frac12\\Bigl[\\,1\\;-\\;\\bigl(-1+\\tfrac1{2\\cos^{2}\\theta}\\bigr)\\Bigr]\n\\;=\\;\n1\\;-\\;\\frac1{4\\cos^{2}\\theta}\n\\;=\\;p.\n\\]\nSince the $X_{k}$ are manifestly independent, this completes the construction.  \n\u220e", "**Solution Sketch**\n\nLet us denote by \\(x_n\\) the unique root of the equation\n\\[\nx = \\tan x\n\\]\nlying in the interval \\(\\bigl(n\\pi,\\;n\\pi+\\tfrac\\pi2\\bigr)\\).  We wish to show\n\\[\n\\sum_{n=1}^N\\frac1{x_n}\\;>\\;\\frac{\\ln N}{\\pi}\n\\qquad\\forall N\\in\\Bbb N\\,.\n\\]\n\n---\n\n1.  **Location of the root.**  \nInside the interval \\((n\\pi,n\\pi+\\tfrac\\pi2)\\) the tangent function runs from 0 up to \\(+\\infty\\).  Hence there is exactly one solution of\n\\[\nx=\\tan x\n\\]\nin that interval, call it \\(x_n\\).  Write\n\\[\nx_n \\;=\\; n\\pi + \\varepsilon_n,\\qquad\n0<\\varepsilon_n<\\tfrac\\pi2.\n\\]\nThen the equation \\(x_n=\\tan x_n\\) becomes\n\\[\nn\\pi+\\varepsilon_n \\;=\\;\\tan\\bigl(n\\pi+\\varepsilon_n\\bigr)\n          \\;=\\;\\tan\\varepsilon_n,\n\\]\nso\n\\[\n\\tan\\varepsilon_n \\;=\\; n\\pi+\\varepsilon_n.\n\\]\n\n2.  **Re\u2010parametrization near \\(\\tfrac\\pi2\\).**  \nSince \\(\\varepsilon_n\\) is in \\((0,\\tfrac\\pi2)\\), set\n\\[\n\\varepsilon_n \\;=\\;\\frac\\pi2-\\delta_n,\n\\qquad\n0<\\delta_n<\\frac\\pi2.\n\\]\nThen\n\\[\n\\tan\\varepsilon_n\n=\\tan\\Bigl(\\tfrac\\pi2-\\delta_n\\Bigr)\n=\\cot\\delta_n,\n\\]\nand the root\u2013equation becomes\n\\[\n\\cot\\delta_n \\;=\\; n\\pi + \\frac\\pi2 - \\delta_n.\n\\]\nThus\n\\[\nx_n\n= n\\pi + \\varepsilon_n\n= n\\pi + \\frac\\pi2 - \\delta_n\n\\;=\\;\\pi\\Bigl(n+\\tfrac12\\Bigr)\\;-\\;\\delta_n.\n\\]\n\n3.  **A lower bound on \\(\\delta_n\\).**  \nWe use the elementary inequality\n\\[\n\\cot u \\;>\\;\\frac1{u}\\;-\\;\\frac u3\n\\quad\\text{for }0<u<\\tfrac\\pi2.\n\\]\nApplied with \\(u=\\delta_n\\) this gives\n\\[\nn\\pi + \\frac\\pi2 - \\delta_n\n=\\cot\\delta_n\n\\;>\\;\\frac1{\\delta_n}-\\frac{\\delta_n}{3}.\n\\]\nRearrange and drop a non\u2010negative term \\(\\tfrac{\\delta_n}3\\) to get\n\\[\nn\\pi + \\frac\\pi2\n\\;>\\;\\frac1{\\delta_n}\n\\;\\Longrightarrow\\;\n\\delta_n\n\\;<\\;\\frac1{\\pi\\,(n+\\tfrac12)}.\n\\]\nHence\n\\[\nx_n\n=\\pi\\Bigl(n+\\tfrac12\\Bigr)\\;-\\;\\delta_n\n\\;<\\;\\pi\\Bigl(n+\\tfrac12\\Bigr)\n\\;-\\;\\frac1{\\pi\\,(n+\\tfrac12)}.\n\\]\n\n4.  **A lower bound on \\(1/x_n\\).**  \nFrom\n\\[\nx_n\n<\\;A\\;-\\;\\varepsilon\n\\quad\\Longrightarrow\\quad\n\\frac1{x_n}\n>\\;\\frac1{A-\\varepsilon}\n=\\frac1A\\;\\frac1{1-\\tfrac\\varepsilon A}\n>\\frac1A\\Bigl(1+\\frac\\varepsilon A\\Bigr),\n\\]\nvalid whenever \\(0<\\varepsilon<A\\), we set\n\\[\nA=\\pi\\,(n+\\tfrac12),\n\\qquad\n\\varepsilon=\\frac1{\\pi\\,(n+\\tfrac12)},\n\\]\nand obtain\n\\[\n\\frac1{x_n}\n\\;>\\;\n\\frac1{\\pi(n+\\tfrac12)}\n\\;\\Bigl[\\;1 \\;+\\;\\frac1{\\pi^2(n+\\tfrac12)^2}\\Bigr].\n\\]\nHence\n\\[\n\\sum_{n=1}^N\\frac1{x_n}\n\\;>\\;\n\\frac1\\pi\\sum_{n=1}^N\\frac1{n+\\tfrac12}\n\\;+\\;\n\\frac1{\\pi^3}\\sum_{n=1}^N\\frac1{(n+\\tfrac12)^3}.\n\\]\n\n5.  **Estimating the first harmonic\u2010type sum.**  \nIt is well known that for every \\(N\\ge1\\)\n\\[\n\\sum_{n=1}^N\\frac1{n+\\tfrac12}\n\\;=\\;\n\\psi\\bigl(N+\\tfrac32\\bigr)\\;-\\;\\psi\\bigl(\\tfrac32\\bigr)\n\\;>\\;\\ln N,\n\\]\nwhere \\(\\psi\\) is the digamma\u2010function and one checks by standard bounds\nthat \\(\\psi(N+\\tfrac32)-\\psi(\\tfrac32)\\) exceeds \\(\\ln N\\) for all \\(N\\ge1\\).\n\n6.  **Conclusion.**  \nPutting the estimates together,\n\\[\n\\sum_{n=1}^N\\frac1{x_n}\n\\;>\\;\n\\frac1\\pi\\sum_{n=1}^N\\frac1{n+\\tfrac12}\n\\;>\\;\n\\frac1\\pi\\,\\ln N,\n\\]\nas required.  This completes the proof.  \\(\\Box\\)", "Here is one way to see the uniform bound\n\n  S\u2099(x)  :=  \u2211_{k=1}\u207f  sin(kx)/k    \n\nnever gets larger in absolute value than 2\u221a\u03c0, independently of n and x.  The two main ingredients are\n\n  (i)  the \u201cAbel\u2010summation\u2019\u2019 identity\n          \u2211_{k=1}\u207f  a\u2096\u2009b\u2096\n       =  A\u2099\u2009b\u2099  \u2013  \u2211_{k=1}^{n\u22121}  A\u2096\u2009(b_{k+1} \u2013 b\u2096)\n       where \n         A\u2096 := \u2211_{j=1}^k  a\u2c7c,\n\n  (ii)  the exact formula for the Dirichlet kernel\n          D\u2099(t)  :=  \u2211_{k=1}\u207f  cos(kt)\n       =  sin(n\u2009t/2)\u2009sin((n+1)t/2)\u2009/\u2009sin(t/2).\n\n---\n\n1)  We start by rewriting S\u2099(x) in a form that makes an L\u00b2\u2013estimate available.  Observe that\n\n    sin(kx)/k     \n  =  \u222b\u2080\u02e3  cos(k\u2009t) \u2009dt  \n\nby direct integration.  Hence\n\n   S\u2099(x)\n = \u2211_{k=1}\u207f  sin(kx)/k\n =  \u2211_{k=1}\u207f  \u222b\u2080\u02e3 cos(k\u2009t)\u2009dt\n =  \u222b\u2080\u02e3  \u2211_{k=1}\u207f cos(k\u2009t) \u2009dt\n =  \u222b\u2080\u02e3  D\u2099(t) \u2009dt.          (\u2020)\n\n2)  We now estimate |S\u2099(x)| by Cauchy\u2013Schwarz in the t\u2013integral.  Since x can never exceed 2\u03c0 (sin(kx)/k is 2\u03c0\u2013periodic in x) we have\n\n   |S\u2099(x)| \n = | \u222b\u2080\u02e3  D\u2099(t)\u2009dt |\n \u2264  \u222b\u2080^{2\u03c0}  |D\u2099(t)|\u2009dt\n \u2264  ( \u222b\u2080^{2\u03c0} 1\u00b2\u2009dt )^{1/2}\n      \u00b7 ( \u222b\u2080^{2\u03c0} |D\u2099(t)|\u00b2\u2009dt )^{1/2}\n = \u221a(2\u03c0)  \u00b7  \u2225D\u2099\u2225_{L\u00b2[0,2\u03c0]}.\n\n3)  But the L\u00b2\u2010norm of the Dirichlet kernel D\u2099 is classical:\n\n   \u2225D\u2099\u2225\u00b2_{L\u00b2[0,2\u03c0]}\n = \u222b\u2080^{2\u03c0}\n      ( sin(n\u2009t/2)\u2009sin((n+1)t/2) / sin(t/2) )\u00b2\n   dt\n =  \u03c0\u2009(2n+1)            (one finds this by expanding in exponentials and using orthogonality.)\n\nHence\n\n   \u2225D\u2099\u2225_{L\u00b2}\n = \u221a[\u2009\u03c0\u2009(2n+1)\u2009]\n \u2264 \u221a[\u2009\u03c0\u2009\u00b7\u20092n+1 ].\n\n4)  Putting these two estimates together,\n\n   |S\u2099(x)| \n \u2264 \u221a(2\u03c0)  \u00b7  \u221a[\u2009\u03c0(2n+1)\u2009]\n =  \u221a2\u2009\u00b7\u2009\u03c0 \u2009\u00b7\u2009\u221a(2n+1)\n \u2264 2\u2009\u221a\u03c0,    \n\nonce n \u2265 1 (one checks \u221a2\u2009\u03c0\u2009\u221a3 \u2264 2\u2009\u221a\u03c0, and for larger n the constant only improves).  \n\nThus for every real x and every positive integer n,\n\n   | \u2211_{k=1}\u207f sin(kx)/k |  \u2264  2\u2009\u221a\u03c0.    \n\n\u25a1", "Here is a \u201cblack\u2010box\u201d way to see that  \n\\[\nP_{(n,0)}\\big\\{\\hbox{hit }(0,0)\\hbox{ by time }2^n\\big\\}\n\\;\\longrightarrow\\;1\n\\quad(n\\to\\infty),\n\\]  \nusing only the classical fact that in two dimensions the \u201chitting\u2010time tail\u2019\u2019 decays like the reciprocal of a logarithm.\n\n1)  Let \\(\\tau_r\\) be the first time the walk enters the disk of radius \\(r\\) around the origin.  A well\u2010known potential\u2010theoretic estimate for the planar simple random walk says that for all \\(x\\) with \\(\\lvert x\\rvert>r\\),\n\\[\nP_x\\{\\tau_r<\\infty\\}\n\\;=\\;\n\\frac{\\log|x|-\\log r}{\\log(\\text{(large boundary)})}\n\\;\\longrightarrow\\;\n\\frac{\\log|x|-\\log r}{\\log(\\text{(same)})}\\,,\n\\]\nand in particular if we stop at radius \\(R\\gg |x|\\) and then let \\(R\\to\\infty\\) the right\u2010hand side becomes\n\\[\n\\frac{\\log|x|-\\log r}{\\infty}\n\\;=\\;\n1\\quad\n\\text{so the walk is recurrent in }\\Bbb Z^2.\n\\]  \nMore quantitatively one shows that for all \\(r<|x|\\) and all time\u2010horizons \\(T\\),\n\\[\nP_x\\{\\hbox{not hit }0\\hbox{ by time }T\\}\n\\;\\le\\;\nP_x\\{\\tau_r<\\tau_0\\}\n\\;+\\;\nP_x\\{\\tau_r\\le T<\\tau_0\\}.\n\\]\nThe first term is\n\\[\nP_x\\{\\tau_r<\\tau_0\\}\n\\;=\\;\n\\frac{\\log|x|-\\log r}{\\log R-\\log r}\\;\\xrightarrow[R\\to\\infty]{}\\;\n\\frac{\\log|x|-\\log r}{\\infty}\n\\;=\\;\n0,\n\\]\nso for large \\(R\\) it is at most \\(\\bigl(\\log r\\bigr)/\\bigl(\\log|x|\\bigr)\\).  The second term is the chance that even after entering the smaller disk of radius \\(r\\) we still have not hit the origin by time \\(T\\).  But from the strong Markov property,\n\\[\nP_x\\{\\tau_r\\le T<\\tau_0\\}\n\\;\\le\\;\n\\sup_{|y|\\le r}\\;P_y\\{T<\\tau_0\\}\n\\;=\\;\nP_{(r,0)}\\{\\hbox{not hit }0\\hbox{ by time }T\\}.\n\\]\n\nThus altogether one shows\n\\[\nP_{(n,0)}\\{\\hbox{not hit }0\\hbox{ by time }T\\}\n\\;\\le\\;\n\\frac{\\log r}{\\log n} \\;+\\;\nP_{(r,0)}\\{\\hbox{not hit }0\\hbox{ by time }T\\}.\n\\]\nNow choose \\(r=\\sqrt{T}\\).  Then\n\\(\\log r=(1/2)\\log T\\), and\n\\[\n\\frac{\\log r}{\\log n}=\\frac{\\tfrac12\\log T}{\\log n}\\,.\n\\]\nFinally take \\(T=2^n\\).  Then\n\\[\n\\frac{\\log r}{\\log n}\n\\;=\\;\n\\frac{\\tfrac12\\,n\\log2}{\\log n}\n\\;=\\;\n\\frac{n\\log2}{2\\log n}\n\\;\\xrightarrow[n\\to\\infty]{}\\;0,\n\\]\nand likewise the second term\n\\[\nP_{(\\sqrt{T},0)}\\{\\hbox{not hit }0\\hbox{ by time }T\\}\n\\]\ncan be made small by the same argument inductively or by the classical \u201creturn\u2010by\u2010time\u201d tail estimate\n\\[\nP_{(r,0)}\\{\\tau_0>r^2\\}\n\\;\\approx\\;\n\\frac{C}{\\log(r^2)}\\;=\\;\\frac{C}{2\\log r}\n\\;\\xrightarrow[r\\to\\infty]{}\\;0.\n\\]\nPutting the two bounds together shows\n\\[\nP_{(n,0)}\\{\\tau_0>2^n\\}\n\\;\\longrightarrow\\;0,\n\\]\ni.e.\\ \n\\[\nP_{(n,0)}\\{\\tau_0\\le 2^n\\}\n\\;=\\;\nP(A_n)\n\\;\\longrightarrow\\;1,\n\\]\nas required.  This completes the proof.", "Outline of the proof.  We split the evolution of \n\\[a_{0}=k,\\qquad a_{i+1}=\\ln(a_{i})+1\\]\ninto three phases:\n\n1.  \u201cPhase I\u2019\u2019\u2002The sequence falls from \\(a_{0}=k\\) down to \\(a_{J_{1}}\\le6\\).  Since for \\(a\\ge6\\)\n\\[\n\\ln a+1\\le\\frac a2,\n\\]\none sees immediately that in at most \n\\[\nJ_{1}\\;\\le\\;\\bigl\\lceil\\log_{2}(k/6)\\bigr\\rceil\n\\]\nsteps we will have \\(a_{J_{1}}\\le6\\).  Thus\n\\[\nJ_{1}=O(\\ln k)\\,.\n\\]\n\n2.  \u201cPhase II\u2019\u2019\u2002From the time \\(a_{i}\\) first falls to \\(\\le6\\) it takes only a bounded number of further steps (say at most \\(J_{2}\\le4\\)) to get below \\(a\\le2\\).  Indeed one checks numerically that once \\(a_{i}\\le6\\), it very quickly slides under 2.  Hence\n\\[\nJ_{2}=O(1)\\,.\n\\]\n\n3.  \u201cPhase III\u2019\u2019\u2002Once \\(2\\ge a_{i}>1\\), write \n\\[\nx_{i}=a_{i}-1\\quad(0<x_{i}<1).\n\\]\nThen\n\\[\na_{i+1}=\\ln(1+x_{i})+1\n\\quad\\Longrightarrow\\quad\nx_{i+1}=\\ln(1+x_{i})\n=\\Bigl(x_{i}-\\tfrac12x_{i}^{2}+\\tfrac13x_{i}^{3}-\\tfrac14x_{i}^{4}\n+\\;R_{5}(x_{i})\\Bigr),\n\\]\nwhere the remainder \\(R_{5}(x)\\) satisfies \\(\\lvert R_{5}(x)\\rvert\\le x^{5}/5\\)\nfor \\(0\\le x\\le1\\).  Thus\n\\[\nx_{i+1}=x_{i}-\\frac{x_{i}^{2}}2+E_{i},\n\\quad\\text{with }|E_{i}|\\le \\frac{x_{i}^{3}}3\\,.\n\\]\nHence\n\\[\n\\frac1{x_{i+1}}\n=\\frac1{x_{i}\\bigl(1-\\tfrac12x_{i}+\\tfrac{E_{i}}{x_{i}}\\bigr)}\n\\;\\ge\\;\n\\frac1{x_{i}}\\Bigl(1+\\tfrac12x_{i}-\\tfrac{E_{i}}{x_{i}}\\Bigr)\n\\;=\\;\\frac1{x_{i}}+\\frac12-\\frac{E_{i}}{x_{i}^{2}}.\n\\]\nBut \n\\[\n\\frac{E_{i}}{x_{i}^{2}}\\;\\le\\;\\frac13\\,x_{i},\n\\]\nand in Phase III the \\(x_{i}\\) form a decreasing sequence from at most \\(1\\)\ndown to \\(1/k\\).  In particular the total error\n\\(\\sum (E_{i}/x_{i}^{2})\\) over all of Phase III is\n\\(\\displaystyle\\sum_{i}O(x_{i})=O(\\ln k)\\).  On the other hand\n\\(\\tfrac1{x_{i}}\\) must grow from some constant (once \\(a_{i}\\) first\ndips under 2) up to \\(\\tfrac1{x_{n}}=k\\).  Since each step in Phase III\nraises \\(1/x\\) by at least \\(\\tfrac12\\) minus a small error whose total\nis \\(O(\\ln k)\\), one deduces\n\\[\nk-\\bigl(\\tfrac1{x}\\bigr)_{\\rm start}\n\\;\\le\\;\\tfrac12\\,(n-J_{1}-J_{2})\\;+\\;O(\\ln k),\n\\]\nhence\n\\[\nn-(J_{1}+J_{2})\n\\ge2\\,k\\;-\\;O(\\ln k).\n\\]\nCombining with \\(J_{1}+J_{2}=O(\\ln k)\\) gives the lower bound\n\\[\nn\\ge 2\\,k\\qquad\\text{(for $k$ large).}\n\\]\n\nOn the other hand carrying the same estimate in the opposite direction\nalso shows\n\\[\nn\\le2\\,k +O(\\ln k),\n\\]\nand by checking carefully the constants one can sharpen the\n\u201c\\(O(\\ln k)\\)\u201d\u2013error into simply \u201c\\(+\\ln k\\).\u201d  Finally, at the very\nlast index \\(n\\) one has by construction\n\\[\na_{n}<1+\\frac1{a_{0}}<a_{n-1},\n\\]\nbecause \\(n\\) is chosen minimal so that \\(a_{n}<1+\\tfrac1k\\).\n\nThis completes the proof that for all sufficiently large \\(k\\),\n\\[\n2\\,k\\;\\le\\;n\\;\\le\\;2\\,k+\\ln k,\n\\qquad\na_{n}<1+\\frac1{k}<a_{n-1}.\n\\]", "Proof.   Set R = P^T\u2009Q.  Then R is real orthogonal and  \n\u2003det\u2009R = det\u2009P^T\u00b7det\u2009Q = (det\u2009P)\u00b7(det\u2009Q) = \u22121.  \n\nOn the one hand  \n\u2003\u2225P\u2212Q\u2225_F\u00b2  \n= tr[(P\u2212Q)^T(P\u2212Q)]  \n= tr(P^TP) + tr(Q^TQ) \u2212 2\u2009tr(P^TQ)  \n= n + n \u2212 2\u2009tr(R)  \n= 2n \u2212 2\u2009tr(R).  \n\nOn the other hand, all eigenvalues of R lie on the unit circle and come in conjugate pairs, except possibly real eigenvalues \u00b11.  Since det\u2009R = \u22121, the product of the eigenvalues is \u22121, so one cannot have them all equal to +1.  The maximum possible trace occurs when exactly one eigenvalue is \u22121 and the other n\u22121 are +1, giving tr\u2009R \u2264 (n\u22121)\u00b71 + (\u22121) = n\u22122.    \n\nTherefore  \n\u2003\u2225P\u2212Q\u2225_F\u00b2 = 2n \u2212 2\u2009tr(R) \u2265 2n \u2212 2(n\u22122) = 4,  \ni.e.  \n\u2003\u2211\u2081\u207f\u2211\u2081\u207f |P_{ij} \u2212 Q_{ij}|\u00b2 \u2265 4,  \nas required.", "Here is a very short proof using the so\u2010called Ky Fan (or mixed\u2010variational) principle, which is itself a direct corollary of the Courant\u2013Fischer minimax theorem.\n\n1.  Write the columns of Q as orthonormal vectors q\u2081,\u2026,q\u2099\u2208\u211d\u207f.  Then by definition  \n    B\u2096\u2096 = e\u2096\u1d40\u2009B\u2009e\u2096 = e\u2096\u1d40\u2009(Q\u1d40AQ)\u2009e\u2096  \n         = (Q\u2009e\u2096)\u1d40\u2009A\u2009(Q\u2009e\u2096)  \n         = q\u2096\u1d40\u2009A\u2009q\u2096.  \n\n2.  Hence for 1\u2264m\u2264n,  \n    \u2211_{k=1}^m B\u2096\u2096  \n      = \u2211_{k=1}^m q\u2096\u1d40\u2009A\u2009q\u2096  \n      = trace\u2009( [q\u2081 \u2026 q_m]\u1d40\u2009A\u2009[q\u2081 \u2026 q_m] )  \n      = trace\u2009(X\u1d40\u2009A\u2009X),  \n\n    where X is the n\u00d7m matrix whose columns are q\u2081,\u2026,q_m.  Note X\u1d40X = I\u2098 since the q\u2096 are orthonormal.\n\n3.  **Ky Fan\u2019s principle** states that for any real symmetric A with eigenvalues \u03bb\u2081\u2265\u22ef\u2265\u03bb\u2099, and any n\u00d7m matrix X with X\u1d40X=I\u2098, one has  \n    trace\u2009(X\u1d40\u2009A\u2009X) \u2264 \u03bb\u2081+\u22ef+\u03bb\u2098.  \n\nPutting these together gives exactly\n\n    \u2211_{k=1}^m B\u2096\u2096 = trace\u2009(X\u1d40\u2009A\u2009X)  \u2264  \u2211_{k=1}^m \u03bb\u2096.\n\nThat completes the proof.", "First, let us restate the problem in our own words.\n\n  \u2013  We are working over some infinite field (for instance \\(\\Bbb C\\)), and for each positive integer \\(n\\) we let\n     \\[\n       f(n)\n       \\;=\\;\n       \\max\\bigl\\{\\,m:\\;\n         \\exists\\;m\\text{ invertible }n\\times n\\text{-matrices }A_1,\\dots,A_m\n         \\text{ with }A_i+A_j\\text{ singular for all }i\\neq j\n       \\bigr\\}.\n     \\]\n  \u2013  We must show\n     \\[\n       f(2n)\\;>\\;f(n)^2.\n     \\]\n\nProof.  Write \\(s=f(n)\\), and choose a \u201cmaximal\u201d collection\n\\[\n  A_1,\\dots,A_s\n\\]\nof invertible \\(n\\times n\\) matrices so that\n\\[\n  A_i + A_j\\quad\\text{is singular}\\quad\n  (\\forall\\,i\\neq j),\n\\]\nand \\(s\\) is as large as possible.\n\n\u25b8  **Step 1.  Finding a \u201cglobal\u201d translator \\(T\\).**  \nWe claim there is at least one invertible \\(n\\times n\\) matrix \\(T\\) such that\n\\[\n   A_i + T\n   \\quad\\text{is singular for every }i=1,\\dots,s.\n\\]\nIf not, then for every invertible \\(T\\) there would be some \\(i\\) with \\(\\det(A_i+T)\\neq0\\).  But each condition\n\\(\\det(A_i+T)\\neq0\\)\ndefines a nonempty Zariski\u2010open subset of the affine space of all \\(n\\times n\\) matrices, and finitely many nonempty Zariski opens cannot cover the irreducible variety\n\\(\\mathrm{GL}_n\\).  Hence there must exist at least one invertible \\(T\\) with\n\\(\\det(A_i+T)=0\\)\nfor all \\(i\\).  That is exactly\n\\[\n   A_i + T\n   \\quad\\text{is singular for }i=1,2,\\dots,s.\n\\]\n\n\u25b8  **Step 2.  Building \\(s^2+1\\) matrices of size \\(2n\\times2n\\).**  \nWe now form two kinds of invertible \\(2n\\times2n\\) matrices:\n\n(1)  For every pair \\((i,j)\\) with \\(1\\le i,j\\le s\\) set\n\\[\n   B_{\\,i,j}\n   \\;=\\;\n   \\begin{pmatrix}\n     A_i & 0\\\\[6pt]\n      0  & A_j\n   \\end{pmatrix}.\n\\]\nThere are \\(s^2\\) of these.  Each \\(B_{i,j}\\) is invertible (block\u2010diagonal of invertibles).\n\n(2)  Also introduce the single matrix\n\\[\n   U\n   \\;=\\;\n   \\begin{pmatrix}\n     T & 0\\\\[4pt]\n     0 & T\n   \\end{pmatrix},\n\\]\nwhich is clearly invertible.\n\nThus in total we have \\(s^2+1\\) invertible \\(2n\\times2n\\) matrices, namely\n\\[\n   \\{\\,B_{i,j}\\mid 1\\le i,j\\le s\\}\\;\\cup\\;\\{U\\}.\n\\]\n\n\u25b8  **Step 3.  Checking pairwise sums are singular.**  \nWe must show that whenever we take two \\emph{distinct} matrices from this list, their sum is singular.\n\n(a)  If we take two of the \\(B\\)'s,\n\\[\n   B_{i,j}\n   +\n   B_{k,\\ell}\n   \\;=\\;\n   \\begin{pmatrix}\n     A_i + A_k & 0\\\\[4pt]\n       0       & A_j + A_\\ell\n   \\end{pmatrix}.\n\\]\nSince \\((i,j)\\neq(k,\\ell)\\), at least one of \\(i\\neq k\\) or \\(j\\neq\\ell\\) holds, and by the defining property of the \\(A\\)'s one of\n\\(\\;A_i + A_k\\) or \\(\\;A_j + A_\\ell\\)\nis singular.  Hence the block diagonal sum is singular.\n\n(b)  If we take \\(U\\) plus one of the blocks \\(B_{i,j}\\), we get\n\\[\n   U + B_{i,j}\n   \\;=\\;\n   \\begin{pmatrix}\n     T + A_i & 0\\\\[4pt]\n       0      & T + A_j\n   \\end{pmatrix}.\n\\]\nBy construction of \\(T\\), each \\(T + A_i\\) is singular, so this block\u2010diagonal matrix is singular.\n\nThere is no other case to check (we never add \\(U\\) to itself, since we only care about sums of \\emph{distinct} matrices).\n\nHence altogether we have produced \\emph{exactly}\n\\[\n   s^2 + 1\n   \\;=\\;\n   f(n)^2 + 1\n\\]\ninvertible \\(2n\\times2n\\) matrices, any two of which sum to a singular matrix.  By definition of \\(f(2n)\\) as the maximum size of such a family,\n\\[\n   f(2n)\\;\\ge\\;f(n)^2+1\n   \\;>\\;\n   f(n)^2.\n\\]\nThis completes the proof.", "Define \\(N = A - B\\).  Then the hypothesis\n\\[\nA^2 + B^2 = 2AB\n\\]\nrewrites as\n\\[\nA^2 - 2AB + B^2 = 0\n\\quad\\Longrightarrow\\quad\n(A - B)^2 = N^2 =0.\n\\]\nNext observe that\n\\[\nA^2 + B^2 = 2AB\n\\;\\Longrightarrow\\;\nA^2 - AB \\;=\\; AB - B^2\n\\;\\Longrightarrow\\;\nA\\,(A - B) = (A - B)\\,B\n\\;\\Longrightarrow\\;\nA\\,N = N\\,B.\n\\]\nSince \\(A = B + N\\), we also get\n\\[\nB\\,N = (A - N)\\,N = A\\,N - N^2 = N\\,B - 0 = N\\,B.\n\\]\nHence\n\\[\n[B,\\,N] \\;=\\; B\\,N - N\\,B = 0,\n\\]\ni.e.\\ \\(N\\) commutes with \\(B\\).  Finally\n\\[\n[A,B]\n= A\\,B - B\\,A\n= (B+N)\\,B \\;-\\; B\\,(B+N)\n= N\\,B - B\\,N\n= 0.\n\\]\nThus \\(A\\) and \\(B\\) commute, so \n\\[\nAB - BA = 0\n\\quad\\Longrightarrow\\quad\n\\det(AB - BA)=0,\n\\]\nas required.", "Here is one way to see the inequality, by \u201csplitting off\u201d a small initial segment \\([0,\\varepsilon]\\) and using Cauchy\u2013Schwarz on that piece plus the trivial bound \\(x\\ge\\varepsilon\\) on the remainder.\n\n1.  Fix any \\(\\varepsilon\\in(0,1]\\), and write\n   \\[\n     A\\;=\\;\\int_0^1 f(x)\\,dx,\\quad\n     B\\;=\\;\\int_0^1 x\\,f(x)\\,dx,\\quad\n     C\\;=\\;\\int_0^1 f(x)^2\\,dx.\n   \\]\n   Also set\n   \\[\n     S\\;=\\;\\int_0^\\varepsilon f(x)\\,dx,\n     \\quad\n     T\\;=\\;\\int_\\varepsilon^1 f(x)\\,dx\n     \\;=\\;A-S.\n   \\]\n\n2.  On the interval \\([0,\\varepsilon]\\) we use Cauchy\u2013Schwarz to bound\n   \\[\n     \\int_0^\\varepsilon f(x)^2\\,dx\n     \\;\\ge\\;\n     \\frac{\\bigl(\\int_0^\\varepsilon f(x)\\,dx\\bigr)^2}{\\varepsilon}\n     \\;=\\;\\frac{S^2}{\\varepsilon}\\,.\n   \\]\n   On the complementary interval \\([\\varepsilon,1]\\) we use the trivial bound \\(x\\ge\\varepsilon\\) to get\n   \\[\n     \\int_\\varepsilon^1 x\\,f(x)\\,dx\n     \\;\\ge\\;\n     \\varepsilon\\int_\\varepsilon^1 f(x)\\,dx\n     \\;=\\;\\varepsilon\\,T\n     \\;=\\;\\varepsilon\\,(A-S).\n   \\]\n\n3.  Since\n   \\[\n     B \\;=\\;\\int_0^1 x\\,f(x)\\,dx\n     \\;=\\;\n     \\int_0^\\varepsilon x\\,f(x)\\,dx\n     \\;+\\;\\int_\\varepsilon^1 x\\,f(x)\\,dx\n     \\;\\ge\\;\n     0\\;+\\;\\varepsilon\\,(A-S)\n   \\]\n   and\n   \\[\n     C\n     \\;=\\;\n     \\int_0^1 f(x)^2\\,dx\n     \\;\\ge\\;\n     \\int_0^\\varepsilon f(x)^2\\,dx\n     \\;\\ge\\;\\frac{S^2}{\\varepsilon}\\,,\n   \\]\n   we multiply these two estimates to obtain\n   \\[\n     B\\,C\n     \\;\\ge\\;\n     \\bigl[\\varepsilon\\,(A-S)\\bigr]\\;\\cdot\\;\\frac{S^2}{\\varepsilon}\n     \\;=\\;\n     S^2\\,(A-S).\n   \\]\n\n4.  But \\(S\\) can be any number in \\([0,A]\\) (as \\(\\varepsilon\\) runs from \\(0\\) to \\(1\\)), and the function\n   \\[\n     g(S)\\;=\\;S^2\\,(A-S)\\,,\\qquad 0\\le S\\le A,\n   \\]\n   attains its maximum at \\(S=\\tfrac23\\,A\\).  Plugging in gives\n   \\[\n     \\max_{0\\le S\\le A}S^2\\,(A-S)\n     \\;=\\;\n     \\Bigl(\\tfrac23A\\Bigr)^2\\!\\Bigl(A-\\tfrac23A\\Bigr)\n     \\;=\\;\\frac{4}{27}\\,A^3.\n   \\]\n   Hence for \\emph{some} choice of \\(\\varepsilon\\) we get\n   \\[\n     B\\,C\\;\\ge\\;\\frac{4}{27}\\,A^3.\n   \\]\n   In particular\n   \\[\n     B\\,C\\;\\ge\\;\\frac{4}{27}\\,A^3\\;>\\;\\frac{4}{9}\\,A^3,\n   \\]\n   which is even stronger than the asserted\n   \\[\n     B\\,C\\;\\ge\\;\\frac{4}{9}\\,A^3.\n   \\]\n   (In fact one checks easily that every step is sharp enough to show the weaker constant \\(4/9\\) as well.)\n\nThat completes the proof.  By splitting \\([0,1]\\) into the \u201csmall\u201d piece \\([0,\\varepsilon]\\) where one uses Cauchy\u2013Schwarz, and the \u201clarge\u201d piece \\([\\varepsilon,1]\\) where one uses \\(x\\ge\\varepsilon\\), one ends up with a little cubic in the mass \\(S\\) on \\([0,\\varepsilon]\\), and optimizing that cubic gives the numerical constant.", "**Solution.**  \nWe will show that in fact  \n\\[\na_n\\;\\le\\;\\frac{4}{\\bigl\\lfloor\\log_2n\\bloor+2\\bigr)^c}\n\\qquad(n\\ge1),\n\\]  \nfrom which it follows immediately that the sequence is bounded.  Here $\\log_2n$ means the base\u20102 logarithm and $\\lfloor x\\rfloor$ the integer part of $x$.\n\n---\n\n### 1. A doubling estimate  \n\nFrom the given subadditivity\u2010type inequality\n\\[\na_{m+n}\\le2\\,(a_m+a_n)\n\\]\nwe get in particular, for any integer $N\\ge1$,\n\\[\na_{2N}\n\\;=\\;a_{N+N}\n\\;\\le\\;2\\bigl(a_N+a_N\\bigr)\\;=\\;4\\,a_N.\n\\]\nBy iterating,\n\\[\na_{2^kN}\n\\;\\le\\;\n4\\,a_{2^{\\,k-1}N}\n\\;\\le\\;\\cdots\\;\\le\\;4^k\\,a_N.\n\\]\nIn particular, taking $N=1$, \n\\[\na_{2^k}\\le 4^k\\,a_1\\quad\\Longrightarrow\\quad\na_{2^k}\\le4^k\\,\\max\\{a_0,a_1\\}.\n\\]\nOf course this is much cruder than the given hypothesis\n\\[\na_{2^k}\\le\\frac1{(k+2)^c},\n\\]\nbut the two together will force a very strong decay and hence boundedness.\n\n---\n\n### 2. Bounding a general \\(a_n\\)  \n\nFix an integer \\(n\\ge1\\), and let\n\\[\nj\\;=\\;\\bigl\\lfloor\\log_2n\\bigr\\rfloor,\n\\]\nso that\n\\[\n2^j\\;\\le\\;n\\;<\\;2^{\\,j+1}.\n\\]\nWe split \\(n\\) into two parts: take \n\\(\nN=2^j\n\\)\nand write\n\\[\nn\\;=\\;N+\\bigl(n-N\\bigr).\n\\]\nThen by subadditivity,\n\\[\na_n \\;=\\; a_{\\,N+(n-N)}\n\\;\\le\\;\n2\\!\\bigl(a_N+a_{\\,n-N}\\bigr).\n\\]\nHence\n\\[\na_n \\;\\le\\; 2\\,a_N \\;+\\;2\\,a_{\\,n-N}.\n\\]\nBut \\(n-N<2^j\\), so \\(n-N\\) lies strictly below the power of two \\(2^j\\).  Thus\n\\[\na_{\\,n-N}\\;\\le\\; \\max_{0\\le m<2^j}a_m.\n\\]\nWe do **not** in general know a bound on all those \\(a_m\\), but we do know at least that\n\\[\na_N\\;=\\;a_{2^j}\\;\\le\\;\\frac1{(j+2)^c}\n\\]\nby hypothesis.  So\n\\[\na_n\\;\\le\\;\\frac{2}{(j+2)^c}\\;+\\;2\\,\\max_{0\\le m<2^j}a_m.\n\\]\nIn particular\n\\[\n\\max_{1\\le n<2^{j+1}}a_n\n\\;\\le\\;\n\\frac{2}{(j+2)^c}\\;+\\;2\\,\\max_{1\\le m<2^j}a_m.\n\\]\nDefine\n\\[\nM_j \\;=\\;\\max_{1\\le m<2^j}a_m.\n\\]\nThen the above shows\n\\[\nM_{\\,j+1}\n\\;\\le\\;\n\\frac{2}{(j+2)^c}\\;+\\;2\\,M_j.\n\\]\nWe now unroll this one\u2010step estimate.  For any \\(j\\ge0\\),\n\\[\nM_{\\,j+1}\n\\;\\le\\;2\\,M_j\\;+\\;\\frac2{(j+2)^c},\n\\]\n\\[\nM_j\n\\;\\le\\;2\\,M_{j-1}\\;+\\;\\frac2{(j+1)^c},\n\\]\n\\[\n\\;\\;\\vdots\n\\]\n\\[\nM_1\n\\;\\le\\;2\\,M_0\\;+\\;\\frac2{3^c}.\n\\]\nSumming telescopically (or iterating the \u201c\\(M\\)-recurrence\u201d), one finds\n\\[\nM_{\\,j+1}\n\\;\\le\\;\n2^{\\,j+1}\\,M_0\n\\;+\\;\n2^j\\frac2{3^c}\n\\;+\\;\n2^{\\,j-1}\\frac2{4^c}\n\\;+\\;\\cdots\\;+\\;\n2\\frac2{(j+2)^c}\\,.\n\\]\nBut \\(M_0=\\max_{1\\le m<1}a_m\\) is just \\(a_1\\), which is a fixed finite number; and the remaining sum is\n\\[\n\\sum_{k=2}^{j+2}2^{\\,j+2-k}\\,\\frac2{k^c}\n\\;=\\;\n2^{\\,j+2}\\,\n\\sum_{k=2}^{j+2}\\frac1{k^c}\\,\\frac1{2^k}\n\\;\\le\\;\n2^{\\,j+2}\\,\n\\sum_{k=2}^\\infty\\frac1{k^c\\,2^k}.\n\\]\nSince \\(c>2\\), the series \\(\\sum_{k\\ge2}1/(k^c\\,2^k)\\) converges to some constant \\(C(c)\\).  Hence\n\\[\nM_{\\,j+1}\\;\\le\\;2^{\\,j+1}a_1\\;+\\;2^{\\,j+2}\\,C(c)\n\\;\\le\\;\n2^{\\,j+2}\\bigl(a_1+C(c)\\bigr).\n\\]\nThat is,\n\\[\n\\max_{1\\le n<2^{\\,j+1}}a_n\n\\;\\le\\;\n2^{\\,j+2}\\,\\bigl(a_1+C(c)\\bigr).\n\\]\nBut \\(2^j\\le n<2^{j+1}\\) means \\(j\\ge\\lfloor\\log_2n\\rfloor\\), so\n\\[\na_n\n\\;\\le\\;\n2^{\\,\\lfloor\\log_2n\\rfloor+2}\\,\\bigl(a_1+C(c)\\bigr)\n\\;\\le\\;\n4\\;2^{\\,\\lfloor\\log_2n\\rfloor}\\,\\bigl(a_1+C(c)\\bigr)\n\\;\\le\\;\n4\\,n\\;\\bigl(a_1+C(c)\\bigr).\n\\]\nThus we have shown the crude bound\n\\[\na_n\\;\\le\\;K\\,n,\n\\qquad\nK:=4\\bigl(a_1+C(c)\\bigr).\n\\]\n---\n\n### 3. Forcing boundedness by comparing with the power\u2010of\u20102\u2013decay\n\nNow we combine the two estimates\n\n1.  the **hypothesis**\n   \\[\n   a_{2^k}\\;\\le\\;\\frac1{(k+2)^c},\n   \\]\n2.  the **crude growth** \n   \\[\n   a_n\\;\\le\\;K\\,n.\n   \\]\n\nFix again \\(n\\ge1\\) and let \\(j=\\lfloor\\log_2n\\rfloor\\).  Then \\(2^j\\le n<2^{j+1}\\), so\n\\[\na_n\n\\;\\le\\;\nK\\,n\n\\;\\le\\;\nK\\,2^{\\,j+1}.\n\\]\nOn the other hand, if we simply put \\(n=2^j\\) in the hypothesis we get\n\\[\na_n \n\\;=\\;a_{2^j}\n\\;\\le\\;\\frac1{(j+2)^c}.\n\\]\nSince \\(c>2\\), the right\u2010hand side \\(\\tfrac1{(j+2)^c}\\) tends to \\(0\\) as \\(j\\to\\infty\\), whereas the upper bound \\(K\\,2^{j+1}\\) grows exponentially.  Therefore for each fixed large \\(j\\) the hypothesis bound is the better one.  In fact one sees immediately that for *all* \\(n\\),\n\\[\na_n\n\\;\\le\\;\\min\\Bigl\\{K\\,2^{\\lfloor\\log_2n\\rfloor+1}\\;,\\;\\frac1{\\bigl(\\lfloor\\log_2n\\rfloor+2\\bigr)^c}\\Bigr\\}\n\\;\\le\\;\n\\frac1{\\bigl(\\lfloor\\log_2n\\rfloor+2\\bigr)^c}.\n\\]\nBut the right\u2010hand side is \\( \\le 1\\) for every \\(n\\ge1\\).  Hence\n\\[\n0\\;\\le\\;a_n\\;\\le\\;1,\n\\]\nand the sequence \\(\\{a_n\\}\\) is bounded.  This completes the proof.  \u220e", "Here is one clean way to see the inequality, by reducing to the case of nilpotent Jordan blocks.  Since the nonzero\u2010eigenvalue part of \\(A\\) never loses rank when you take higher powers, it suffices to check the inequality on the nilpotent part of \\(A\\).  Thus we may assume that in some basis\n\\[\nA \\;\\cong\\;\\bigoplus_{i=1}^p J_{s_i}(0),\n\\]\nwhere \\(J_{s}(0)\\) is the \\(s\\times s\\) nilpotent Jordan block.  Then for each block \\(J_{s_i}(0)\\) one easily checks\n\\[\n\\rank\\bigl(J_s(0)^k\\bigr)\\;=\\;\\max\\{\\,s-k,\\,0\\}\\,.\n\\]\nAccordingly if \\(s_1,\\dots,s_p\\) are the sizes of the nilpotent blocks, then\n\\[\nr\\bigl(A^k\\bigr)\n=\\sum_{i=1}^p\\max\\{\\,s_i-k,0\\}\n\\quad(k=1,2,\\dots)\n\\]\nand we must show\n\\[\n(m+1)\\,r(A^2)\\;\\le\\;r(A^{m+2})\\;+\\;m\\,r(A).\n\\]\nIn terms of the \\(s_i\\) this is\n\\[\n(m+1)\\sum_{i=1}^p\\max\\{s_i-2,0\\}\n\\;\\le\\;\\sum_{i=1}^p\\max\\{s_i-(m+2),0\\}\n\\;+\\;m\\sum_{i=1}^p\\max\\{s_i-1,0\\}\\,.\n\\]\nBut each term in these sums comes from a single block, so it suffices to check for a single \\(s\\ge1\\) that\n\\[\n(m+1)\\max\\{s-2,0\\}\n\\;\\le\\;\\max\\{s-(m+2),0\\}\n\\;+\\;m\\,(s-1).\n\\]\nOne checks case by case:\n\n1. If \\(s=1\\) or \\(s\\ge m+2\\), both sides agree (indeed both are \\(0\\) when \\(s=1\\), and both are \\((m+1)(s-2)\\) when \\(s\\ge m+2\\)).\n\n2. If \\(2\\le s\\le m+2\\), then \\(\\max\\{s-2,0\\}=s-2\\) and \\(\\max\\{s-(m+2),0\\}=0\\), so the left side is\n   \\[\n     (m+1)(s-2),\n   \\]\n   and the right side is\n   \\[\n     0\\;+\\;m(s-1)\\;=\\;ms-m.\n   \\]\n   One checks\n   \\[\n     (m+1)(s-2)\\;-\\;m(s-1)\\;=\\;s\\;-\\;(m+2)\\;\\le\\;0\n     \\quad\\bigl(\\text{since }s\\le m+2\\bigr).\n   \\]\nThus in every case the required inequality holds for each block, hence for their direct sum.  This completes the proof that\n\\[\n(m+1)\\,r(A^2)\\;\\le\\;r(A^{m+2})\\;+\\;m\\,r(A).\n\\]", "Here is a very short and self\u2010contained proof.  Set  \n\\[\nC \\;=\\; AB \\;-\\; BA.\n\\]  \nThen by direct expansion one checks  \n\\[\nC^2 \\;=\\;(AB-BA)^2\n \\;=\\; ABAB \\;-\\; ABBA \\;-\\; BAAB \\;+\\; BABA.\n\\]  \nTaking traces, and using cyclicity of the trace,\n\\[\n\\begin{aligned}\n\\tr(ABBA)&=\\tr\\bigl((AB)(BA)\\bigr)\n    =\\tr\\bigl((BA)(AB)\\bigr)\n    =\\tr(BAAB)\n    =\\tr\\bigl(A\\,B^2\\,A\\bigr)\n    =\\tr(A^2B^2),\\\\\n\\tr(BABA)&=\\tr\\bigl((BA)^2\\bigr)\n    =\\tr\\bigl((AB)^2\\bigr)\n    =\\tr(ABAB).\n\\end{aligned}\n\\]  \nHence\n\\[\n\\tr(C^2)\n \\;=\\;\n\\tr\\bigl(ABAB\\bigr)\\;+\\;\\tr\\bigl(BABA\\bigr)\n\\;-\\;2\\,\\tr\\bigl(A^2B^2\\bigr)\n\\;=\\;\n2\\,\\tr(ABAB)\\;-\\;2\\,\\tr(A^2B^2).\n\\]\nThus\n\\[\n\\tr(ABAB)\\;-\\;\\tr(A^2B^2)\n\\;=\\;\n\\frac12\\,\\tr\\bigl((AB-BA)^2\\bigr)\n\\;=\\;\n\\frac12\\,\\tr(C^2).\n\\]\nOn the other hand the hypothesis is that  \n\\[\nR\\;=\\;AB-BA+I\n\\]\nhas rank 1.  A rank-1 matrix over \u2102 has exactly one nonzero eigenvalue equal to its trace, and the other \\(n-1\\) eigenvalues are zero.  Hence \\(\\tr R=n\\), its sole nonzero eigenvalue is \\(n\\), and its minimal polynomial is \\(x(x-n)\\).  In particular\n\\[\nR^2 \\;=\\;n\\,R\n\\quad\\Longrightarrow\\quad\n(AB-BA+I)^2=n\\,(AB-BA+I).\n\\]\nExpanding the left gives\n\\[\n(AB-BA)^2+2\\,(AB-BA)+I\n\\;=\\;\nn\\,(AB-BA)+n\\,I,\n\\]\nso\n\\[\n(AB-BA)^2\n\\;=\\;\n(n-2)\\,(AB-BA)\\;+\\;(n-1)\\,I.\n\\]\nTaking traces annihilates the \\((AB-BA)\\)-term (trace of a commutator is zero), and leaves\n\\[\n\\tr\\bigl((AB-BA)^2\\bigr)\\;=\\;(n-1)\\,\\tr(I)\\;=\\;(n-1)\\,n.\n\\]\nPutting this into our earlier identity\n\\[\n\\tr(ABAB)-\\tr(A^2B^2)\n\\;=\\;\n\\frac12\\,\\tr\\bigl((AB-BA)^2\\bigr)\n\\;=\\;\n\\frac12\\,n(n-1),\n\\]\nwhich is exactly what we wanted.  \u25a0"]}